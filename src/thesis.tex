\documentclass[12pt,a4paper,twoside,openany]{book}
\raggedbottom

%% build: latexmk -pdf -pvc thesis.tex


%% Packages
%% --------------------------------------------------------------------------------

\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathpartir}
\usepackage{scalerel}
\usepackage{stmaryrd}
\usepackage{authblk}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\usepackage{bm}
\usepackage{titlesec}

\usepackage{multirow}
\usepackage{tikz}
\usetikzlibrary{arrows,
                calc,
                decorations.pathreplacing,
                calligraphy,% had to be after decorations.pathreplacing
                matrix,
                positioning
                }

%% \bibliographystyle{IEEEtran}
\bibliographystyle{alpha}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\small\thepage}
\fancyhead[RE]{\small\rightmark}
\fancyhead[LO]{\small\leftmark}

%% Environments
%% --------------------------------------------------------------------------------

\theoremstyle{remark}
\newtheorem{notation}{Notation}

\theoremstyle{definition}
\newtheorem{mydefinition}{Definition}
\newtheorem{myexample}{Example}
\newtheorem{mylemma}{Lemma}

\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newtheorem{corollary}{Corollary}

%% Fonts and spacing
%% --------------------------------------------------------------------------------

%% \geometry{left=3cm,right=2cm,top=2.5cm,bottom=2.5cm,includehead,includefoot}

\linespread{1.25}
\geometry{left=4cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includehead,includefoot}


%% Chapter style
%% --------------------------------------------------------------------------------

\titleformat{\chapter}[display]
  {\bfseries\Large}
  {\filright\MakeUppercase{\chaptertitlename} \Huge\thechapter}
  {1ex}
  {\titlerule\vspace{1ex}\filleft}
  [\vspace{1ex}\titlerule]


%% Abbrevs
%% --------------------------------------------------------------------------------

\newcommand{\mi}[1]{\mathit{#1}}
\newcommand{\ms}[1]{\mathsf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}


\newcommand{\Ix}{\mi{Ix}}

\newcommand{\zero}{\ms{zero}}
\newcommand{\suc}{\ms{suc}}

\newcommand{\refl}{\mathsf{refl}}
\newcommand{\reflect}{\mathsf{reflect}}
\newcommand{\Reflect}{\mathsf{Reflect}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\Con}{\mathsf{Con}}
\newcommand{\Sub}{\mathsf{Sub}}
\newcommand{\Tm}{\mathsf{Tm}}
\newcommand{\Ty}{\mathsf{Ty}}
\newcommand{\U}{\mathsf{U}}
\newcommand{\El}{\mathsf{El}}
\newcommand{\Id}{\mathsf{Id}}
\newcommand{\proj}{\mathsf{proj}}
\renewcommand{\tt}{\mathsf{tt}}
\newcommand{\blank}{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}
\newcommand{\ra}{\rightarrow}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\Lift}{\Uparrow}
\newcommand{\ToS}{\mathsf{ToS}}
\newcommand{\ext}{\triangleright}
\newcommand{\emptycon}{\scaleobj{.75}\bullet}
\newcommand{\Pii}{\Pi}
\newcommand{\funi}{\Rightarrow}
\newcommand{\fune}{\Rightarrow^{\ms{ext}}}
\newcommand{\appi}{\mathsf{app}}
\newcommand{\lami}{\mathsf{lam}}
\newcommand{\Pie}{\Pi^{\mathsf{ext}}}
\newcommand{\appe}{\mathsf{app^{ext}}}
\newcommand{\lame}{\mathsf{lam^{ext}}}
\newcommand{\toe}{\to^{\ms{ext}}}
\newcommand{\Piinf}{\Pi^{\mathsf{inf}}}
\newcommand{\appinf}{\mathsf{app^{inf}}}
\newcommand{\laminf}{\mathsf{lam^{inf}}}
\newcommand{\appitt}{\mathop{{\scriptstyle @}}}
\newcommand{\Refl}{\mathsf{Refl}}
\newcommand{\IdU}{\mathsf{IdU}}
\newcommand{\ReflU}{\mathsf{ReflU}}
\newcommand{\Sig}{\mathsf{Sig}}
\newcommand{\ToSSig}{\mathsf{ToSSig}}
\newcommand{\Subtype}{\mathsf{Subtype}}
\newcommand{\subtype}{\mathsf{subtype}}
\newcommand{\NatSig}{\mathsf{NatSig}}
\newcommand{\Sg}{\Sigma}
\newcommand{\flcwf}{\mathsf{flcwf}}
\newcommand{\SigTy}{\mathsf{SigTy}}
\newcommand{\SigTm}{\mathsf{SigTm}}
\newcommand{\SigU}{\mathsf{SigU}}
\newcommand{\tm}{\ms{tm}}
\newcommand{\ty}{\ms{ty}}

\newcommand{\Kfam}{\mathsf{K}}
\newcommand{\lamK}{\mathsf{lam}_{\K}}
\newcommand{\appK}{\mathsf{app}_{\K}}

\newcommand{\toinf}{\to^{\ms{inf}}}
\newcommand{\lambdainf}{\lambda^{\ms{inf}}}

\newcommand{\p}{\mathsf{p}}
\newcommand{\q}{\mathsf{q}}
\newcommand{\K}{\mathsf{K}}
\newcommand{\A}{\mathsf{A}}
\newcommand{\D}{\mathsf{D}}
\renewcommand{\S}{\mathsf{S}}
\newcommand{\arri}{\Rightarrow}
\newcommand{\arre}{\Rightarrow^{\mathsf{ext}}}
\newcommand{\arrinf}{\Rightarrow^{\mathsf{inf}}}
\newcommand{\syn}{\mathsf{syn}}
\newcommand{\SynSig}{\mathsf{SynSig}}
\newcommand{\bCon}{\bs{\Con}}
\newcommand{\bTy}{\bs{\Ty}}
\newcommand{\bSub}{\bs{\Sub}}
\newcommand{\bTm}{\bs{\Tm}}
\newcommand{\bGamma}{\bs{\Gamma}}
\newcommand{\bDelta}{\bs{\Delta}}
\newcommand{\bsigma}{\bs{\sigma}}
\newcommand{\bdelta}{\bs{\delta}}
\newcommand{\bepsilon}{\bs{\epsilon}}
\newcommand{\bt}{\bs{t}}
\newcommand{\bu}{\bs{u}}
\newcommand{\bA}{\bs{A}}
\newcommand{\ba}{\bs{a}}
\newcommand{\bb}{\bs{b}}
\newcommand{\bB}{\bs{B}}
\newcommand{\bid}{\bs{\id}}
\newcommand{\bemptycon}{\scaleobj{.75}{\bs{\bullet}}}
\newcommand{\bSet}{\bs{\Set}}
\newcommand{\bU}{\bs{\U}}
\newcommand{\bEl}{\bs{\El}}
\newcommand{\bPii}{\bs{\Pi}}
\newcommand{\bPie}{\bs{\Pie}}
\newcommand{\bPiinf}{\bs{\Piinf}}
\newcommand{\bappi}{\bs{\mathsf{app}}}
\newcommand{\blami}{\bs{\mathsf{lam}}}
\newcommand{\bId}{\bs{\Id}}
\newcommand{\bM}{\bs{\mathsf{M}}}
\newcommand{\bT}{\bs{\mathsf{T}}}
\newcommand{\bS}{\bs{\mathsf{S}}}
\newcommand{\bP}{\bs{\mathsf{P}}}
\newcommand{\bD}{\bs{\mathsf{D}}}
\newcommand{\bI}{\bs{\mathsf{I}}}
\newcommand{\bK}{\bs{\mathsf{K}}}

\newcommand{\ul}[1]{\underline{#1}}
\newcommand{\ulGamma}{\ul{\Gamma}}
\newcommand{\ulDelta}{\ul{\Delta}}
\newcommand{\ulgamma}{\ul{\gamma}}
\newcommand{\ulOmega}{\ul{\Omega}}
\newcommand{\uldelta}{\ul{\delta}}
\newcommand{\ulsigma}{\ul{\sigma}}
\newcommand{\ulnu}{\ul{\nu}}
\newcommand{\ulepsilon}{\ul{\epsilon}}
\newcommand{\ulemptycon}{\ul{\emptycon}}
\newcommand{\ult}{\ul{t}}
\newcommand{\ulu}{\ul{u}}
\newcommand{\ulA}{\ul{A}}
\newcommand{\ula}{\ul{a}}
\newcommand{\ulB}{\ul{B}}
\newcommand{\tos}{\mathsf{tos}}
\newcommand{\coe}{\mathsf{coe}}
\newcommand{\coh}{\mathsf{coh}}
\newcommand{\llb}{\llbracket}
\newcommand{\rrb}{\rrbracket}

\newcommand{\Var}{\ms{Var}}
\newcommand{\var}{\ms{var}}
\newcommand{\app}{\ms{app}}
\newcommand{\vz}{\ms{vz}}
\newcommand{\vs}{\ms{vs}}
\newcommand{\Alg}{\ms{Alg}}
\newcommand{\Mor}{\ms{Mor}}
\newcommand{\DispAlg}{\ms{DispAlg}}
\newcommand{\Section}{\ms{Section}}
\newcommand{\Initial}{\ms{Initial}}
\newcommand{\Inductive}{\ms{Inductive}}
\newcommand{\TmAlg}{\ms{TmAlg}}
\newcommand{\Rec}{\ms{Rec}}
\newcommand{\Ind}{\ms{Ind}}
\newcommand{\Obj}{\ms{Obj}}
\newcommand{\Nat}{\ms{Nat}}
\newcommand{\Bool}{\ms{Bool}}
\newcommand{\mbbC}{\mbb{C}}
\newcommand{\hmbbC}{\hat{\mbb{C}}}
\newcommand{\mbbD}{\mbb{D}}
\newcommand{\lam}{\ms{lam}}

\newcommand{\true}{\ms{true}}
\newcommand{\false}{\ms{false}}
\newcommand{\up}{\uparrow}
\newcommand{\down}{\downarrow}

\newcommand{\lab}{\langle}
\newcommand{\rab}{\rangle}
\newcommand{\defn}{:\equiv}
\newcommand{\yon}{\ms{y}}

\newcommand{\lub}{\,\sqcup\,}


%% --------------------------------------------------------------------------------

\title{Type-Theoretic Signatures for Algebraic Theories and Inductive Types}
\date{2021 September}
\author{András Kovács}

%% --------------------------------------------------------------------------------

\begin{document}

\clearpage\maketitle
\thispagestyle{empty}

\frontmatter
\tableofcontents{}

\mainmatter
\chapter{Introduction}
\section{Specification and Semantics for Inductive Types}
\section{Overview of the Thesis and Contributions}
\section{Notation and Conventions}
\subsection{Metatheory}
\subsection{Universes}
\label{sec:universes}
\label{sec:notation}

\chapter{Simple Inductive Signatures}
\label{chap:simple-inductive-signatures}

In this chapter, we take a look at a very simple notion of inductive
signature. The motivation for doing so is to present the basic ideas of this
thesis in the easiest possible setting, with explicit definitions. The later
chapters are greatly generalized and expanded compared to the current one, and
are not feasible (and probably not that useful) to present in full formal
detail. We also include a complete Agda formalization of the contents of this
chapter, in less than 200 lines.

\todo{potentially in intro}

The mantra throughout this dissertation is the following: inductive types are
specified by typing contexts in certain \emph{theories of signatures}. For each
class of inductive types, there is a corresponding theory of signatures, which
is viewed as a proper type theory and comes equipped with an algebraic model
theory. \emph{Semantics} of signatures is given by interpreting them in certain
models of the theory of signatures. Semantics should at least provide a notion
of induction principle for each signature; in this chapter we provide a bit more
than that, and substantially more in Chapters \ref{chap:fqiit} and \ref{chap:iqiit}.

\section{Theory of Signatures}
\label{sec:simple-signatures}

Generally, more expressive theories of signatures can describe a larger classes
of inductive types. As we are aiming at minimalism right now, the current theory
of signatures is as follows:

\begin{mydefinition}
The \textbf{theory of signatures}, or ToS for short, is a simple type theory
equipped with the following features:
  \begin{itemize}
    \item An empty base type $\iota$.
    \item A \emph{first-order function type} $\iota\!\to\!\blank$; this is a
      function whose domain is fixed to be $\iota$. Moreover, first-order functions only
      have neutral terms: there is application, but no $\lambda$-abstraction.
  \end{itemize}
\end{mydefinition}

We can specify the full syntax using the following Agda-like inductive definitions.
\begin{alignat*}{4}
  & \Ty              &&: \Set           && \Var &&: \Con \to \Ty \to \Set \\
  & \iota            &&: \Ty            && \vz  &&: \Var\,(\Gamma \ext A)\,A \\
  & \iota\!\to\blank &&: \Ty \to \Ty    && \vs  &&: \Var\,\Gamma\,A \to \Var\,(\Gamma \ext B)\,A\\
  & && && &&\\
  & \Con             &&: \Set           && \Tm  &&: \Con \to \Ty \to \Set \\
  & \emptycon        &&: \Con           && \var &&: \Var\,\Gamma\,A \to \Tm\,\Gamma\,A \\
  & \blank\ext\blank &&: \Con \to \Ty \to \Con \hspace{2em} && \app &&: \Tm\,\Gamma\,(\iota\to A) \to \Tm\,\Gamma\,\iota
                                                           \to \Tm\,\Gamma\,A
\end{alignat*}
Here, $\Con$ contexts are lists of types, and $\Var$ specifies well-typed De Bruijn indices, where
$\vz$ represents the zero index, and $\vs$ takes the successor of an index.

\begin{notation} We use capital Greek letters starting from $\Gamma$ to refer to contexts, $A$, $B$, $C$ to
refer to types, and $t$, $u$, $v$ to refer to terms. In examples, we may use a
nameful notation instead of De Bruijn indices. For example, we may write $x :
\Tm\,(\emptycon \ext (x : \iota) \ext (y : \iota))\,\iota$ instead of $\var\,(\vs\,\vz)
: \Tm\,(\emptycon \ext \iota \ext \iota)\,\iota$. Additionally, we may write
$t\,u$ instead of $\app\,t\,u$ for $t$ and $u$ terms.
\end{notation}

\begin{mydefinition} \textbf{Parallel substitutions} map variables to terms.
\begin{alignat*}{3}
&\Sub : \Con \to \Con \to \Set\\
&\Sub\,\Gamma\,\Delta \equiv \{A\} \to \Var\,\Delta\,A \to \Tm\,\Gamma\,A
\end{alignat*}
We use $\sigma$ and $\delta$ to refer to substitutions. We also recursively
define the action of substitution on terms:
\begin{alignat*}{3}
  &\rlap{$\blank[\blank] : \Tm\,\Delta\,A \to \Sub\,\Gamma\,\Delta \to \Tm\,\Gamma\,A$}\\
  &(\var\, x)   &&[ \sigma ] \defn \sigma\,x\\
  &(\app\,t\,u) &&[ \sigma ] \defn \app\,(t[\sigma])\,(u[\sigma])
\end{alignat*}
The identity substitution $\id$ is defined simply as $\var$. It is easy to see that
$t[\id] = t$ for all $t$. Substitution composition is as follows.
\begin{alignat*}{3}
  &\blank\!\circ\!\blank : \Sub\,\Delta\,\Xi \to \Sub\,\Gamma\,\Delta \to \Sub\,\Gamma\,\Xi\\
  &(\sigma \circ \delta)\,x \defn (\sigma\,x)[\delta]
\end{alignat*}
\end{mydefinition}

\begin{myexample} We may write signatures for natural numbers and binary trees respectively as follows.
\begin{alignat*}{3}
  & \ms{NatSig}  &&\defn \emptycon \ext (\mi{zero} : \iota) \ext (\mi{suc} : \iota \to \iota)\\
  & \ms{TreeSig} &&\defn \emptycon \ext (\mi{leaf} : \iota) \ext (\mi{node} : \iota \to \iota \to \iota)
\end{alignat*}
\end{myexample}

In short, the current ToS allows inductive types which are
\begin{itemize}
\item \emph{Single-sorted}: this means that we have a single type constructior, corresponding to $\iota$.
\item \emph{Closed}: signatures cannot refer to any externally existing type. For example, we cannot write a signature for ``lists of natural number'' in a direct fashion, since there is no way to refer to the type of natural numbers.
\item \emph{Finitary}: inductive types corresponding to signatures are always
  finitely branching trees. Being closed implies being finitary, since an
  infinitely branching node would require some external type to index subtrees
  with. For example, $\mi{node} : (\mathbb{N} \to \iota) \to \iota$ would
  specify an infinite branching (if such type was allowed in ToS).
\end{itemize}

\emph{Remark.} We omit $\lambda$-expressions from ToS for the sake of
simplicity: this causes terms to be always in normal form (neutral, to be
precise), and thus we can skip talking about conversion rules. Later, starting
from Chapter \ref{chap:fqiit} we include proper $\beta\eta$-rules in signature
theories.

\section{Semantics}
\label{sec:simple-semantics}

For each signature, we need to know what it means for a type theory to support
the corresponding inductive type. For this, we need at least a notion of
\emph{algebras}, which can be viewed as a bundle of all type and
value constructors, and what it means for an algebra to support an
\emph{induction principle}.  Additionally, we may want to know what it means to
support a \emph{recursion principle}, which can be viewed as a non-dependent
variant of induction. In the following, we define these notions by induction on
ToS syntax.

\emph{Remark.} We use ``algebra'' and ``model'' synonymously throughout
this thesis.

\subsection{Algebras}

First, we calculate types of algebras. This is simply a standard interpretation
into the $\Set$ universe. We define the following operations by induction; the
$\blank^A$ name is overloaded for $\Con$, $\Ty$ and $\Tm$.
\begin{alignat*}{3}
& \hspace{-4em} \rlap{$\blank^A : \Ty \to \Set \to \Set$} \\
& \hspace{-4em} \iota^A\,&&X \defn X \\
& \hspace{-4em} (\iota\to A)^A\,&&X \defn X \to A^A\,X\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Con \to \Set \to \Set$}\\
& \hspace{-4em} \rlap{$\Gamma^A\,X \defn \{A : \Ty\} \to \Var\,\Gamma\,A \to A^A\,X$}\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Tm\,\Gamma\,A \to \{X : \Set\} \to \Gamma^A\,X \to A^A\,X$}\\
& \hspace{-4em} (\var\,x)^A\,&&\gamma \defn \gamma\,x\\
& \hspace{-4em} (\app\,t\,u)^A\,&&\gamma \defn t^A\,\gamma\,(u^A\,\gamma)\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Sub\,\Gamma\,\Delta \to \{X : \Set\} \to \Gamma^A\,X \to \Delta^A\,X$}\\
& \hspace{-4em} \rlap{$\sigma^A\,\gamma\,x \defn (\sigma\,x)^A\,\gamma$}
\end{alignat*}
Here, types and contexts depend on some $X : \Set$, which serves as the
interpretation of $\iota$. We define $\Gamma^A$ as a product: for each variable
in the context, we get a semantic type. This trick, along with the definition of
$\Sub$, makes formalization a bit more compact. Terms and substitutions are
interpreted as natural maps. Substitutions are interpreted by pointwise interpreting
the contained terms.

\begin{notation}
We may write values of $\Gamma^A$ using notation for $\Sigma$-types. For
example, we may write $(\mi{zero} : X) \times (\mi{suc} : X \to X)$ for the
result of computing $\ms{NatSig}^A\,X$.
\end{notation}

\begin{mydefinition} We define \textbf{algebras} as follows.
\begin{alignat*}{3}
  & \Alg : \Con \to \Set_1 \\
  & \Alg\,\Gamma \defn (X : \Set) \times \Gamma^A\,X
\end{alignat*}
\end{mydefinition}

\begin{myexample} $\Alg\,\ms{NatSig}$ is computed to $(X : \Set)\times(\mi{zero} :
X)\times(\mi{suc} : X \to X)$.
\end{myexample}

\subsection{Morphisms}

Now, we compute notions of morphisms of algebras. In this case, morphisms are
functions between underlying sets which preserve all specified structure. The
interpretation for calculating morphisms is a \emph{logical relation
interpretation} \cite{udayReynolds} over the $\blank^A$ interpretation. The key
part is the interpretation of types:
\begin{alignat*}{3}
  & \hspace{-4em}\rlap{$\blank^M : (A : \Ty)\{X_0\,X_1 : \Set\}(X^M : X_0 \to X_1) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-4em}\iota^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn X^M\,\alpha_0 = \alpha_1 \\
  & \hspace{-4em}(\iota\to A)^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn
       (x : X_0) \to A^M\,X^M\,(\alpha_0\,x)\,(\alpha_1\,(X^M\,x))
\end{alignat*}
We again assume an interpretation for the base type $\iota$, as $X_0$, $X_1$ and
$X^M : X_0 \to X_1$. $X^M$ is function between underlying sets of algebras, and
$A^M$ computes what it means that $X^M$ preserves an operation with type $A$. At
the base type, preservation is simply equality. At the first-order function
type, preservation is a quantified statement over $X_0$. We define morphisms for
$\Con$ pointwise:
\begin{alignat*}{3}
  &\blank^M : (\Gamma : \Con)\{X_0\,X_1 : \Set\} \to (X_0 \to X_1) \to \Gamma^A\,X_0 \to \Gamma^A\,X_1 \to \Set\\
  &\Gamma^M\,X^M\,\gamma_0\,\gamma_1 \defn
    \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^M\,X^M\,(\gamma_0\,x)\,(\gamma_1\,x)
\end{alignat*}
For terms and substitutions, we get preservation statements, which are sometimes
called \emph{fundamental lemmas} in discussions of logical relations \cite{udayReynolds}.
\begin{alignat*}{3}
  & \hspace{-10em}\rlap{$\blank^M : (t : \Tm\,\Gamma\,A) \to \Gamma^M\,X^M\,\gamma_0\,\gamma_1 \to A^M\,X^M\,(t^A\,\gamma_0)\,(t^A\,\gamma_1)$}\\
  & \hspace{-10em}(\var\,x)^M    &&\gamma^M \defn \gamma^M\,x \\
  & \hspace{-10em}(\app\,t\,u)^M &&\gamma^M \defn t^M\,\gamma^M\,(u^A\,\gamma_0)\\
  & \hspace{-10em}&& \\
  & \hspace{-10em}\rlap{$\blank^M : (\sigma : \Sub\,\Gamma\,\Delta) \to \Gamma^M\,X^M\,\gamma_0\,\gamma_1 \to \Delta^M\,X^M\,(\sigma^A\,\gamma_0)\,(\sigma^A\,\gamma_1)$}\\
  & \hspace{-10em} \rlap{$\sigma^M\, \gamma^M\,x \defn (\sigma\,x)^M\,\gamma^M$}
\end{alignat*}
The definition of $(\app\,t\,u)^M$ is well-typed by the induction hypothesis
$u^M\,\gamma^M : X^M\,(u^A\,\gamma_0) = u^A\,\gamma_1$.

\begin{mydefinition}
\label{def:simple-morphism}
To get notions of \textbf{algebra morphisms}, we again pack up $\Gamma^M$ with
the interpretation of $\iota$.
\begin{alignat*}{3}
  & \Mor : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Alg\,\Gamma \to \Set \\
  & \Mor\,\{\Gamma\}\,(X_0,\,\gamma_0)\,(X_1,\,\gamma_1) \defn (X^M : X_0 \to X_1) \times \Gamma^M\,X^M\,\gamma_0\,\gamma_1
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation:
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\Mor\,\{\NatSig\}\,(X_0,\,\mi{zero_0},\,\mi{suc_0})\,(X_0,\,\mi{zero_1},\,\mi{suc_1}) \defn$} \\
           &(X^M : X_0 \to X_1) \\
   \times\,&(X^M\,\mi{zero_0} = \mi{zero_1}) \\
   \times\,&((x : X_0) \to X^M\,(\mi{suc_0}\,x) = \mi{suc_1}\,(X^M\,x))
\end{alignat*}
\end{myexample}

\begin{mydefinition} We state \textbf{initiality} as a predicate on algebras:
\begin{alignat*}{3}
  & \Initial : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set\\
  & \Initial\,\{\Gamma\}\,\gamma \defn
    (\gamma' : \Alg\,\Gamma) \to \ms{isContr}\,(\Mor\,\gamma\,\gamma')
\end{alignat*}
Here $\ms{isContr}$ refers to unique existence \cite[Section 3.11]{hottbook}. If we drop
$\ms{isContr}$ from the definition, we get the notion of weak initiality, which
corresponds to the recursion principle for $\Gamma$. Although we call this
predicate $\Initial$, in this chapter we do not yet show that algebras form a
category. We provide the extended semantics in Chapter \ref{chap:fqiit}. The
computed algebras and morphism there remain the same as in the current chapter.
\end{mydefinition}

\paragraph{Morphisms vs.\ logical relations.}
The $\blank^M$ interpretation can be viewed as a special case of logical
relations over the $\blank^A$ model: every morphism is a \emph{functional}
logical relation, where the chosen relation between the underlying sets happens
to be a function. Consider now a more general relational interpretation for
types:
\begin{alignat*}{3}
  & \hspace{-0.5em}\rlap{$\blank^R : (A : \Ty)\{X_0\,X_1 : \Set\}(X^R : X_0 \to X_1 \to \Set) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-0.5em}\iota^R\,&&X^R\,\alpha_0\,\,\alpha_1 \defn X^R\,\alpha_0\,\alpha_1 \\
  & \hspace{-0.5em}(\iota\to A)^R\,&&X^R\,\alpha_0\,\,\alpha_1 \defn
       (x_0 : X_0)(x_1 : X_1) \to X^R\,x_0\,x_1 \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,x_1)
\end{alignat*}
Here, functions are related if they map related inputs to related outputs. If we
know that $X^M\,\alpha_0\,\alpha_1 \equiv (f\,\alpha_0 = \alpha_1)$ for some $f$
function, we get
\[
  (x_0 : X_0)(x_1 : X_1) \to f\,x_0 = x_1 \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,x_1)
\]
Now, we can simply substitute along the input equality proof in the above type,
to get the previous definition for $(\iota \to A)^M$:
\[
  (x_0 : X_0) \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,(f\,x_0))
\]
This substitution along the equation is called ``singleton contraction'' in the
jargon of homotopy type theory \cite{hottbook}. The ability to perform contraction
here is at the heart of the \emph{strict positivity restriction} for inductive
signatures. Strict positivity in our setting corresponds to only having
first-order function types in signatures. If we allowed function domains to be
arbitrary types, in the definition of $(A \to B)^M$ we would only have a
black-box $A^M\,X^M : A^A\,X_0 \to A^A\,X_1 \to \Set$ relation, which is not
known to be given as an equality.

In Chapter \ref{chap:fqiit} we expand on this. As a preliminary summary:
although higher-order functions have relational interpretation, such relations
do not generally compose. What we eventually aim to have is a \emph{category} of
algebras and algebra morphisms, where morphisms do compose. We need a
\emph{directed} model of the theory of signatures, where every signature becomes
a category of algebras. The way to achieve this, is to prohibit higher-order
functions, thereby avoiding the polarity issues that prevent a directed
interpretation for general function types.

\subsection{Displayed Algebras}

At this point we do not yet have specification for induction principles. We use
the term \emph{displayed algebra} to refer to ``dependent'' algebras, where
every displayed algebra component lies over corresponding components in the base
algebra. For the purpose of specifying induction, displayed algebras can be
viewed as bundles of induction motives and methods.

Displayed algebras over some $\gamma : \Alg\,\Gamma$ are equivalent to slices
over $\gamma$ in the category of $\Gamma$-algebras; we show this in Chapter
\ref{chap:fqiit}. A slice $f : \Sub\,\Gamma\,\gamma'\,\gamma$ maps elements of
$\gamma$'s underlying set to elements in the base algebra. Why do we need
displayed algebras, then? The main reason is that if we are to eventually
implement inductive types in a dependently typed language, we need to compute
induction principles exactly, not merely up to isomorphisms.

For more illustration of using some displayed algebras in a type-theoretic
setting, see \cite{displayedcats}. We adapt the term ``displayed algebra'' from
ibid.\ as a generalization of displayed categories (and functors, natural
transformations) to other algebraic structures.

The displayed algebra interpretation is a \emph{logical predicate}
interpretation, defined as follows.
\begin{alignat*}{3}
  & \rlap{$\blank^D : (A : \Ty)\{X\} \to (X \to \Set) \to A^A\,X \to \Set$}\\
  & \iota^D\,       && X^D\,\alpha \defn X^D\,\alpha \\
  & (\iota\to A)^D\,&& X^D\,\alpha \defn (x : X)(x^D : X^D\,x) \to A^D\,X^D\,(\alpha\,x)\\
  & &&\\
  & \rlap{$\blank^D : (\Gamma : \Con)\{X\} \to (X \to \Set) \to \Gamma^A\,X \to \Set$}\\
  & \rlap{$\Gamma^D\,X^D\,\gamma \defn
       \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^D\,X^D\,(\gamma\,x)$}\\
  & &&\\
  & \rlap{$\blank^D : (t : \Tm\,\Gamma\,A)
      \to \Gamma^D\,X^D\,\gamma \to A^D\,X^D\,(t^A\,\gamma)$}\\
  & (\var\,x)^D\,&&\gamma^D \defn \gamma^D\,x\\
  & (\app\,t\,u)^D\,&&\gamma^D \defn t^D\,\gamma^D\,(u^A\,\gamma)\,(u^D\,\gamma^D)\\
  & &&\\
  & \rlap{$\blank^D : (\sigma : \Sub\,\Gamma\,\Delta)
      \to \Gamma^D\,X^D\,\gamma \to \Delta^D\,X^D\,(\sigma^A\,\gamma)$}\\
  & \rlap{$\sigma^D\,\gamma^D\,x \defn (\sigma\,x)^D\,\gamma^D$}
\end{alignat*}
Analogously to before, everything depends on a predicate interpretation $X^D : X
\to \Set$ for $\iota$. For types, a predicate holds for a function if the
function preserves predicates. The interpretation of terms is again a
fundamental lemma, and we again have pointwise definitions for contexts and
substitutions.
\begin{mydefinition}[\textbf{displayed algebras}]\label{def:simple-section}
\begin{alignat*}{3}
  & \DispAlg : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set_1\\
  & \DispAlg\,\{\Gamma\}\,(X,\,\gamma) \defn (X^D : X \to \Set) \times \Gamma^D\,X^D\,\gamma
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc}) \equiv$}\\
              & (X^D &&: X \to \Set)\\
      \times\,& (\mi{zero^D} &&: X^D\,\mi{zero})\\
      \times\,& (\mi{suc^D} &&: (n : X) \to X^D\,n \to X^D\,(\mi{suc}\,n))
\end{alignat*}
\end{myexample}

\subsection{Sections}

Sections of displayed algebras are ``dependent'' analogues of algebra morphisms,
where the codomain is displayed over the domain.

\begin{alignat*}{3}
  & \hspace{-6em}\rlap{$\blank^S : (A : \Ty)\{X\,X^D\}(X^S : (x : X) \to X^D\,x) \to (\alpha : A^A\,X) \to A^D\,X^D\,\alpha \to \Set$}\\
  & \hspace{-6em}\iota^S\,&&X^S\,\alpha\,\,\alpha^D \defn X^S\,\alpha = \alpha^D \\
  & \hspace{-6em}(\iota\to A)^S\,&&X^S\,\alpha\,\,\alpha^D \defn
  (x : X) \to A^S\,X^S\,(\alpha\,x)\,(\alpha^D\,(X^S\,x))\\
  & \hspace{-6em}&&\\
  &\hspace{-6em}\rlap{$\Con^S : (\Gamma : \Con)\{X\,X^D\}(X^S : (x : X) \to X^D\,x) \to (\gamma : \Gamma^A\,X) \to \Gamma^D\,X^D\,\gamma \to \Set$}\\
  &\hspace{-6em}\rlap{$\Gamma^S\,X^S\,\gamma_0\,\gamma_1 \defn
    \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^S\,X^S\,(\gamma_0\,x)\,(\gamma_1\,x)$}\\
  & \hspace{-6em} && \\
  & \hspace{-6em}\rlap{$\blank^S : (t : \Tm\,\Gamma\,A) \to \Gamma^S\,X^S\,\gamma\,\gamma^D \to A^S\,X^S\,(t^A\,\gamma)\,(t^D\,\gamma^D)$}\\
  & \hspace{-6em}(\var\,x)^S    &&\gamma^S \defn \gamma^S\,x \\
  & \hspace{-6em}(\app\,t\,u)^S &&\gamma^S \defn t^S\,\gamma^S\,(u^A\,\gamma)\\
  & \hspace{-6em}&& \\
  & \hspace{-6em}\rlap{$\blank^S : (\sigma : \Sub\,\Gamma\,\Delta) \to \Gamma^S\,X^S\,\gamma\,\gamma^D \to \Delta^S\,X^S\,(\sigma^A\,\gamma)\,(\sigma^A\,\gamma^D)$}\\
  & \hspace{-6em} \rlap{$\sigma^S\, \gamma^S\,x = (\sigma\,x)^S\,\gamma^S$}
\end{alignat*}

\begin{mydefinition}[\textbf{Displayed algebra sections} (``sections'' in short)]
\begin{alignat*}{3}
  & \Section : \{\Gamma : \Con\} \to (\gamma : \Alg\,\Gamma) \to \DispAlg\,\gamma \to \Set\\
  & \Section\,(X,\,\gamma)\,(X^D\,\gamma^D) \defn (X^S : (x : X) \to X^D\,x) \times \Gamma^S\,X^S\,\gamma\,\gamma^D
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\Section\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})\,(X^D,\,\mi{zero^D},\,\mi{suc^D}) \equiv$}\\
              & (X^S &&: (x : X) \to X^D\,x)\\
      \times\,& (\mi{zero^S} &&: X^S\,\mi{zero} = \mi{zero^D})\\
      \times\,& (\mi{suc^S} &&: (n : X) \to X^S\,(\mi{suc\,n}) = \mi{suc^D}\,n\,(X^S\,n))
\end{alignat*}
\end{myexample}

\begin{mydefinition}[\textbf{Induction}]
We define a predicate which holds if an algebra supports induction.
\begin{alignat*}{3}
  & \Inductive : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set_1\\
  & \Inductive\,\{\Gamma\}\,\gamma \defn
     (\gamma^D : \DispAlg\,\gamma) \to \Section\,\gamma\,\gamma^D
\end{alignat*}
\end{mydefinition}

We can observe that $\Inductive\,\{\ms{NatSig}\}\,(X,\,\ms{zero},\,\ms{suc})$
computes exactly to the usual induction principle for natural numbers. The input
$\DispAlg$ is a bundle of the induction motive and the methods, and the output
$\Section$ contains the $X^S$ eliminator function together with its $\beta$
computation rules.

\section{Term Algebras}

In this section we show that if a type theory supports the inductive types comprising
the theory of signatures, it also supports every inductive type which is described
by the signatures.

Note that we specified $\Tm$ and $\Sub$, but did not need either of them when
specifying signatures, or when computing induction principles. That signatures
do not depend on terms, is a property specific to simple signatures; this will
not be the case in Chapter \ref{chap:fqiit} when we move to more general
signatures. However, terms and substitutions are already useful here in the
construction of term algebras.

The idea is that terms in contexts comprise initial algebras. For example,
$\Tm\,\ms{NatSig}\,\iota$ is the set of natural numbers (up to
isomorphism). Informally, this is because the only way to construct terms is by
applying the $\ms{suc}$ variable (given by $\var\,\vz$) finitely many times to
the $\ms{zero}$ variable (given by $\var\,(\vs\,\vz)$).

\begingroup
\allowdisplaybreaks
\begin{mydefinition}[\textbf{Term algebras}]
Fix an $\Omega : \Con$. We abbreviate $\Tm\,\Omega\,\iota$ as $\ms{T}$; this will serve
as the carrier set of the term algebra. We additionally define the following.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^T : (A : \Ty) \to \Tm\,\Omega\,A \to A^A\,\ms{T}$} \\
  & \hspace{-5em}\iota^T\,&&t \defn t \\
  & \hspace{-5em}(\iota\to A)^T\,&&t \defn \lambda\,u.\,A^T\,(\app\,t\,u)\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (\Gamma : \Con) \to \Sub\,\Omega\,\Gamma \to \Gamma^A\,\ms{T}$}\\
  & \hspace{-5em}\rlap{$\Gamma^T\,\nu\,\{A\}\,x \defn A^T\,(\nu\,x)$}\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (t : \Tm\,\Gamma\,A)(\nu : \Sub\,\Omega\,\Gamma) \to A^T\,(t[\nu]) = t^A\,(\Gamma^T\,\nu)$}\\
  & \hspace{-5em}(\var\,x)^T\,   &&\nu    \text{   holds by   } \refl\\
  & \hspace{-5em}(\app\,t\,u)^T\,&&\nu \text {   holds by   } t^T\,\nu \text{   and   } u^T\,\nu\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (\sigma : \Sub\,\Gamma\,\Delta)(\nu : \Sub\,\Omega\,\Gamma)\{A\}(x : \Var\,\Delta\,A)$}\\
  & \hspace{-3em}\rlap{$\to \Delta^T\,(\sigma \circ \nu)\,x = \sigma^A\,(\Gamma^T\,\nu)\,x$}\\
  & \hspace{-5em}\rlap{$ \sigma^T\,\nu\,x \defn (\sigma\,x)^T\,\nu$}
\end{alignat*}
Now we can define the term algebra for $\Omega$ itself:
\begin{alignat*}{3}
  & \TmAlg_{\Omega} : \Alg\,\Omega \\
  & \TmAlg_{\Omega} \defn \Omega^T\,\Omega\,\id
\end{alignat*}
\end{mydefinition}
\endgroup

In the interpretation for contexts, it is important that $\Omega$ is
fixed, and we do induction on all $\Gamma$ contexts such that there is a
$\Sub\,\Omega\,\Gamma$. It would not work to try to compute term algebras by
direct induction on contexts, because we need to refer to the same $\ms{T}$ set
in the interpretation of every type in a signature.

The interpretation of types embeds terms as $A$-algebras. At the base type
$\iota$, this embedding is simply the identity function, since $\iota^A\,\ms{T}
\equiv \ms{T} \equiv \Tm\,\Omega\,\iota$. At function types we recursively proceed
under a semantic $\lambda$. The interpretation of contexts is pointwise.

The interpretations of terms and substitutions are coherence properties, which
relate the term algebra construction to term evaluation in the $\blank^A$ model.
For terms, if we pick $\nu \equiv \id$, we get $A^T\,t =
t^A\,\TmAlg_{\Omega}$. The left side embeds $t$ in the term model via
$\blank^T$, while the right hand side evaluates $t$ in the term model.

A way to view the term algebra construction, is that we are working in a
\emph{slice model} over the fixed $\Omega$, and every $\nu :
\Sub\,\Omega\,\Gamma$ can be viewed as an internal $\Gamma$-algebra in this
model. The term algebra construction demonstrates that every such internal
algebra yields an external element of $\Gamma^A$.

%% We will
%% see in Section \ref{sec:fqiit-term-algebras} that we can construct term algebras
%% from \emph{any} model of a ToS, not just the ToS syntax; but while term algebras
%% constructed from ToS syntax are themselves initial algebras, in other cases they
%% may not be initial.

\subsection{Recursor Construction}
\label{sec:simple-weak-initiality}
We show that $\TmAlg_{\Omega}$ supports a recursion principle, i.e.\ it is weakly
initial.

\begin{mydefinition}[\textbf{Recursor construction}]\label{def:simple-recursor} We assume $(X,\,\omega) : \Alg\,\Omega$;
recall that $X : \Set$ and $\omega : \Omega^A\,X$. We define $\ms{R} : \ms{T} \to X$
as $\ms{R}\,t \equiv t^A\,\omega$. We additionally define the following.
\begin{alignat*}{3}
& \hspace{-6em}\rlap{$\blank^R : (A : \Ty)(t : \Tm\,\Omega\,A) \to A^M\,\ms{R}\,(A^T\,t)\,(t^A\,\omega)$}\\
& \hspace{-6em}\iota^R\,&&t \defn (\refl : t^A\,\omega = t^A\,\omega)\\
& \hspace{-6em}(\iota\to A)^R\,&&t \defn \lambda\,u.\,A^R\,(\app\,t\,u)
\end{alignat*}
\begin{alignat*}{3}
& \hspace{-10em}\rlap{$\blank^R : (\Gamma : \Con)(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)$}\\
& \hspace{-10em}\rlap{$\Gamma^R\,\nu\,x \defn A^R\,(\nu\,x)$}
\end{alignat*}
We define the recursor for $\Omega$ as
\begin{alignat*}{3}
  & \Rec_{\Omega} : (\mi{alg} : \Alg\,\Omega) \to \Mor\,\TmAlg_{\Omega}\,\mi{alg}\\
  & \Rec_{\Omega}\,(X,\,\omega) \defn (\ms{R},\,\Omega^R\,\Omega\,\id)
\end{alignat*}
\end{mydefinition}

In short, the way we get recursion is by evaluating terms in arbitrary
$(X,\,\omega)$ algebras using $\blank^A$. The $\blank^R$ operation for types and
contexts confirms that $\ms{R}$ preserves structure appropriately, so that
$\ms{R}$ indeed yields algebra morphisms.

We skip interpreting terms and substitutions by $\blank^R$. It is necessary to
do so with more general signatures, but not in the current chapter.

\subsection{Eliminator Construction}

We take the idea of the previous section a bit further. We have seen that
recursion for term algebras is given by evaluation in the ``standard'' model
$\blank^A$. Now, we show that induction for term algebras corresponds to
evaluation in the logical predicate model $\blank^D$.

\begin{mydefinition}[\textbf{Eliminator construction}]\label{def:simple-eliminator-construction}
We assume $(X^D,\,\omega^D) : \DispAlg\,\TmAlg_\Omega$. Recall that $X^D :
\ms{T} \to \Set$ and $\omega^D : \Omega^D\,X^D\,(\Omega^T\,\Omega\,\id)$. Like
before, we first interpret the underlying set:
\begin{alignat*}{3}
  & \ms{E} : (t : \ms{T}) \to X^D\,t \\
  & \ms{E}\,t \defn t^D\,\omega^D
\end{alignat*}
However, this definition is not immediately well-typed, since $t^D\,\omega^D$
has type $X^D\,(t^A\,(\Omega^T\,\Omega\,\id))$, so we have to show that
$t^A\,(\Omega^T\,\Omega\,\id) = t$. This equation says that nothing happens if
we evaluate a term with type $\iota$ in the term model. We get it from the
$\blank^T$ interpretation of terms: $t^T\,\id : t[\id] =
t^A\,(\Omega^T\,\Omega\,\id)$, and we also know that $t[\id] = t$. We interpret types
and contexts as well:
\begin{alignat*}{3}
  & \hspace{-8em}\rlap{$\blank^E : (A : \Ty)(t : \Tm\,\Omega\,A) \to A^S\,\ms{E}\,(t^A\,(\Omega^T\,\Omega\,\id))\,(t^D\,\omega^D)$}\\
  & \hspace{-8em}\iota^E\,&&t : (t^A\,(\Omega^T\,\Omega\,\id))^D\,\omega^D = t^D\,\omega^D\\
  & \hspace{-8em}(\iota\to A)^E\,&&t \defn \lambda\,u.\, A^E\,(\app\,t\,u)\\
  & \hspace{-8em}&& \\
  & \hspace{-8em}\rlap{$\blank^E : (\Gamma : \Con)(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^S\,\ms{E}\,(\nu^A\,(\Omega^T\,\Omega\,\id))\, (\nu^D\,\omega^D)$}\\
  & \hspace{-8em}\rlap{$\Gamma^E\,\nu\,x \defn A^E\,(\nu\,x)$}
\end{alignat*}
In $\iota^E$ we use the same equation as in the definition of $\ms{E}$. In
$(\iota\to A)^E$ the definition is well-typed because of the same equation, but
instantiated for the abstracted $u$ term this time. All of this amounts to some
additional path induction and transport fiddling in the (intensional) Agda
formalization. We get induction for $\Omega$ as below.
\begin{alignat*}{3}
  &\Ind_{\Omega} : (\mi{alg} : \DispAlg\,\TmAlg_\Omega) \to \Section\,\TmAlg_\Omega\,\mi{alg}\\
  &\Ind_{\Omega}\,(X^D,\,\omega^D) \defn (E,\, \Omega^E\,\Omega\,\id)
\end{alignat*}
\end{mydefinition}

\section{Discussion}

\subsection{Comparison to F-algebras}

A well-known alternative way for treating inductive types is to use certain
cocontinuous endofunctors as a more semantic notion of signatures.

For example, single-sorted inductive types can be presented as endofunctors
which preserve colimits of some ordinal-indexed chains. For instance, if we have
an $\kappa$-cocontinuous $F : \mbb{C} \to \mbb{C}$, then algebras are given as
$(X : |\mbb{C}|) \times (\mbb{C}(F\,X,\,X))$, morphisms as commuting squares,
and Adámek's theorem \cite{adamek} establishes the existence of initial
algebras.

An advantage of this approach is that we can describe different classes of
signatures by choosing different $\mbb{C}$ categories:
\begin{itemize}
  \item If $\mbb{C}$ is $\mbf{Set}$, we get simple inductive types.
  \item If $\mbb{C}$ is $\mbf{Set}^I$ for some set $I$, we get indexed inductive types.
  \item If $\mbb{C}$ is $\mbf{Set}/I$, we get inductive-recursive types.
\end{itemize}

Another advantage of $F$-algebras is that signatures are a fairly semantic
notion: they make sense even if we have no syntactic presentation at hand. That
said, often we do need syntactic signatures, for use in proof assistants, or
just to have a convenient notation for a class of cocontinuous functors.

An elegant way of carving out a large class of such functors is to
consider polynomials as signatures. For example, when working in \textbf{Set}, a
signature is an element of $(S : \Set) \times (P : S \to \Set)$, and $(S,\,P)$
is interpreted as a functor as $X \mapsto (s : S) \times (P\,s \to X)$. The
initial algebra is the W-type specified by $S$ shapes and $P$ positions. This
yields infinitary inductive types as well.

However, it is not known how to get \emph{inductive-inductive} signatures by
picking the right $\mbb{C}$ category and a functor. In an inductive-inductive
signature, there may be multiple sorts, which can be indexed over previously
declared sorts. For example, in the signature for categories we have $\Obj :
\Set$ and $\Mor : \Obj \to \Obj \to \Set$, indexed twice over $\Obj$. Some
extensions are required to the idea of $F$-algebras:
\begin{itemize}
\item
  For inductive-inductive definitions with two sorts, Forsberg gives a
  specification with two functors, and a considerably more complex notion of
  algebras, involving dialgebras \cite{forsberg-phd}\footnote{However, the
  dialgebra specification only covers restricted signatures, where $B : A \to
  \Set$ constructor types may refer to $A : \Set$ constructors, but no other
  dependency is allowed.  There is a more general and yet more complicated
  notion of signature in \cite{forsberg-phd}, which is not anymore represented
  with functors.}.
\item
  For an arbitrary number of sorts, Altenkirch et
  al.\ \cite{altenkirch18qiit} use a ``list'' of functors, specified mutually
  with categories of algebras: each functor has as domain the semantic category
  of all previous sorts.
\end{itemize}

The functors-as-signatures approach gets significantly less convenient as we
consider more general specifications. The approach of this thesis is the skip the
middle ground between syntactic signatures and semantic categories of algebras:
we treat syntactic signatures as a key component, and give direct semantic
interpretation for them. Although we lose the semantic nature of $F$-algebras,
our approach scales extremely well, all the way up to infinitary
quotient-inductive-inductive types in Chapter \ref{chap:iqiit}, and to some
extent to higher inductive-inductive types as well in Chapter \ref{chap:hiit}.

If we look back at $\blank^A : \Con \to \Set \to \Set$, we may note that
$\Gamma^A$ yields a functor, in fact the same functor (up to isomorphism) that
we would get from an $F$-algebra presentation. However, this is a coincidence in
the single-sorted case. With the $F$-algebra presentation, we can view $(X :
|\mbb{C}|) \times (\mbb{C}(F\,X,\,X))$ as specifying the category of algebras as
the total category of a displayed category (by viewing the $\Sigma$-type here as
taking total categories; a $\Sigma$ in $\mbf{Cat}$). In our approach, we aim to
get the displayed categories directly, without talking about functors.

\subsection{Generic Programming}
\label{sec:generic-programming}

Let's consider now our signatures and term algebras in the context of generic
programming. This is largely future work, and we don't elaborate it much. But we
can draw some preliminary conclusions and make some comparisons.

If a language can formalize inductive signatures and their semantics, that can
be viewed as an implementation of generic programming over the described types.
Compared to a purely mathematical motivation for this formalization, the
requirements for practical generic programming are a bit more stringent.
\begin{itemize}
  \item \emph{Encoding overhead}: there should be an acceptable overhead in
    program size and performance when using generic representations.  Size
    blowup can be an issue when writing proofs as well, when types and
    expressions become too large to mentally parse.
  \item \emph{Strictness properties}: generic representations should compute as
    much as possible, ideally in exactly the same way as their non-generic
    counterparts.
\end{itemize}

\subsubsection{Fixpoints of functors}
There is a sizable literature of using fixpoints of functors in generic
programming, mainly in Haskell \cite{alacarte,compdata,multirec} and Agda
\cite{loh11generic,allais20type}. We give a minimal example below for an
Agda-like implementation.

We have an inductive syntax for some strictly positive functors, covering essentially the
same signatures as $\Con$.
\begin{alignat*}{3}
  & \ms{Sig}                &&: \Set \\
  & \ms{Id}                 &&: \ms{Sig} \\
  & \ms{K\top}              &&: \ms{Sig} \\
  & \blank\!\otimes\!\blank &&: \ms{Sig} \to \ms{Sig} \to \ms{Sig} \\
  & \blank\!\oplus\!\blank  &&: \ms{Sig} \to \ms{Sig} \to \ms{Sig}
\end{alignat*}

$\ms{Id}$ codes the identity functor, and $\ms{K\top}$ codes the functor which
is constantly $\top$. $\blank\!\otimes\!\blank$ and $\blank\!\oplus\!\blank$ are
pointwise products and coproducts respectively. So we have the evident
interpretation functions:
\begin{alignat*}{3}
  & \llbracket\blank\rrbracket &&: \ms{Sig} \to \Set \to \Set\\
  & \ms{map} &&: (F : \ms{Sig}) \to (X_0 \to X_1) \to \llbracket F \rrbracket\,X_0 \to \llbracket F \rrbracket\,X_1
\end{alignat*}
In Haskell and Agda, the easiest way to get initial algebras is to directly define
the inductive fixpoint for each assumed $F : \ms{Sig}$:
\begin{alignat*}{3}
  & \ms{Fix_F} &&: \Set \\
  & \ms{con_F} &&: \llbracket F \rrbracket\,\ms{Fix_F} \to \ms{Fix_F}
\end{alignat*}
In Haskell, this definition is valid for arbitrary \emph{semantic} $F$ functor,
because there is no termination checking or positivity checking. In Agda, the
above definition is valid because the positivity checker is willing to look
inside the definition of $\llbracket\blank\rrbracket$. However, Coq and Lean
reject this definition. Next we establish weak initiality, by defining the
recursor:
\begin{alignat*}{3}
  & \ms{rec} : (\llbracket F \rrbracket\,X \to X) \to \ms{Fix_F} \to X \\
  & \ms{rec}\,f\,(\ms{con}\,x) \defn f\,(\ms{map}\,(\ms{rec}\,f)\,x)
\end{alignat*}
This is again fine in Haskell, but it unfortunately does not pass Agda's
termination checker. The most conservative solution is to inline the recursive
call into $\ms{map}$, so that the definition becomes transparent to termination
checking.
\begin{alignat*}{3}
  &\ms{rec} : (\llbracket F \rrbracket\,X \to X) \to \ms{Fix_F} \to X\\
  &\ms{rec}\,f\,(\ms{con}\,x) \defn f\,(\ms{maprec}\,f\,x)
\end{alignat*}
\begin{alignat*}{3}
  & \rlap{$\ms{maprec} : \{G\} \to (\llbracket F \rrbracket\,X \to X) \to \llbracket G \rrbracket\,\ms{Fix_F} \to \llbracket G \rrbracket\,X$}\\
  & \ms{maprec}\,\{\Id\}\,&&f\,x &&\defn \ms{rec}\,f\,x\\
  & \ms{maprec}\,\{\ms{K\top}\}\,&&f\,x &&\defn x\\
  & \ms{maprec}\,\{G \otimes H\}\,&&f\,(x,\,y) &&\defn  (\ms{maprec}\,f\,x,\,\ms{maprec}\,f\,y)\\
  & \ms{maprec}\,\{G \oplus H\}\,&&f\,(\ms{inj_1}\,x) &&\defn \ms{maprec}\,f\,x\\
  & \ms{maprec}\,\{G \oplus H\}\,&&f\,(\ms{inj_2}\,x) &&\defn \ms{maprec}\,f\,x
\end{alignat*}

Alternatively, we might use \emph{sized types} \cite{abel17normalization}, as
in \cite{allais20type}. The drawback is dependence on an additional
language feature which is only supported in Agda, and which has had several
soundness issues since its introduction \cite{TODO}.

There is yet another possible approach: defining initial algebras as sequential
colimits, using Adámek's theorem. This approach was taken by Ahrens, Matthes and
Mörtberg in \cite{ahrens19from}. However, the encoding overhead is excessive,
and it is practically unusable for generic programming. Another drawback is that
defining colimits requires quotient types, which are often not available
natively.

\subsubsection{W-types}
Given a polynomial $(S,\,P) : (S : \Set) \times (S \to \Set)$, the corresponding
W-type is inductively specified as below:
\begin{alignat*}{3}
  & \ms{W}_{S,\,P} &&: \Set \\
  & \ms{sup} &&: (s : S) \to (P\,s \to \ms{W}_{S,\,P}) \to \ms{W}_{S,\,P}
\end{alignat*}
If we assume $\top$, $\bot$, $\Bool$, $\Pi$, $\Sigma$, $\ms{W}$-types, universes
and an intensional identity type, a large class of inductive types can be
derived, including infinitary and finitary indexed inductive families; this
was shown by Hugunin \cite{whynotw}. The encoding also yields definitional
$\beta$-rules for recursion and elimination. However, there is also significant
encoding overhead here.
\begin{itemize}
  \item
    First, there is a translation from more convenient signatures to $(S,\,P)$ polynomials.
  \item Then, we take the $\ms{W}_{S\,P}$ type, but we need to additionally
    restrict it to the \emph{canonical} elements by a predicate, as in $(x :
    \ms{W}_{S\,P}) \times \ms{canonical}\,x$. This is required because the only
    way to represent inductive branching is by functions, but functions
    sometimes contain too many elements up to definitional equality. For
    example, $\bot \to A$ has infinitely many definitonally distinct
    inhabitants.
\end{itemize}
There is also a performance overhead imposed by the mandatory higher-order
constructors. W-types are a great way to have a small basis in a formal setting,
both in intensional and extensional type theories, but they are a bit too heavy
for practical purposes.

\subsubsection{Term algebras}
The main advantage of the term algebras described in this chapter is that they
can be defined using plain inductive families, which are available in every
major dependently typed language. Even in GHC Haskell, the support for
generalized ADTs is sufficient for implementing term algebras. In contrast, as
we have seen, the direct inductive definition of fixpoints is only possible in
Agda, while the colimit definition requires quotients and is rather
heavyweight. Even in Agda, the drawback of the direct fixpoint definition is
that many generic operations only pass termination checking after manual
inlining. With term algebras, generic operations can be defined by induction on
$\Tm\,\Gamma\,A$ in an obviously terminating way.

For practical usage it makes sense to slightly modify terms. We switch to a
\emph{spine neutral} definition. We mutually inductively define $\ms{Spine}$ and
$\Tm$:
\begin{alignat*}{3}
  & \ms{Spine} &&: (\Gamma : \Con) \to \Ty \to \Ty \to \Set \\
  & \epsilon &&: \{A\} \to \ms{Spine}\,\Gamma\,A\,A\\
  & \blank\!,\!\blank &&: \{B\,C\} \to \Tm\,\Gamma\,\iota \to \ms{Spine}\,\Gamma\,B\,C \to \ms{Spine}\,\Gamma\,(\iota\to B)\,C\\
  & \Tm  &&: \Con \to \Ty \to \Set \\
  & \blank\$\blank &&: \{A\,B\} \to \Var\,\Gamma\,A \to \ms{Spine}\,\Gamma\,A\,B \to \Tm\,\Gamma\,B
\end{alignat*}
With this representation, a term is always a variable applied to a list of
arguments. This can be useful, because pattern matching implementations in
metalanguages (e.g.\ Agda or Idris) are more likely to know about which
constructors are possible in patterns. Using this, we give here an ad-hoc
definition of natural numbers in pseudo-Agda.
\begin{alignat*}{3}
  &\Nat : \Set && \ms{zero} &&\defn \vz\,\$\,\epsilon\\
  &\Nat \defn \Tm\,(\emptycon\ext \iota\to \iota \ext \iota)\,\iota\hspace{2em} && \ms{suc}\,n &&\defn \vs\,\vz\,\$\,(n,\,\epsilon)
\end{alignat*}
\begin{alignat*}{3}
  &\hspace{-6.5em}\rlap{$\ms{NatElim} : (P : \Nat \to \Set) \to P\,\ms{zero}\to ((n : \Nat) \to P\,n \to P\,(\ms{suc}\,n))$}\\
  &\hspace{-6.5em}\rlap{$\hspace{4em}\to (n : \Nat) \to P\,n$}\\
  &\hspace{-6.5em}\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,(\vz\,\$\,\epsilon) &&\defn \ms{pz}\\
  &\hspace{-6.5em}\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,(\vs\,\vz\,\$\,(n,\,\epsilon)) &&\defn
    \ms{ps}\,n\,(\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,n)
\end{alignat*}
The actual Agda definition can be found in the supplementary formalization, and
it is pretty much the same as above. We recover the exact same behavior with
respect to pattern matching as with native inductive definitions.

$\Rec_\Omega$ and $\Ind_\Omega$ can be adapted to spine neutral terms with minor
adjustments. But what about the $\beta$-rules which they produce as part of
their output, are they definitional (i.e.\ proven by $\refl$)? In this chapter
we do not have a rigorous way of reasoning about definitional equalities; in the
next chapter we develop such reasoning and show that $\Rec_\Omega$ enjoys
definitional $\beta$-rules (with or without the spine neutral
definition).

However, $\Ind_\Omega$ only supports propositional $\beta$-rules. The issue is
the extra transporting in the definition of $\ms{E} : (t : \Tm\,\Omega\,\iota)
\to X^D\,t$: transports don't strictly commute with constructors. This appears
to be a point of advantage for the direct fixpoint definition in Agda, as it
allows generic elimination with strict computation rules \cite{TODO}.

The term algebra presentation can be easily extended to indexed families. In
that case, signatures and terms are still definable with basic inductive
families, without requiring quotients or complicated encodings; see Kaposi and
von Raumer \cite{mutualinductive}.

A related existing work is \emph{sum-of-products} generics by De Vries and Löh
\cite{sop}. There, signatures for functors are in a normal form: we cannot
freely take products and coproducts, instead a signature looks very much like a
$\Con$ in this chapter (except in an indexed form). The authors observe that
several generic programming patterns are easier to express with normalized
signatures. However, they still use explicit fixpoints as the way to get initial
algebras.

\chapter{Semantics in Two-Level Type Theory}
\label{chap:2ltt}

In this chapter we describe how two-level type theory is used as a metatheoretic
setting in the rest of this thesis. First, we provide motivation and
overview. Second, we describe models of type theories in general, and models of
two-level type theories as extensions. Third, we describe presheaf models of
two-level type theories. Finally, we generalize the semantics and the term
algebra construction from Chapter \ref{chap:simple-inductive-signatures} in
two-level type theory, as a way to illustrate the applications.

\section{Motivation}
\label{sec:2ltt-motivation}
We note two shortcomings of the semantics presented in the
previous chapter.

First, the semantics that we provided was not as general as it could be. We
used the internal $\Set$ universe to specify algebras, but algebras make sense
in many different categories. A crude way to generalize semantics is to simply
say that our formalization, which was carried out in the syntax (i.e.\ initial
model) of some intensional type theory, can be interpreted in any model of the
type theory. However, this is wasteful: for simple inductive signatures, it is
enough to assume a category with finite products as semantic setting. We don't
need all the extra baggage that comes with a model of a type theory.

Second, we were not able to reason about definitional equalities, only
propositional ones. We have a formalization of signatures and semantics in
intensional Agda, where the two notions differ\footnote{As opposed to in
extensional type theory, where they're the same.}, but only propositional
equality is subject to internal reasoning. For instance, we would like to show
that term algebras support recursion with strict $\beta$-rules, and for this we
need to reason about strict equality.

\begin{notation}
We use $\emptycon$ for the terminal object in a $\mbb{C}$ category, with
$\epsilon : \mbb{C}(A,\,\emptycon)$ for the unique morphism. For products, we
use $\blank\!\otimes\!\blank$ with $(\blank\!,\!\blank) : \mbb{C}(A,\,B) \to
\mbb{C}(A,\,C) \to \mbb{C}(A,\,B\otimes C)$ and $\p$ and $\q$ for
first and second projections respectively.
\end{notation}

\begin{myexample}
Assuming $\mbbC$ has finite products, natural number algebras and binary tree
algebras are specified as follows.
\begin{alignat*}{3}
  &\Alg_{\ms{NatSig}} &&\defn (X : |\mbbC|) \times \mbbC(\emptycon,\,X) \times \mbbC(X,\,X)\\
  &\Alg_{\ms{TreeSig}}&& \defn (X : |\mbbC|) \times \mbbC(\emptycon,\,X) \times \mbbC(X \otimes X,\,X)
\end{alignat*}
\end{myexample}
Here, $\Alg_{\ms{NatSig}}$ and $\Alg_{\ms{TreeSig}}$ are both sets in some
metatheory, and the $\times$ in the definitions refer to the metatheoretic
$\Sigma$. Algebras can be viewed as diagrams which preserve finite products, and
algebra morphisms are natural transformations.

How should we adjust $\Alg$ to compute algebras in $\mbbC$, and $\Mor$ to
compute their morphisms? While it is possible to do this in a direct fashion,
working directly with objects and morphisms of $\mbbC$ is rather unwieldy. $\mbbC$ is
missing many convenience features of type theories.
\begin{itemize}
\item There are no variables or binders. We are forced to work in a point-free
  style or chase diagrams; both become difficult to write and read after a
  certain point of complexity.
\item
  There are no functions, universes or inductive types.
\item
  Substitution (with weakening as a special case) has to be handled explicitly
  and manually. Substitutions are certain morphisms, while ``terms'' are also
  morphisms, and we have to use composition to substitute terms. In contrast, if
  we are working internally in a type theory, terms and substitutions are
  distinct, and we only have to explicitly deal with terms, and substitutions
  are automated and implicit.
\end{itemize}

The above overlaps with motivations for working in \emph{internal languages}
\cite{internallogic} of structured categories: they aid calculation and compact
formalization by hiding bureaucratic structural details.

A finite product category $\mbbC$ does not have much of an internal language, it
is too bare-bones. But we can work instead in the internal language of
$\hat\mbbC$, the category of presheaves over $\mbbC$. This allows faithful
reasoning about $\mbbC$, while also including all convenience features of
extensional type theory.

\emph{Two-level type theories} \cite{twolevel}, or 2LTT in short, are type
theories such that they have ``standard'' interpretations in presheaf
categories. A 2LTT has an inner layer, where types and terms arise by embedding
$\mbbC$ in $\hat{\mbbC}$, and an outer layer, where constructions are inherited
from $\hat{\mbbC}$. The exact details of the syntax may vary depending on what
structures $\mbbC$ supports, and which type formers we assume in the outer
layer. Although it is possible to add assumptions to a 2LTT which preclude
standard presheaf semantics \cite[Section 2.4.]{twolevel}, we stick to basic
2LTT in this thesis. By using 2LTT, we are able to use a type-theoretic syntax
which differs only modestly from the style of definitions that we have seen so
far.

From a programming perspective, basic 2LTT provides a convenient syntax for
writing metaprograms. This can be viewed as \emph{two-stage compilation}: if we
have a 2LTT program with an inner type, we can run it, and it returns another
program, which lives purely in the inner theory.

\section{Models of Type Theories}
\label{sec:models-of-tts}

Before explaining 2LTT-specific features, we review models of type theories
in general. Variants of 2LTT will be obtained by adding extra features on the
top of more conventional TTs.

It is also worth to take a more general look at models at this point, because
the notions presented in this subsection (categories with families, type
formers) will be reused several times in this thesis, when specifying theories
of signatures.

\subsection{The Algebraic View}

We take an algebraic view \cite{TODO} of models and syntaxes of type theories throughout
this thesis. Models of type theories are algebraic structures: they are
categories with certain extra structure. The syntax of a type theory is
understood to be its initial model. In initial models, the underlying category
is the category of typing contexts and parallel substitutions, while the extra
structure corresponds to type and term formers, and equations quotient the
syntax by definitional equality.

Type theories can be described with quotient inductive-inductive (QII)
signatures, and their initial models are quotient inductive-inductive types
(QIITs). Hence, 2LTT is also a QII theory. We will first talk about QIITs in
Chapter \ref{chap:fqiit}. Until then, we shall make do with an informal
understanding of categorical semantics for type theories, without using anything
in particular from the metatheory of QIITs. There is some circularity here, that
we talk about QIITs in this thesis, but we employ QIITs when talking about
them. However, this is only an annoyance in exposition and not a fundamental
issue: Chapter \ref{chap:levitation} describes how to eliminate circularity by a
form of bootstrapping.

The algebraic view lets us dispense with all kinds of ``raw'' syntactic objects.
We only ever talk about well-typed and well-formed objects, moreover, every
construction must respect definitional equalities. For terms in the algebraic
syntax, definitional equality coincides with metatheoretic equality. This
mirrors equality of morphisms in 1-category theory, where we usually reuse
metatheoretic equality in the same way.

In the following we specify notions of models for type theories. We split this
in two parts: categories with families and type formers.

\subsection{Categories With Families}

\begin{mydefinition}
A \textbf{category with family} (cwf) \cite{Dybjer96internaltype} is a way to
specify the basic structural rules for contexts, substitutions, types and
terms. It yields a dependently typed explicit substitution calculus \cite{TODO}.
A cwf consists of the following.
\begin{itemize}
\item
  A category with a terminal object. We denote the set of objects as $\Con :
  \Set$ and use capital Greek letters starting from $\Gamma$ to refer to
  objects. The set of morphisms is $\Sub : \Con \to \Con \to \Set$, and we use
  $\sigma$, $\delta$ and so on to refer to morphisms. We write $\id$ for the
  identity morphism and $\blank\circ\blank$ for composition. The terminal
  object is $\emptycon$ with unique morphism $\epsilon :
  \Sub\,\Gamma\,\emptycon$. In initial models (that is, syntaxes) of type
  theories, objects correspond to typing contexts, morphisms to parallel
  substitutions and the terminal object to the empty context; this informs the
  naming scheme.
\item A \emph{family structure}, containing $\Ty : \Con \to \Set$ and $\Tm :
  (\Gamma : \Con) \to \Ty\,\Gamma \to \Set$. We use $A$, $B$, $C$ to refer to
  types and $t$, $u$, $v$ to refer to terms. $\Ty$ is a presheaf over the
  category of contexts and $\Tm$ is a displayed presheaf over $\Ty$. This means
  that types and terms can be substituted:
  \begin{alignat*}{3}
    &\blank[\blank] : \Ty\,\Delta \to \Sub\,\Gamma\,\Delta \to \Ty\,\Gamma\\
    &\blank[\blank] : \Tm\,\Delta\,A \to (\sigma : \Sub\,\Gamma\,\Delta) \to \Tm\,\Gamma\,(A[\sigma])
  \end{alignat*}
  Substitution is functorial: we have $A[\id] = A$ and
  $A[\sigma\circ\delta] = A[\sigma][\delta]$, and likewise for terms.

  A family structure is additionally equipped with \emph{context comprehension}
  which consists of a context extension operation $\blank\ext\blank : (\Gamma :
  \Con) \to \Ty\,\Gamma \to \Con$ together with an isomorphism
  $\Sub\,\Gamma\,(\Delta\ext A) \simeq ((\sigma : \Sub\,\Gamma\,\Delta) \times
  \Tm\,\Gamma\,(A[\sigma]))$ which is natural in $\Gamma$.
\end{itemize}
\end{mydefinition}

The following notions are derivable from the comprehension structure:
\begin{itemize}
\item
  By going right-to-left along the isomorphism, we recover \emph{substitution
  extension} $\blank,\blank : (\sigma : \Sub\,\Gamma\,\Delta) \to
  \Tm\,\Gamma\,(A[\sigma]) \to \Sub\,\Gamma\,(\Delta\ext A)$. This means that
  starting from $\epsilon$ or the identity substitution $\id$, we can iterate
  $\blank,\blank$ to build substitutions as lists of terms.
\item
  By going left-to-right, and starting from $\id : \Sub\,(\Gamma\ext
  A)\,(\Gamma\ext A)$, we recover the \emph{weakening substitution} $\p :
  \Sub\,(\Gamma\ext A)\,\Gamma$ and the \emph{zero variable} $\q :
  \Tm\,(\Gamma\ext A)\,(A[\p])$.
\item
  By weakening $\q$, we recover a notion of variables as De Bruijn indices. In
  general, the $n$-th De Bruijn index is defined as $\q[\p^{n}]$, where $\p^{n}$
  denotes $n$-fold composition.
\end{itemize}

Comprehension can be characterized either by taking $\blank,\blank$, $\p$ and
$\q$ as primitive, or the natural isomorphism. The two are equivalent, and we
may switch between them, depending on which is more convenient.

There are other ways for presenting the basic categorical structure of models,
which are nonetheless equivalent to cwfs, including natural models
\cite{awodey18natural} and categories with attributes \cite{cartmellthesis}. We
use the cwf presentation for its immediately algebraic character and closeness
to conventional explicit substitution syntax.

\begin{notation}As De Bruijn indices are hard to read, we will mostly use
nameful notation for binders. For example, assuming $\Nat : \{\Gamma : \Con\}
\to \Ty\,\Gamma$ and $\Id : \{\Gamma : \Con\}(A : \Ty\,\Gamma) \to
\Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma$, we may write $\emptycon \ext
n : \Nat \ext p : \Id\,\Nat\,n\,n$ for a typing context, instead of using
numbered variables or cwf combinators as in $\emptycon \ext \Nat \ext
\Id\,\Nat\,\q\,\q$.
\end{notation}

\begin{notation}
In the following, we will denote family structures by ($\Ty$,$\Tm$) pairs and overload context
extension $\blank\ext\blank$ for different families.
\end{notation}

\begin{mydefinition} The following derivable operations are commonly used.
\label{def:cwfops}
  \begin{itemize}
    \item \emph{Single substitution} can be derived from parallel substitution
      as follows. Assume $t : \Tm\,(\Gamma\ext A)\,B$, and $u :
      \Tm\,\Gamma\,A$. $t$ is a term which may depend on the last variable in
      the context, which has $A$ type. We can substitute that variable with the
      $u$ term as $t[\id,\,u] : \Tm\,\Gamma\,(\A[\id,\,u])$. Note that term
      substitution causes the type to be substituted as well. $(\id,\,u) :
      \Sub\,\Gamma\,(\Gamma\ext A)$ is well-typed because $u : \Tm\,\Gamma\,A$
      hence also $u : \Tm\,\Gamma\,(A[\id])$.

    \item We can \emph{lift substitutions} over binders as follows. Assuming
      $\sigma : \Sub\,\Gamma\,\Delta$ and $A : \Ty\,\Delta$, we construct a
      lifting of $\sigma$ which maps an additional $A$-variable to itself:
      $(\sigma\circ\p,\,\q) : \Sub\,(\Gamma\ext A[\sigma])\,(\Delta \ext A)$.
      Let us see why this is well-typed. We have $\p : \Sub\,(\Gamma\ext
      A[\sigma])\,\Gamma$ and $\sigma : \Sub\,\Gamma\,\Delta$, so $\sigma \circ
      \p : \Sub\,(\Gamma\ext A[\sigma])\,\Delta$. Also, $\q : \Tm\,(\Gamma\ext
      A[\sigma])\,(A[\sigma][\p])$, hence $\q : \Tm\,(\Gamma\ext
      A[\sigma])\,(A[\sigma \circ \p])$, thus $(\sigma\circ \p,\,\q)$
      typechecks.
  \end{itemize}
\end{mydefinition}

\begin{notation}

As a nameful notation for substitutions, we may write $t[x \mapsto u]$, for
a single substitution, or $t[x \mapsto u_1, y \mapsto u_2]$ and so on.

In nameful notation we leave all weakening implicit, including substitution
lifting. Formally, if we have $t : \Tm\,\Gamma\,A$, we can only mention $t$ in
$\Gamma$. If we need to mention it in $\Gamma \ext B$, we need to use $t[\p]$
instead. In the nameful notation, $t : \Tm\,(\Gamma\ext x : B)\,A$ may be
used.\footnote{Moreover, when working in the internal syntax of a theory, we
just write Agda-like type-theoretic notation, without noting contexts and
substitutions in any way.}
\end{notation}

\subsection{Type formers}
A family structure in a cwf may be closed under certain type formers, such as
functions, $\Sigma$-types, universes or inductive types. We give some examples
here for their specification. First, we look at common negative type formers,
which can be specified using isomorphisms. Then, we consider positive type
formers, and finally universes.

\subsubsection{Negative types}

\begin{mydefinition}
A $(\Ty,\,\Tm)$ family supports \textbf{$\Pi$-types} if it supports the following.
\begin{alignat*}{3}
  &\Pi           &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  &\ms{\Pi[]}    &&: (\Pi\,A\,B)[\sigma] = \Pi\,(A[\sigma])\,(B[\sigma\circ\p,\,\q])\\
  &\app          &&: \Tm\,\Gamma\,(\Pi\,A\,B) \to \Tm\,(\Gamma \ext A)\,B\\
  &\lam          &&: \Tm\,(\Gamma \ext A)\,B \to \Tm\,\Gamma\,(\Pi\,A\,B)\\
  &\Pi\beta      &&: \app\,(\lam\,t) = t\\
  &\Pi\eta       &&: \lam\,(\app\,t) = t\\
  &\lam[]        &&: (\lam\,t)[\sigma] = \lam\,(t[\sigma\circ\p,\,\q])
\end{alignat*}
Here, $\Pi$ is the type formation rule. $\ms{\Pi[]}$ is the type substitution
rule, expressing that substituting $\Pi$ proceeds structurally on constituent
types.  Note $B[\sigma\circ\p,\,\q]$, where we lift $\sigma$ over the additional
binder.

The rest of the rules specify a natural isomorphism $\Tm\,\Gamma\,(\Pi\,A\,B)
\simeq \Tm\,(\Gamma \ext A)\,B$. We only need a substitution rule (i.e.\ a
naturality rule) for one direction of the isomorphism, since the naturality of
the other map is derivable.

This way of specifying $\Pi$-types is very convenient if we have explicit
substitutions. The usual ``pointful'' specification is equivalent to this. For
example, we have the following derivation of pointful application:
\begin{alignat*}{3}
  &\app' : \Tm\,\Gamma\,(\Pi\,A\,B) \to (u : \Tm\,\Gamma\,A) \to \Tm\,\Gamma\,(B[\id,\,u])\\
  &\app'\,t\,u \defn (\app\,t)[\id,\,u]
\end{alignat*}

\end{mydefinition}

\textbf{Remark on naturality.} The above specification for $\Pi$ can be written
more compactly if we assume that everything is natural with respect to
substitution.
\begin{alignat*}{3}
  &\Pi            &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  & (\app,\,\lam) &&: \Tm\,\Gamma\,(\Pi\,A\,B) \simeq \Tm\,(\Gamma \ext A)\,B
\end{alignat*}
This is a reasonable assumption; in the rest of the thesis we only ever define
structures on cwfs which are natural in this way.

\begin{notation} From now on, when specifying type formers in family structures,
we assume that everything is natural, and thus omit substitution equations.
\end{notation}

There are ways to make this idea more precise, and take it a step further by
working in languages where only natural constructions are possible. The term
\emph{higher-order abstract syntax} (HOAS) is sometimes used for this style. It lets us
also omit contexts, so we would only need to write
\begin{alignat*}{3}
  &\Pi            &&: (A : \Ty) \to (\Tm\,A \to \Ty) \to \Ty\\
  & (\app,\,\lam) &&: \Tm\,(\Pi\,A\,B) \simeq ((a : \Tm\,A) \to \Tm\,(B\,a))
\end{alignat*}
Recently several promising works emerged in this area \cite{TODO}. Although this
technology is likely to be the preferred future direction in the metatheory of
type theories, this thesis does not make use of it. The field is rather fresh,
with several different approaches and limited amount of pedagogical exposition,
and the new techniques would also raise the level of abstraction in this thesis,
all contributing to making it less accessible. It's also not obvious how exactly
HOAS-style could be employed to aid formalization here, and it would require
significant additional research.  Often, a setup with multiple modalities
(``multimodal'' \cite{gratzer20multimodal}) is required
\cite{bocquet2021induction}, because we work with presheaves over different
cwfs. It seems that a synthetic notion of dependent modes would be also
required to formalize constructions in this thesis, since we often work with
displayed presheaves over displayed cwfs. This is however not yet developed in
literature.

\begin{mydefinition}
\label{def:constant-families}
A family structure supports \textbf{constant families} if we have the following.
\begin{alignat*}{3}
  & \K &&: \Con \to \{\Gamma : \Con \} \to \Ty\,\Gamma \\
  & (\appK,\,\lamK) &&: \Tm\,\Gamma\,(\K\,\Delta) \simeq \Sub\,\Gamma\,\Delta
\end{alignat*}
Constant families express that every context can be viewed as a non-dependent
type in any context. Having constant families is equivalent to the
\emph{democracy} property for a cwf
\cite{clairambault2014biequivalence,forsberg-phd}.  Constant families are
convenient when building models, because they let us model non-dependent types
as semantic contexts, which are often simpler structures than semantic types.
From a programming perspective, constant families specify closed record types,
where $\K\,\Delta$ has $\Delta$-many fields.

If we have equalities of sets for the specification,
i.e.\ $\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$, we have \textbf{strict
  constant families}.

\end{mydefinition}

\begin{mydefinition}
A family structure supports \textbf{$\Sigma$-types} if we have
\begin{alignat*}{3}
  & \Sigma  &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  & (\proj,\,(\blank,\blank)) &&: \Tm\,\Gamma\,(\Sigma\,A\,B) \simeq ((t : \Tm\,\Gamma\,A) \times \Tm\,\Gamma\,(B[\id,\,t]))
\end{alignat*}
We use the shorter specification above, where everything is assumed to be
natural. We may write $\proj_1$ and $\proj_2$ for composing the metatheoretic
first and second projections with $\proj$.
\end{mydefinition}

\begin{mydefinition}
A family structure supports the \textbf{unit type} if we have $\top : \Ty\,\Gamma$ such
that $\Tm\,\Gamma\,\top \simeq \top$, where the $\top$ on the right is the
metatheoretic unit type, and we overload $\top$ for the internal unit type.
From this, we get the internal $\tt : \Tm\,\Gamma\,\top$, which is
definitionally unique.
\end{mydefinition}

\begin{mydefinition}
A family structure supports \textbf{extensional identity} types if there is $\Id
: \Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma$ such that
$(\reflect,\,\refl) : \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t = u)$.
\end{mydefinition}

It is also possible to give a positive definition for identity types, in which
case we get intensional identity. Extensional identity corresponds to a
categorical equalizer of terms (a limit), while the Martin-Löf-style intensional
identity is characterized as the initial reflexive relation on a type (a
colimit).

This choice between negative and positive specification generally exists for
type formers with a single term construction rule. For example, $\Sigma$ can be
defined as a positive type, with an elimination rule that behaves like pattern
matching. Positive $\Sigma$ is equivalent to negative $\Sigma$, although it only
supports propositional $\eta$-rules. In contrast, positive identity is usually
\emph{not} equivalent to negative identity.

$\refl : t = u \to \Tm\,\Gamma\,(\Id\,t\,u)$ expresses reflexivity of identity:
definitionally equal terms are provably equal. $\reflect$, which goes the other
way around, is called \emph{equality reflection} \cite{TODO}: provably equal
terms are identified in the metatheory.

Uniqueness of identity proofs (UIP) is often ascribed to the extensional
identity type \cite{TODO}. UIP means that $\Tm\,\Gamma\,(\Id\,t\,u)$ has at most
a single inhabitant up to $\Id$. However, UIP is not something which is inherent
in the negative specification, instead it's inherited from the metatheory. If
$\Tm$ forms a homotopy set in the metatheory, then internal equality proofs
inherit uniqueness through the defining isomorphism.

\subsubsection{Positive types}

We do not dwell much on positive types here, as elsewhere in this thesis we talk
a lot about specifying such types anyway. We provide here some background and
a small example.

The motivation is to specify initial internal algebras in a cwf. However,
specifying the uniqueness of recursors using definitional equality is
problematic, if we are to have decidable and efficient conversion checking for a
type theory. Consider the specification of $\Bool$ together with its recursor.
\begin{alignat*}{3}
  & \Bool  &&: \Ty\,\Gamma \\
  & \true  &&: \Tm\,\Gamma\,\Bool \\
  & \false &&: \Tm\,\Gamma\,\Bool \\
  & \ms{BoolRec} &&: (B : \Ty\,\Gamma)\to \Tm\,\Gamma\,B \to \Tm\,\Gamma\,B \to \Tm\,\Gamma\,\Bool \to \Tm\,\Gamma\,B\\
  & \true\beta &&: \ms{BoolRec}\,B\,t\,f\,\true = t\\
  & \false\beta &&: \ms{BoolRec}\,B\,t\,f\,\false = f
\end{alignat*}
$\ms{BoolRec}$ together with the $\beta$-rules specifies an internal
$\Bool$-algebra morphism. A possible way to specify definitional uniqueness is
as follows. Assuming $B : \Ty\,\Gamma$, $t : \Tm\,\Gamma\,B$, $f :
\Tm\,\Gamma\,B$ and $m : \Tm\,(\Gamma\ext b : \Bool)\,B$, such that $m[b \mapsto
  \true] = t$ and $m[b \mapsto \false] = f$, it follows that
$\ms{BoolRec}\,B\,t\,f\,b : \Tm\,(\Gamma\ext b : \Bool)\,B$ is equal to $m$.

Unfortunately, deciding conversion with this rule entails deciding pointwise
equality of arbitrary $\Bool$ functions, which can be done in exponential time
in the number of $\Bool$ arguments. More generally, Scherer presented a decision
algorithm for conversion checking with strong finite sums and products in simple
type theory \cite{scherer17deciding}, which also takes exponential time. If we
move to natural numbers with definitionally unique recursion, conversion
checking becomes undecidable.

One solution is to have propositionally unique recursion instead. However, if
such equations are postulated, that would break the canonicity property in
intensional type theories, since now we would have equality proofs other than
$\refl$ in the empty context.

The standard solution is to have dependent elimination principles instead: this
allows inductive reasoning, canonicity and effectively decidable definitional
equality at the same time. For $\Bool$, we would have
\begin{alignat*}{3}
  & \ms{BoolInd} &&: (B : \Ty\,(\Gamma\ext b : \Bool)) \to \Tm\,\Gamma\,(B[b \mapsto \true])\\
  & &&\to \Tm\,\Gamma\,(B[b \mapsto \false]) \to (t : \Tm\,\Gamma\,\Bool) \to \Tm\,\Gamma\,(B[b \mapsto t])
\end{alignat*}
together with $\ms{BoolInd}\,B\,t\,f\,\true = t$ and $\ms{BoolInd}\,B\,t\,f\,\false = f$.

Of course, if we assume extensional identity types, we have undecidable
conversion anyway, and definitionally unique recursion is equivalent to
induction. But decidable conversion is an essential part of type theory, perhaps
its main selling point as a foundation for mechanized mathematics, which makes
it possible to relegate a deluge of boilerplate to computers. Hence, decidable
conversion should be kept in mind.

\subsubsection{Universes}

Universes are types which classify types. There are several different flavors of
universes.

\begin{mydefinition} A \textbf{Tarski-style} universe consists of
the following data:
\begin{alignat*}{3}
  & \U : \Ty\,\Gamma\hspace{2em}\El : \Tm\,\Gamma\,\U \to \Ty\,\Gamma
\end{alignat*}
\end{mydefinition}
This is a weak classifier, since not all $\Ty\,\Gamma$ are necessarily
represented as terms of the universe. Rather, this kind of universe can be
viewed as an internal sub-family of $(\Ty,\,\Tm)$. Like families, Tarski
universes can be closed under type formers. For instance, if $\U$ has $\Nat$,
we have the following:
\begin{alignat*}{3}
  &\Nat : \Tm\,\Gamma\,\U
    \hspace{1em}\mi{zero} : \Tm\,\Gamma\,(\El\,\Nat)
    \hspace{1em}\mi{suc} : \Tm\,\Gamma\,(\El\,\Nat) \to \Tm\,\Gamma\,(\El\,\Nat)
\end{alignat*}
\vspace{-2em}
\begin{alignat*}{3}
  \ms{NatElim} &:\,\,\,(P : \Ty\,(\Gamma\ext n : \El\,\Nat))\\
  &\to \Tm\,\Gamma\,(P[n \mapsto \mi{zero}])\\
  &\to \Tm\,(\Gamma\ext n : \El\,\Nat \ext \mi{np} : P[n \mapsto n])\,(P[n \mapsto \mi{suc}\,n]) \\
  &\to (n : \Tm\,\Gamma\,(\El\,\Nat)) \to \Tm\,\Gamma\,(P[n \mapsto n])
\end{alignat*}
If all type formers in $\U$ follow this scheme, $\U$ may be called a
\textbf{weakly Tarski} universe. If we assume that every type former in $\U$ is
also duplicated in $(\Ty,\,\Tm)$, moreover $\El$ preserves all type formers, so
that e.g.\ $\El\,\Nat$ is definitionally equal to the natural number type in
$\Ty$, then $\U$ is \textbf{strongly Tarski}.

It is often more convenient to have stronger classifiers as universes, so that
\emph{all} types in a given family structure are represented.

\begin{mydefinition}
Ignoring size issues for now, \textbf{Coquand universes} \cite{TODO} are
specified as follows:
\[
  \U : \Ty\,\Gamma\hspace{1em} (\El,\,\ms{c}) : \Tm\,\Gamma\,\U \simeq \Ty\,\Gamma
\]
$\ms{c}$ maps every type in $\Ty$ to a code in $\U$. Now we can ignore $\El$
when specifying type formers, as $\ms{c}$ can be always used to get a code in
$\U$ for a type.
\end{mydefinition}

Unfortunately, the exact specification above yields an inconsistent
``type-in-type'' system, because $\U$ itself has a code in $\U$. The standard
solution is to have multiple family structures $(\Ty_i,\,\Tm_i)$, indexed by
universe levels, and have $\U_i : \Ty_{i + 1}\,\Gamma$ and
$\Tm_{i+1}\,\Gamma\,\U_i \simeq \Ty_i\,\Gamma$. For a general specification of
consistent universe hierarchies, see \cite{kovacs2021generalized}. As mentioned in Section
\ref{sec:universes}, we omit universe indices in the following, and implicitly
assume ``just enough'' universes for particular purposes.

\begin{mydefinition}
\textbf{Russell universes} are Coquand universes additionally satisfying
$\Tm\,\Gamma\,\U = \Ty\,\Gamma$ as an equality of sets, and also $\ms{El}\,t =
t$. This justifies omitting $\El$ and $\ms{c}$ from informal notation,
implicitly casting between $\Tm\,\Gamma\,\U$ and $\Ty\,\Gamma$.
\end{mydefinition}
Russell-style universes are commonly supported in set-theoretic models. They are
also often inherited from meta-type-theories which themselves have
Russell-universes. Major implementations of type theories (Coq, Lean, Agda,
Idris) are all such.


\section{Two-Level Type Theory}

\subsection{Models}

We describe models of 2LTT in the following. This is not the only possible way
to present 2LTT; our approach differs from \cite{twolevel} in some ways. We will summarize
the differences at the end of this section.

\begin{mydefinition}
A model of a \textbf{two-level type theory} is a model of type theory such that
\begin{itemize}
  \item It supports a Tarski-style universe $\Ty_0 : \Ty\,\Gamma$ with decoding $\Tm_0 :
    \Tm\,\Gamma\,\Ty_0 \to \Ty\,\Gamma$.
  \item $\Ty_0$ may be closed under arbitrary type formers, however, it is only possible
    to eliminate from $\Ty_0$ type formers to types in $\Ty_0$.
\end{itemize}
Types in $\Ty_0$ are called \emph{inner} types, while other types are \emph{outer}. Alternatively,
we may talk about \emph{object-level} and \emph{meta-level} types.
\end{mydefinition}

For example, if we have inner functions, we have the following:
\begin{alignat*}{3}
  &\Pi_0 &&: (A : \Tm\,\Gamma\,\Ty_0) \to \Tm\,(\Gamma \ext \Tm_0\,A) \to \Tm\,\Gamma\,\Ty_0\\
  &(\app_0,\,\lam_0) &&: \Tm\,\Gamma\,(\Tm_0\,(\Pi_0\,A\,B)) \simeq \Tm\,(\Gamma \ext \Tm_0\,A)\,(\Tm_0\,B)
\end{alignat*}
If we have inner Booleans, we have the following (with $\beta$-rules omitted):
\begin{alignat*}{3}
  &\Bool_0 &&: \Tm\,\Gamma\,\Ty_0\\
  &\true_0 &&: \Tm\,\Gamma\,(\Tm_0\,\Bool_0)\\
  &\false_0 &&: \Tm\,\Gamma\,(\Tm_0\,\Bool_0)\\
  & \ms{BoolInd_0} &&: (B : \Tm\,(\Gamma\ext b : \Tm_0\,\Bool_0)\,\Ty_0)\\
  & && \to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto \true_0]))\\
  & &&\to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto \false_0]))\\
  & && \to (t : \Tm\,\Gamma\,(\Tm_0\,\Bool_0)) \to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto t]))
\end{alignat*}

Intuitively, we can view outer types and terms as metatheoretical, while $\Ty_0$
represents the set of types in the object theory, and $\Tm_0$ witnesses that any
object type can be mapped to a metatheoretical set of object terms. The
restriction on elimination is crucial. If we have a Boolean term in the object
language, we can use the object-level elimination principle to construct new
object terms. But it makes no sense to eliminate into the metatheory. In fact,
an object-level Boolean term is not necessarily $\true$ or $\false$, it can also
be just a variable or neutral term in some context, or it can be an arbitrary
non-canonical value in a given model.

We review some properties of 2LTT. An important point is the action of $\Tm_0$
on type formers. In general, $\Tm_0$ preserves the negative type formers but not
others.

For example, we have the isomorphism $\Tm_0\,(\Pi_0\,A\,B) \simeq
\Pi_1\,(\Tm_0\,A)\,(\Tm_0\,B)$, where $\Pi_1$ denotes outer functions.  We move
left-to-right by mapping $t$ to $\lam_1\,(\app_1\,t)$, and the other way by
mapping $t$ to $\lam_0\,(\app_0\,t)$. The preservation of $\Sigma$, $\top$, $\K$
and extensional identity is analogous.

In contrast, we can map from outer positive types to inner ones, but not the
other way around. From $b : \Tm\,\Gamma\,\Bool_1$, we can use the outer
$\Bool_1$ recursor to return in $\Tm_0\,\Bool_0$. In the other direction, we
only have constant functions since the $\Bool_0$ recursor only targets types in
$\Ty_0$.

It may be the case that there are universes in the inner layer. For example,
disregarding size issues (or just accepting an inconsistent inner theory), there
may be an $\U_0$ in $\Ty_0$ such that we have $\Tm\,\Gamma\,(\Tm_0\,\U_0) =
\Tm\,\Gamma\,\Ty_0$. This amounts to having a Russell-style inner universe with
type-in-type. Assume that we have $\U_1$ as well, as a meta-level Russell
universe. Then we can map from $\Tm_0\,\U_0$ to $\U_1$, by taking $A$ to
$\Tm_0\,A$, but we cannot map in the other direction.

\subsection{Internal Syntax and Notation}
\label{sec:2ltt-internal-syntax}

In the rest of this thesis we will mostly work internally to a 2LTT, i.e.\ we
use 2LTT as metatheory. We adapt the metatheoretical notations used up until
now. We list used features and conventions below.

\begin{itemize}
  \item
    We keep previous notation for type formers. For instance, $\Pi$-types are
    written as $(x : A) \to B$ or as $A \to B$.
  \item
    We assume a Coquand-style universe in the outer layer, named $\Set$. As
    before, we leave the sizing levels implicit; if we were fully precise, we
    would write $\Set_i$ for a hierarchy of outer universes. Despite having a
    Coquand universe, we shall omit encoding and decoding in the internal
    syntax, and instead work in Russell-style. In practical implementations,
    elaborating Russell-style notation to Coquand-style is straightforward to
    do.
  \item
    If the same type formers are supported both in the inner and outer layers, we
    may distinguish them by $_0$ and $_1$ subscripts, e.g.\ by having $\Bool_0$ and
    $\Bool_1$. We omit some inferable subscripts, e.g.\ for $\Pi$ and
    $\Sigma$-types. In these cases, we usually know from the type parameters which
    type former is meant. For example, $\Tm_0\,\Bool_0 \to \Bool_1$ can only refer
    to outer functions.
  \item
    We have the convention that $\blank\!=\!\blank$ refers to the inner equality
    type, while $\blank\!\equiv\!\blank$ refers to the outer equality type. In
    the semantics of 2LTT that we use, outer equality of inner values is
    interpreted as definitional equality of inner terms, hence the naming
    scheme.
  \item
    By having $\Set$, we are able to have $\Ty_0 : \Set$ and $\Tm_0 : \Ty_0 \to
    \Set$. So we don't have to deal with proper meta-level types, and have a
    more uniform notation. Notation and specification for inner type formers
    changes accordingly. For example, for inner $\Pi$-types we may write $(x :
    A) \to B$ if $A : \Ty_0$ and $B$ depends on $x : \Tm_0\,A$. This also
    enables a higher-order specification: if $B : \Tm_0\,A \to \Ty_0$, then $(x
    : A) \to B\,x : \Ty_0$, and the specifying isomorphism for $\Pi$ can be
    written as $\Tm_0\,((x : A) \to B\,x) \simeq ((x : \Tm_0\,A) \to
    \Tm_0\,(B\,x))$.
    \begin{notation}
      An explicit notation for inner function abstraction would look like
      $\lam_0\,t$ for $t : (x : \Tm_0\,A) \to \Tm_0\,(B\,x)$. This results in
      ``double'' abstraction, e.g.\ in
      $\lam_0\,(\lambda\,x.\,\suc_0\,(\suc_0\,x)) : \Tm_0\,(\Nat_0 \to
      \Nat_0)$. Instead of this, we write $\lambda_0\,x.\,t$ as a notation, thus
      we write $\lambda_0\,x.\,\suc_0\,(\suc_0\,x)$ for the above example. We
      may also group multiple $\lambda_0$ binders together the same way as with
      $\lambda$.
    \end{notation}
  \item
    We may omit inferable $\Tm_0$ applications. For instance, $\Bool_1 \to
    \Bool_0$ can be ``elaborated'' to $\Bool_1 \to \Tm_0\,\Bool_0$ without
    ambiguity, since the function codomain must be on the same level as the
    domain, and the only thing we can do to make sense of this is to lift the
    codomain by $\Tm_0$. Sometimes there is some ambiguity: $(\Bool_0 \to
    \Bool_0) \to \Bool_1$ can be elaborated both to $\Tm_0\,(\Bool_0 \to
    \Bool_0) \to \Bool_1$ and to $(\Tm_0\,\Bool_0 \to \Tm_0\,\Bool_0) \to
    \Bool_1$. However, in this case the two output types are definitionally
    isomorphic, because of the $\Pi$-preservation by $\Tm_0$. Hence, the
    elaboration choice does not make much difference, so we may still omit
    $\Tm_0$-s in situations like this.
\end{itemize}

\begin{myexample} Working in the internal syntax of 2LTT, the specification of $\Bool_0$
looks like the following (omitting $\beta$ again):
\begin{alignat*}{3}
  &\Bool_0  &&: \Ty_0\\
  &\true_0  &&: \Bool_0\\
  &\false_0 &&: \Bool_0\\
  & \ms{BoolInd_0} &&: (B : \Bool_0 \to \Ty_0) \to B\,\true_0 \to B\,\false_0 \to (t : \Bool_0) \to B\,t
\end{alignat*}
If we elaborate the type of $\ms{BoolInd_0}$, we get the following:
\begin{alignat*}{3}
  & \ms{BoolInd_0} &&: (B : \Tm_0\,\Bool_0 \to \Ty_0) \to \Tm_0\,(B\,\true_0) \to \Tm_0\,(B\,\false_0)\\
  & && \to (t : \Tm_0\,\Bool_0) \to \Tm_0\,(B\,t)
\end{alignat*}
Here, the type is forced to live in the outer level because of the dependency on
$\Ty_0$. Since $\Ty_0$ is an outer type, $\Bool_0 \to \Ty_0$ must be lifted, which
in turn requires all other types to be lifted as well.
\end{myexample}

\subsection{Alternative Presentation for 2LTT}

We digress a bit on a different way to present 2LTT. In the primary 2LTT
reference \cite{twolevel}, inner and outer layers are specified
as follows. We have two different \emph{family structures} on the base
cwf, $(\Ty_0,\,\Tm_0)$ and $(\Ty_1,\,\Tm_1)$, and a morphism between them. A
family morphism is natural transformation mapping types to types and terms to
terms, which is an isomorphism on terms. We might name the component maps
as follows:
\begin{alignat*}{3}
  &\Lift &&: \Ty_0\,\Gamma \to \Ty_1\,\Gamma \\
  &\up   &&: \Tm_0\,\Gamma\,A \to \Tm_1\,\Gamma\,(\Lift\!A)\\
  &\down &&: \Tm_1\,\Gamma\,(\Lift\!A) \to \Tm_0\,\Gamma\,A
\end{alignat*}
An advantage of this presentation is that we may close $(\Ty_0,\,\Tm_0)$ under
type formers without any encoding overhead, for example by having $\Bool_0 :
\Ty_0\,\Gamma$, $\true_0 : \Tm_0\,\Gamma\,\Bool_0$, etc., without the
Tarski-style decoding. On the other hand, we don't automatically get an outer
universe of inner types. We can recover that in two ways:
\begin{itemize}
\item
  We can assume an inner universe $\U_0 : \Ty_0\,\Gamma$, which can be lifted to the
  outer theory as $\Lift\!\U_0$. However, we may not want to make this
  assumption, in order to keep the inner theory as simple as possible.
\item
  We can assume an outer universe which classifies elements of
  $\Ty_0\,\Gamma$. This amounts to reproducing the $\Ty_0$ \emph{type} from our
  2LTT presentation, as an additional assumption. But in this case, we might as
  well skip the two family structures and the $\Lift$ morphism.
\end{itemize}
In this thesis we make ubiquitous use of the outer universe of inner types, so
we choose that to be the primitive notion, instead of having two family
structures.

Do we lose anything by this? For the purposes of this thesis, not
really. However, if we want to implement 2LTT as a system for two-stage
compilation, the $\Lift$ syntax appears to be closer to existing systems.
Staging is about computing all outer redexes but no inner ones, thereby
outputting syntax which is purely in the inner theory. This can be implemented
as a stage-aware variant of normalization-by-evaluation \cite{TODO}. We can give
an intuitive staging interpretation for the operators in the $\Lift$ syntax:
\begin{itemize}
\item
  $\Lift\!A$ is the type of $A$-expressions. This corresponds to $a\,\ms{code}$
  in MetaOcaml \cite{TODO} and $\ms{Exp}\,a$ in Template Haskell.
\item
  $\up$ is \emph{quoting}, which creates an expression from any inner term. This is
  $.\lab\blank\rab.$ in MetaOCaml and $[|\blank|]$ in Template Haskell.
\item $\down$ is \emph{splicing}, which inserts the result of a meta-level computation into
  an object-level expression. This is $\sim$ in MetaOCaml and $\$$ in Template Haskell.
\end{itemize}
For example, in the $\Lift$ syntax, we might write a polymorphic identity function
which acts on inner types in two different ways:
\begin{alignat*}{3}
  &\id : (A : \U_0) \to A \to A\hspace{2em} && \id' : (A :\,\Lift\!\U_0) \to\,\Lift\!(\down A) \to\,\Lift\!(\down A)\\
  &\id \defn \lambda_0\,A\,x.\,x && \id' \defn \lambda_1\,A\,x.\,x
\end{alignat*}
The first one lives in the inner family structure. The second one is the same
thing, but lifted to the outer theory. The choice between the two allows us to
control staging-time evaluation. If we write $\id\,\Bool_0\,\true_0$, that's an
inner expression which goes into the staging output as it is. On the other hand,
$\down(\id'\,(\up\,\Bool_0)\,(\up\,\true_0))$ reduces to $\down(\up\,\true_0)$
which in turn reduces to $\true_0$. The same choice can be expressed in our
syntax as well:
\begin{alignat*}{3}
  &\id : \Tm_0\,((A : \U_0) \to A \to A)\hspace{2em}&&\id' : (A : \Tm_0\,\U_0) \to\,\Tm_0\,A \to \Tm_0\,A\\
  &\id \defn \lambda_0\,A\,x.\,x &&\id' \defn \lambda\,A\,x.\,x
\end{alignat*}
It remains to be checked which style is preferable in a staging
implementation. In the $\Lift$ style, the quoting and splicing operations add
noise to core syntax, but they are also mostly inferable during elaboration, and
they pack stage-changing information into $\up$ and $\down$, thereby making it
feasible to omit stage annotations in other places in the core syntax. In the
$\Ty_0$ style, we don't have quote/splice, but we have to keep track of stages
in all type/term formers. The author of this thesis has made a prototype
implementation of staging in the $\Lift$ style but not in the $\Ty_0$ style
\cite{TODO}. It would be interesting to compare the two in future work.

\section{Standard Semantics of 2LTT}

We review the standard semantics of 2LTT which we use in the rest of the
thesis. This justifies the metaprogramming view, that 2LTT allows meta-level
reasoning about an inner theory.

We present it two steps, by assuming progressively more structure in the inner
theory. First, we only assume a category. This already lets us present a
presheaf semantics for the outer layer. Then, we assume a cwf as the inner
theory, which lets us interpret $\Ty_0$ and $\Tm_0$ and also consider inner type
formers.

\subsection{Presheaf Model of the Outer Layer}

In this subsection we present a presheaf model for the outer layer of 2LTT, that
is, the base category together with the terminal object, the $(\Ty,\,\Tm)$
family and some type formers. This presheaf semantics is well-known in the
literature \cite{TODO}. We give a specification which follows \cite{TODO} and
\cite{TODO} most closely.

In the following, we work outside 2LTT (since we are defining a model of 2LTT),
in a suitable metatheory; an extensional type theory with enough $\Set$
universes suffices.

We assume a $\mbbC$ category. We write $i,\,j,\,k : |\mbbC|$ for objects and
$f,\,g,\,h\,: \mbbC(i,\,j)$ for morphisms. We use a different notation than for
cwfs before, in order to disambiguate components in $\mbbC$ from components in
the presheaf model of 2LTT. We use $\hmbbC$ to refer to the model which is being
defined. We use the same component names for $\hmbbC$ as in Section
\ref{sec:models-of-tts}.

\subsubsection{Model of cwf}

\begin{mydefinition}
$\Gamma : \Con$ is a presheaf over $\mbbC$. Its components
are as follows.
\begin{alignat*}{3}
  & |\Gamma|             &&: |\mbbC| \to \Set \\
  & \blank\lab\blank\rab &&: |\Gamma|\,j \to \mbbC(i,\,j) \to |\Gamma|\,i\\
  & \gamma\lab\id\rab &&= \gamma \\
  & \gamma\lab f\circ g\rab &&= \gamma \lab f \rab \lab g \rab
\end{alignat*}
We flip around the order of arguments in the action of $\Gamma$ on
morphisms. This is more convenient because of the contravariance; we can observe
this in the statement of preservation laws already. The action on morphisms is
sometimes called \emph{restriction}.
\end{mydefinition}

\begin{mydefinition}
$\sigma : \Sub\,\Gamma\,\Delta$ is a natural transformation from $\Gamma$ to
$\Delta$. It has action $|\sigma| : |\Gamma|\,i \to |\Delta|\,i$, such that
$|\sigma|(\gamma\lab f \rab) = (|\sigma|\gamma)$.
\end{mydefinition}

\begin{mydefinition}
\label{def:presheaf-type}
$A : \Ty\,\Gamma$ is a displayed presheaf over $\Gamma$. The
``displayed'' here is used in exactly the same sense as in ``displayed
algebra'' before. As we will see in Chapter \ref{chap:fqiit}, presheaves can be
specified with a signature, in which case a presheaf is an algebra, and a
displayed presheaf is a displayed algebra. The definition here is equivalent
to saying that $A$ is a presheaf over the category of elements of $\Gamma$,
but it is more convenient to use in concrete definitions and calculations. The
components of $A$ are as follows.
\begin{alignat*}{3}
  &|A| &&: |\Gamma|\,i \to \Set\\
  &\blank\lab\blank\rab &&: |A|\,\gamma \to (f : \mbbC(i,\,j)) \to |A|\,(\gamma\lab f \rab)\\
  & \alpha\lab\id\rab &&= \alpha \\
  & \alpha\lab f\circ g\rab &&= \alpha \lab f \rab \lab g \rab
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
$t : \Tm\,\Gamma\,A$ is a section of the displayed presheaf $A$. This is
again the same notion of section that we have seen before, instantiated for
presheaves.
\begin{alignat*}{3}
  & |t| : (\gamma : |\Gamma|)\,i \to |A|\,\gamma \\
  & |t|(\gamma\lab f \rab) = (|t|\gamma)\lab f \rab
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
$\Gamma \ext A : \Con$ is the total presheaf of the displayed presheaf $A$. Its action on objects and morphisms is the following.
\begin{alignat*}{3}
  &|\Gamma \ext A| &&\defn (\gamma : |\Gamma|) \times |A\,\gamma|\\
  &(\gamma,\,\alpha)\lab f \rab &&\defn (\gamma\lab f \rab,\, \alpha\lab f \rab)
\end{alignat*}
The $\id$ and $\blank\!\circ\!\blank$ preservation laws follow immediately.
\end{mydefinition}

\begin{mydefinition}
$A[\sigma] : \Ty\,\Gamma$ is defined as follows, assuming
$A : \Ty\,\Delta$ and $\sigma : \Sub\,\Gamma\,\Delta$.
\begin{alignat*}{3}
  & |A[\sigma]|\,\gamma &&\defn |A|\,(|\sigma|\,\gamma) \\
  & \alpha \lab f \rab &&\defn \alpha \lab f \rab
\end{alignat*}
In the second component, we use $\blank\!\lab\!\blank\!\rab$ for $A$ on the right hand
side.  The definition is well-typed since $|A|\,(|\sigma|\,(\gamma\lab f \rab))
= |A|\,((|\sigma|\,\gamma)\lab f \rab)$ by the naturality of
$\sigma$. Functoriality follows from functoriality of $A$.
\end{mydefinition}

It's easy to check that the above definitions can be extended to a cwf.
\begin{itemize}
  \item For the base category, we take the category of presheaves.
  \item The empty context $\emptycon$ is the terminal presheaf, i.e.\ the
        constantly $\top$ functor.
  \item Type substitution is functorial, as it is defined as simple function
    composition of actions on objects.
  \item Term substitution is defined as composition of a section and
    a natural transformation; and also functorial for the same reason.
  \item Context comprehension structure follows from the $\Sigma$-based definition for
    context extension.
\end{itemize}

\subsubsection{Yoneda embedding}

Before continuing with interpreting type formers in $\hmbbC$, we review the
Yoneda embedding, as it is useful in subsequent definitions.

\begin{mydefinition}
The \textbf{Yoneda embedding}, denoted $\ms{y}$, is a functor from $\mbbC$ to
the underlying category of $\hmbbC$, defined as follows.
\begin{alignat*}{3}
  & \yon : |\mbbC| \to \Con \hspace{3em}&& \yon : \mbbC(i,\,j) \to \Sub\,(\yon\,i)\,(\yon\,j)\\
  & \yon\,i \defn \mbbC(\blank,\,i) && |\yon\,f|\,g \defn f \circ g
\end{alignat*}
\end{mydefinition}

\begin{mylemma}[\textbf{Yoneda lemma}] We have $\Sub\,(\yon\,i)\,\Gamma \simeq |\Gamma|\,i$ as an isomorphism of sets, natural in $i$ \cite{TODO}.
\end{mylemma}

\noindent\emph{Corollary.} If we choose $\Gamma$ to be $\yon j$, it follows that
$\Sub\,(\yon\,i)\,(\yon\,j) \simeq \mbbC(i,\,j)$, i.e.\ that $\yon$ is
bijective on morphisms; hence it is an embedding.

\begin{notation}
\label{not:yoneda}
For $\gamma : |\Gamma|\,i$, we use $\gamma\lab \blank \rab :
\Sub\,(\yon\,i)\,\Gamma $ to denote transporting right-to-left along the Yoneda
lemma. In the other direction we don't really need a notation, since from
$\sigma : \Sub\,(\yon\,i)\,\Gamma$ we get $\sigma\,\id : |\Gamma|\,i$.
\end{notation}

\subsubsection{Type formers}

\begin{mydefinition}
\label{def:k-psh}
\textbf{Constant families} are displayed presheaves which do not depend on their context.
\begin{alignat*}{3}
  & \K &&: \Con \to \{\Gamma : \Con \} \to \Ty\,\Gamma\\
  & |\K\,\Delta|\,\{i\}\,\gamma\,&&\defn |\Delta|\,i \\
  & \delta\lab f \rab &&\defn \delta \lab f \rab
\end{alignat*}
With this definition, we have $\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$
so we have strict constant families.
\end{mydefinition}

\begin{notation}
It is useful to consider any set as a constant presheaf, so
given $A : \Set$ we may write $A : \Con$ for the constant presheaf
as well.
\end{notation}

\begin{mydefinition}
From any $A : \Set$, we get $\K\,A : \Ty\,\Gamma$. This can be used to
model negative or positive \textbf{closed type formers}. For example, natural
numbers are modeled as $\K\,\mbb{N}$, Booleans as $\K\,\Bool$, the unit type as
$\K\,\top$, and so on.
\end{mydefinition}

\begin{mydefinition}
\label{def:presheaf-univ}
\textbf{Coquand universes} can be defined as follows. We write $\Set_{\hmbbC}$
for the outer universe in the model, to distinguish it from the external
$\Set$. Since the $\Set_{\hmbbC}$ is a non-dependent type, it is helpful to
define it as a $\Set_{\hmbbC} : \Con$ such that $\Sub\,\Gamma\,\Set_{\hmbbC}
\simeq \Ty\,\Gamma$.  The usual universe can be derived from this as
$\K\,\Set_{\hmbbC}$. Again, we ignore size issues; the fully formal definition
would involve indexing constructions in $\hmbbC$ by universe levels.

We can take a hint from the Yoneda lemma. We aim to define $|\Set_{\hmbbC}|\,i$,
but by the Yoneda lemma it is isomorphic to $\Sub\,(\yon
i)\,\Set_{\hmbbC}$. However, by specification this should be isomorphic to
$\Ty\,(\yon\,i)$, so we take this as definition:
\begin{alignat*}{3}
  & \Set_{\hmbbC} &&: \Con\\
  &|\Set_{\hmbbC}|\,i &&\defn \Ty\,(\yon\,i)\\
  &A \lab f \rab &&\defn A[\yon f]
\end{alignat*}
\end{mydefinition}
In the $A \lab f \rab$ definition, we substitute $A : \Ty\,(\yon\,i)$ with $\yon
f : \Sub\,(\yon j)\,(\yon i)$ to get an element of $\Ty\,(\yon j)$.  The
required $\Sub\,\Gamma\,\Set_{\hmbbC} \simeq \Ty\,\Gamma$ is straightforward, so
we omit the definition.

We note that \emph{Russell} universes are not supported in the outer layer, as
$\Sub\,\Gamma\,\Set_{\hmbbC}$ and $\Ty\,\Gamma$ are not strictly the same, in
particular they have a different number of components as iterated
$\Sigma$-types. Nevertheless, as we mentioned in Section \ref{sec:2ltt-internal-syntax}, we
use Russell-style notation in the internal 2LTT syntax, and assume that encoding/decoding
is inserted by elaboration.

\begin{mydefinition}
\textbf{$\Sigma$-types} are defined pointwise. The definitions for pairing and
projections follow straightforwardly.
\begin{alignat*}{3}
  & \Sigma  &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\    & |\Sigma\,A\,B|\,\gamma && \defn (\alpha : |A|\,\gamma) \times |B|\,(\gamma,\,\alpha)\\
  & (\alpha,\,\beta) \lab f \rab && \defn (\alpha \lab f \rab,\, \beta \lab f \rab)
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
We define \textbf{$\Pi$-types} in the following. This is a bit more complicated,
so first we look at the simpler case of presheaf exponentials.

The exponential $\Delta^\Gamma : \Con$ is characterized by the isomorphism
$\Sub\,(\Gamma \otimes \Delta)\,\Xi\,\simeq\,\Sub\,\Gamma\,(\Xi^\Delta)$, where
we write $\otimes$ for the pointwise product of two presheaves. We can again use
the Yoneda lemma. We want to define $|\Delta^\Gamma|\,i$, but this is isomorphic
to $\Sub\,(\yon i)\,(\Delta^\Gamma)$, which should be isomorphic to $\Sub\,(\yon
i \otimes \Gamma)\,\Delta$ by the specification of exponentials. Hence:
\begin{alignat*}{3}
  &|\Delta^\Gamma|\,i &&\defn \Sub\,(\yon i \otimes \Gamma)\,\Delta \\
  & \sigma \lab f \rab &&\defn \sigma \circ (\yon f \circ \p,\,\q)
\end{alignat*}
In the definition of presheaf restriction, we use $\p$, $\q$ as projections and
$\blank\!,\!\blank$ as pairing for $\otimes$. In short, $(\yon f \circ \p,\,\q)$
is the same as the morphism lifting from Definition \ref{def:cwfops}: it weakens
$\yon f : \Sub\,(\yon j)\,(\yon i)$ to $\Sub\,(\yon j \otimes \Gamma)\,(\yon i
\otimes \Gamma)$.

The dependently typed case follows the same pattern, except that we use $\Tm$
and $\blank\!\ext\!\blank$ instead of $\Sub$ and
$\blank\!\otimes\!\blank$. Additionally, the action on objects depends on
$\gamma : |\Gamma|\,i$, and we make use of $\gamma \lab \blank \rab\,\,:
\Sub\,(\yon i)\,\Gamma$ (introduced in Notation \ref{not:yoneda}).
\begin{alignat*}{3}
  & \Pi &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma \ext A) \to \Ty\,\Gamma\\
  & |\Pi\,A\,B|\,\{i\}\,\gamma &&\defn \Tm\,(\yon i \ext A[\gamma \lab \blank \rab])\,(B[\gamma\lab\blank\rab \circ\,\p,\,\q])\\
  & t\lab f \rab &&\defn t[\yon f \circ \p,\, \q]
\end{alignat*}
Let's unfold the above definition a bit. Assuming $t : |\Pi\,A\,B|\,\{i\}\,\gamma$, we have
\[
|t| : \{j : |\mbbC|\}\to((f,\,\alpha) : (f : \mbbC(j,\,i)) \times |A|\,(\gamma\lab f \rab)) \to
       |B|\,(\gamma\lab f\rab,\,\alpha)
\]
This is a bit clearer if we remove the $\Sigma$-type by currying.
\[
|t| : \{j : |\mbbC|\}(f : \mbbC(j,\,i))(\alpha : |A|\,(\gamma \lab f \rab)) \to
       |B|\,(\gamma\lab f \rab,\,\alpha)
\]

Restriction is functorial since it is defined as $\Tm$ substitution. The definitions
for $\lam$ and $\app$ are left to the reader.
\end{mydefinition}

\begin{mydefinition}
\textbf{Extensional identity} is defined as pointwise equality of sections:
\begin{alignat*}{3}
  & \Id : \Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma\\
  & |\Id\,t\,u|\,\gamma \defn |t|\,\gamma = |u|\,\gamma
\end{alignat*}
For the restriction operation, we have to show that $|t|\,\gamma = |u|\,\gamma$
implies $|t|\,(\gamma\lab f \rab) = |u|\,(\gamma \lab f \rab)$. This
follows from congruence by $\blank \lab f \rab$ and naturality of $t$ and
$u$.  The defining $(\reflect,\,\refl) : \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t =
u)$ isomorphism is evident, assuming UIP and function extensionality for the
metatheoretic $\blank\!=\!\blank$ relation (which we do assume).
\end{mydefinition}

\subsection{Modeling The Inner Layer}

We assume now that $\mbbC$ is a cwf. We write types as $a,\,b,\,c :
\Ty_\mbbC\,i$ and terms as $t,\,u,\,v : \Tm_\mbbC\,i\,a$. We reuse $\emptycon$
for the terminal object and $\blank\ext\blank$ for context extension, and
likewise reuse notation for substitutions.

\begin{mydefinition}[\textbf{$\Ty_{0}$, $\Tm_{0}$}]
First, note that $\Ty_{\mbbC}$ is a presheaf over $\mbbC$, and $\Tm_{\mbbC}$ is
a displayed presheaf over $\Ty_{\mbbC}$; this follows from the requirement that
they form a family structure over $\mbbC$. Hence, in the presheaf model
$\Ty_{\mbbC}$ is an element of $\Con$ and $\Tm_{\mbbC}$ is an element of
$\Ty\,\Ty_{\mbbC}$. Also recall from Definition \ref{def:k-psh} that
$\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$. With this is mind, we
give the following definitions:
\begin{alignat*}{3}
  & \Ty_0 : \Ty\,\Gamma                   && \Tm_0 : \Tm\,\Gamma\,\Ty_0 \to \Ty\,\Gamma\\
  & \Ty_0 \defn \K\,\Ty_{\mbbC}\hspace{2em} && \Tm_0\,A \defn \Tm_{\mbbC}[A]
\end{alignat*}
$\Tm_{\mbbC}[A]$ is well-typed since $A : \Tm\,\Gamma\,(\K\,\Ty_{\mbbC})$, thus
$A : \Sub\,\Gamma\,\Ty_{\mbbC}$. In other words, $A$ is a natural transformation
from $\Gamma$ to the presheaf of inner types.
\end{mydefinition}

\subsubsection{Inner type formers}

Can type formers in $(\Ty_{\mbbC},\,\Tm_{\mbbC})$ be transferred to
$(\Ty_0,\,\Tm_0)$ in the presheaf model of 2LTT? For example, if $\mbbC$
supports $\Bool$, we would like to model $\Bool_0$ in $\Ty_0$ as well. The
following explanation is adapted from Capriotti \cite[Section
  2.3]{capriotti2017models}.

Generally, a type former in $\mbbC$ transfers to $\hmbbC$ if it can be specified
in the internal language of $\hmbbC$; if the type former ``always has been'' in
$\hmbbC$ to begin with. To be describable in $\hmbbC$, a type former needs to be
natural with respect to $\mbbC$ morphisms. This is also a core idea of HOAS:
when working in $\hmbbC$, everything is natural, and we can omit boilerplate
related to contexts and substitutions. For example, consider the specification
of inner $\Pi$-types in the internal syntax of 2LTT:
\begin{alignat*}{3}
  &\Pi_0             &&: (A : \Ty_0) \to (\Tm_0\,A \to \Ty_0) \to \Ty_0\\
  &(\app_0,\,\lam_0) &&: \Pi_0\,A\,B \simeq ((a :\,\Tm_0\,A) \to \,\Tm_0\,(B\,a))
\end{alignat*}
We can say that this \emph{defines} what it means for $\mbbC$ to support
$\Pi$. We recover the usual non-higher-order specification of $\Pi$ in the
following way, up to isomorphism:
\begin{itemize}
\item First, we interpret the higher-order specification as a context or closed $\Sigma$-type
      in the standard presheaf model of 2LTT. This yields a presheaf over $\mbbC$.
\item Then, we evaluate the resulting presheaf at the terminal object
      $\emptycon$. This yields a set which is isomorphic to the conventional
      specification of $\Pi$.
\end{itemize}

In summary, if by ``type formers'' we mean extra structure on $(\Ty_0,\,\Tm_0)$
which is definable in 2LTT, then \emph{by definition} all such type formers
transfer from $\mbbC$ to $(\Ty_0,\,\Tm_0)$. This holds for every type former
mentioned in this thesis.

\subsection{Functions With Inner Domains}

There is a useful semantic simplification in the standard presheaf model, in
cases where we have functions of the form $\Pi\,(\Tm_0\,A)\,B$. This greatly
reduces encoding overhead when interpreting inductive signatures in 2LTT; we
look at examples in Section \ref{sec:2ltt-simple-signatures}. First we look at
the simply-typed case with presheaf exponentials.
\begin{mylemma}
$\yon$ preserves finite products up to isomorphism, i.e.\ $\yon \emptycon \simeq
  \emptycon$ and $\yon (i \otimes j) \simeq (\yon i \otimes \yon j)$.
\end{mylemma}
\begin{proof}
$\yon \emptycon$ is $\mbbC(\blank,\,\emptycon)$ by definition, which is
pointwise isomorphic to $\top$, hence isomorphic to $\emptycon \equiv
\K\,\top$. $\yon (i \otimes j)$ is $\mbbC(\blank,\,i \otimes j)$, which is
isomorphic to $\yon i \otimes \yon j$ by the specification of products.
\end{proof}
\begin{mylemma} We have the following isomorphism.
\begin{alignat*}{3}
  & |\Gamma^{\yon i}|\,j \equiv \hspace{3em}&&\\
  & \Sub\,(\yon j \otimes \yon i)\,\Gamma \simeq \hspace{3em} &&\text{by product preservation}\\
  & \Sub\,(\yon (j \otimes i))\,\Gamma \simeq \hspace{3em} &&\text {by Yoneda lemma}\\
  & |\Gamma|\,(j \otimes i)&&
\end{alignat*}
\end{mylemma}

It is possible to rephrase the above derivation for $\Pi$-types. For that, we
would need to define the action of $\yon$ on types and terms, consider the
preservation of $\blank\ext\blank$ by $\yon$, and also specify a ``dependent''
Yoneda lemma for $\Tm$. For the sake of brevity, we omit this, and present the
result directly:
\begin{alignat*}{3}
  & |\Pi\,(\Tm_0\,A)\,B|\,\{i\}\,\gamma \simeq |B|\,\{i \ext |A|\,\gamma\}\,(\gamma \lab \p \rab,\,\q)
\end{alignat*}
In short, depending on an inner domain is the same as depending on an extended
context in $\mbbC$.  We expand a bit on the typing of the right hand side. We
have $\gamma : |\Gamma|\,i$, moreover
\begingroup
\allowdisplaybreaks
\begin{alignat*}{3}
  & |B| &&: \{j : \mbbC\} \to |\Gamma\,\,\ext \Tm_0\,A|\,j \to \Set\\
  & |B| &&: \{j : \mbbC\} \to ((\gamma' : |\Gamma|\,j)\times \Tm_{\mbbC}\,j\,(|A|\,\gamma')) \to \Set\\
  & |B|\,\{i \ext |A|\,\gamma\} &&: ((\gamma' : |\Gamma|\,(i \ext |A|\,\gamma))\times \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,(|A|\,\gamma')) \to \Set\\
  & \gamma \lab \p \rab &&: |\Gamma|\,(i \ext |A|\,\gamma)\\
  & \q &&: \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,((|A|\,\gamma)[\p])\\
  & \q &&: \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,(|A|\,(\gamma \lab \p \rab))\\
\end{alignat*}
\endgroup

\section{Simple Inductive Signatures in 2LTT}
\label{sec:2ltt-simple-signatures}

We revisit simple inductive signatures in this section, working internally to
2LTT. We review the concepts introduced in Chapter
\ref{chap:simple-inductive-signatures} in the same order.

\begin{notation}
In this section we shall be fairly explicit about writing $\Tm_0$-s and
transporting along definitional isomorphisms. The simple setting makes it
feasible to be explicit; in later chapters we are more terse, as signatures and
semantics get more complicated.
\end{notation}

\subsection{Theory of Signatures}
Signatures are defined exactly in the same way as before: we have $\Con : \Set$,
$\Ty : \Set$, $\Sub : \Con \to \Con \to \Set$, $\Var : \Con \to \Ty \to \Set$ and
$\Tm : \Con \to \Ty \to \Set$. However, now by $\Set$ we mean the outer universe
of 2LTT. Thus signatures are inductively defined in the outer layer.

\subsection{Algebras}
\label{sec:2ltt-simple-algebras}

Again we compute algebras by induction on signatures, but now we use inner
types for carriers of algebras. We interpret types as follows:
\begin{alignat*}{3}
& \hspace{-4em} \rlap{$\blank^A : \Ty \to \Ty_0 \to \Set$} \\
& \hspace{-4em} \iota^A\,&&X \defn \Tm_0\,X \\
& \hspace{-4em} (\iota\to A)^A\,&&X \defn \Tm_0\,X \to A^A\,X
\end{alignat*}
Elsewhere, we change the type of the $X$ parameters accordingly:
\begin{alignat*}{3}
& \blank^A &&: \Con \to \Ty_0 \to \Set\\
& \blank^A &&: \Var\,\Gamma\,A \to \{X : \Ty_0\} \to \Gamma^A\,X \to A^A\,X\\
& \blank^A &&: \Tm\,\Gamma\,A \to \{X : \Ty_0\} \to \Gamma^A\,X \to A^A\,X\\
& \blank^A &&: \Sub\,\Gamma\,\Delta \to \{X : \Ty_0\} \to \Gamma^A\,X \to \Delta^A\,X
\end{alignat*}
We also define $\ms{Alg}\,\Gamma$ as $(X : \Ty_0) \times \Gamma^A\,X$.

\begin{myexample}
Inside 2LTT we have the following:\footnote{Up to isomorphism, since we previously defined $\Gamma^A$ as a function type instead of an iterated product type.}
\[ \Alg\,\ms{NatSig} \equiv (X : \Ty_0)\times(\mi{zero} : \Tm_0\,X)\times(\mi{suc} : \Tm_0\,X \to \Tm_0\,X) \]
Then, we may assume any cwf $\mbbC$, and interpret the above closed type in the
presheaf model $\hmbbC$, and evaluate the result at $\emptycon$ and
the unique element of the terminal presheaf $\K\,\top$:
\[
  |\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt : \Set
\]
We only need to compute definitions now. We use the simplified semantics for
$\mi{suc} : \Tm_0\,X \to \Tm_0\,X$, since the function domain is an inner
type. We get the following:
\[
|\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt \equiv
(X : \Ty_{\mbbC}\,\emptycon) \times (\mi{zero} : \Tm_{\mbbC}\,\emptycon\,X) \times (\mi{suc} : \Tm_{\mbbC}\,(\emptycon \ext X)\,X)
\]
Using the same computation, we get the following for binary trees:
\[
|\Alg\,\ms{TreeSig}|\,\{\emptycon\}\,\tt \equiv
(X : \Ty_{\mbbC}\,\emptycon) \times (\mi{leaf} : \Tm_{\mbbC}\,\emptycon\,X) \times (\mi{node} : \Tm_{\mbbC}\,(\emptycon \ext X \ext X)\,X)
\]
\end{myexample}

We can also get internal algebras in any $\mbbC$ category with finite products,
because we can build cwfs from all such $\mbbC$.

\begin{mydefinition} Assuming $\mbbC$ with finite products, we build a cwf by setting
$\Con \defn |\mbbC|$, $\Ty\,\Gamma \defn |\mbbC|$, $\Sub\,\Gamma\,\Delta \defn \mbbC(\Gamma,\,\Delta)$, $\Tm\,\Gamma\,A \defn \mbbC(\Gamma,\,A)$, $\Gamma \ext A \defn \Gamma \otimes A$ and $\emptycon \defn \emptycon_{\mbbC}$. In short, we build a non-dependent (simply-typed) cwf.
\end{mydefinition}

Now we can effectively interpret signatures in finite product categories. For
example:
\[
|\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt \equiv
(X : |\mbbC|) \times (\mi{zero} : \mbbC(\emptycon,\,X)) \times (\mi{suc} : \mbbC(\emptycon \otimes X,\,X))
\]
This is almost the same as what we would write by hand for the specification of
natural number objects; the only difference is the extra $\emptycon
\otimes\blank$ in $\mi{suc}$.

\subsection{Morphisms}

We get an additional degree of freedom in the computation of morphisms:
preservation equations can be inner or outer. The former option is \emph{weak}
or \emph{propositional} preservation, while the latter is \emph{strict}
preservation. In the presheaf model of 2LTT, outer equality is definitional
equality of inner terms, while inner equality is propositional equality in the
inner theory. Of course, if the inner theory has extensional identity types,
weak and strict equations in 2LTT coincide for inner types. We compute weak
preservation for types as follows.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^M : (A : \Ty)\{X_0\,X_1 : \Ty_0\}(X^M : \Tm_0\,X_0 \to \Tm_0\,X_1) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-5em}\iota^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn \Tm_0\,(X^M\,\alpha_0 = \alpha_1) \\
  & \hspace{-5em}(\iota\to A)^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn
       (x : \Tm_0\,X_0) \to A^M\,X^M\,(\alpha_0\,x)\,(\alpha_1\,(X^M\,x))
\end{alignat*}
For strict preservation, we simply change $\Tm_0\,(X^M\,\alpha_0 = \alpha_1)$ to
$X^M\,\alpha_0 \equiv \alpha_1$. The definition of morphisms is the same as
before:
\begin{alignat*}{3}
  &\blank^M : (\Gamma : \Con_1)\{X_0\,X_1 : \Ty_0\} \to (\Tm_0\,X_0 \to \Tm_0\,X_1) \to \Gamma^A\,X_0 \to \Gamma^A\,X_1 \to \Set\\
  &\Gamma^M\,X^M\,\gamma_0\,\gamma_1 \defn
  \{A\}(x : \Var_1\,\Gamma\,A) \to A^M\,X^M\,(\gamma_0\,x)\,(\gamma_1\,x)\\
  & \\
  &\Mor : \{\Gamma : \Con_1\} \to \Alg\,\Gamma \to \Alg\,\Gamma \to \Set \\
  &\Mor\,\{\Gamma\}\,(X_0,\,\gamma_0)\,(X_1,\,\gamma_1) \defn (X^M : \Tm_0\,X_0 \to \Tm_0\,X_1) \times \Gamma^M\,X^M\,\gamma_0\,\gamma_1
\end{alignat*}
We omit here the $\blank^M$ definitions for terms and substitutions.

\subsection{Displayed Algebras}

We present $\blank^D$ only for types below.
\begin{alignat*}{3}
  & \rlap{$\blank^D : (A : \Ty)\{X\} \to (\Tm_0\,X \to \Ty_0) \to A^A\,X \to \Set$}\\
  & \iota^D\,       && X^D\,\alpha \defn \Tm_0\,(X^D\,\alpha) \\
  & (\iota\to A)^D\,&& X^D\,\alpha \defn (x : \Tm_0\,X)(x^D : \Tm_0\,(X^D\,x)) \to A^D\,X^D\,(\alpha\,x)
\end{alignat*}
We use type dependency in the inner layer. In the presheaf model, this is
interpreted as inner types depending on certain contexts.
\begin{myexample} Assume a closed $(X,\,\mi{zero},\,\mi{suc})$ $\Nat$-algebra in 2LTT. We have the following computation:
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc}) \equiv$}\\
              & (X^D &&: \Tm_0\,X \to \Ty_0)\\
      \times\,& (\mi{zero^D} &&: \Tm_0\,(X^D\,\mi{zero}))\\
      \times\,& (\mi{suc^D} &&: (n : \Tm_0\,X) \to \Tm_0\,(X^D\,n) \to \Tm_0\,(X^D\,(\mi{suc}\,n)))
\end{alignat*}
Let's look at the presheaf interpretation now. We simplify functions with inner
domains everywhere. Also note that for $\ms{suc} : \Tm_0\,X \to \Tm_0\,X$, we
get $|\ms{suc}|\,\tt : \Tm_{\mbbC}\,(\emptycon\ext n : |X|\,\tt)\,(|X|\,\tt)$ in
the semantics, so a $\ms{suc}\,t$ application is translated as a substitution
$(|\ms{suc}|\,\tt)[n \mapsto |t|\,\tt]$.
\begin{alignat*}{3}
  & \rlap{$|\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})|\,\{\emptycon\}\,\tt \equiv$}\\
              & (X^D &&: \Ty_{\mbbC}\,(\emptycon\ext n : |X|\,\tt))\\
      \times\,& (\mi{zero^D} &&: \Tm_{\mbbC}\,\emptycon\,(X^D[n \mapsto |\mi{zero}|\,\tt]))\\
      \times\,& (\mi{suc^D} &&: \Tm_{\mbbC}\,(\emptycon\ext n : |X|\,\tt \ext n^D : X^D[n \mapsto |\mi{zero}|\,\tt])\,(X^D[n \mapsto (|\mi{suc}|\,\tt)[n \mapsto n]))
\end{alignat*}
\end{myexample}
To explain $(|\ms{suc}|\,\tt)[n \mapsto n])$: we have $\ms{suc}\,n$ in 2LTT,
where $n$ is an inner variable, and in the presheaf model inner variables become
actual variables in the inner theory. Hence, we map the $n$ which $\ms{suc}$
depends on to the concrete $n$ in the context.

We can also interpret displayed algebras in finite product categories:
\begin{alignat*}{3}
  & \hspace{-2em}\rlap{$|\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})|\,\{\emptycon\}\,\tt \equiv$}\\
              & (X^D &&: |\mbbC|)\\
      \times\,& (\mi{zero^D} &&: \mbbC(\emptycon,\,X^D))\\
      \times\,& (\mi{suc^D} &&: \mbbC(\emptycon \otimes |X|\,\tt \otimes X^D,\, X^D))
\end{alignat*}

While displayed algebras in cwfs can be used as bundles of induction motives and
methods, in finite product categories they are argument bundles to
\emph{primitive recursion}; this is sometimes also called a
\emph{paramorphism} \cite{bananas}. In an internal syntax, the type of primitive
recursion for natural numbers could be written more compactly as:
\begin{alignat*}{3}
  & \ms{primrec} : (X : \Set) \to X \to (\Nat \to X \to X) \to \Nat \to X
\end{alignat*}
This is not the same thing as the usual recursion principle (corresponding to
weak initiality), because of the extra dependency on $\Nat$ in the method for
successors.

\subsection{Sections}
Sections are analogous to morphisms. We again have a choice between weak and
strict preservation; below we have weak preservation.
\begin{alignat*}{3}
  & \rlap{$\blank^S : (A : \Ty)\{X\,X^D\}(X^S : (x : \Tm_0\,X)\to \Tm_0\,(X^D\,x))$}\\
  & \hspace{2em}\rlap{$\to (\alpha : A^A\,X) \to A^D\,X^D\,\alpha \to \Set$}\\
  & \iota^S\,&&X^S\,\alpha\,\,\alpha^D \defn \Tm_0\,(X^S\,\alpha = \alpha^D) \\
  & (\iota\to A)^S\,&&X^S\,\alpha\,\,\alpha^D \defn
  (x : \Tm_0\,X) \to A^S\,X^S\,(\alpha\,x)\,(\alpha^D\,(X^S\,x))
\end{alignat*}

\subsection{Term Algebras}
\label{sec:simple-2ltt-term-algebras}

\todo{Try to skip the lowering isomorphisms altogether by only using inner AD and outer MS}

For term algebras, we need to assume a bit more in the inner theory. For
starters, it has to support the theory of signatures. In order to avoid name
clashes down the line, we use $\SigTy_0$ to refer to signature types, and
$\SigTm_0$ for terms. That is, we have
\begin{alignat*}{3}
  & \SigTy_0  &&: \Ty_0\\
  & \Con_0   &&: \Ty_0\\
  & \Var_0   &&: \Tm_0\,\Con_0 \to \Tm_0\,\SigTy_0 \to \Ty_0\\
  & \SigTm_0 &&: \Tm_0\,\Con_0 \to \Tm_0\,\SigTy_0 \to \Ty_0\\
  & \Sub_0   &&: \Tm_0\,\Con_0 \to \Tm_0\,\Con_0 \to \Ty_0
\end{alignat*}
together with all constructors and induction principles. We also assume inner
$\Pi$-types, because we previously defined $\Sub$ using functions.

\emph{Remark.} If we only want to construct term algebras, it is not necessary
to assume inner induction principles. It is sometimes useful to construct term
algebras from models which are explicitly \emph{not} initial; we will see such
examples in \ref{sec:lambda-encodings}. In this section, our goal is to redo the constructions
of Chapter \ref{chap:simple-inductive-signatures} without making essential changes, so
we just assume everything that was available there.

We still have ToS in the outer layer. To make the naming
scheme consistent, we shall write outer ToS types as $\SigTy_1$,
$\SigTm_1$, $\Con_1$, $\Var_1$ and $\Sub_1$. We have conversion functions from
the outer ToS to the inner ToS:
\begin{mydefinition}
\label{def:simple-lowering}
We have the following \textbf{lowering} functions which
preserve all structure.
\begin{alignat*}{3}
  & \down\,: \SigTy_1 &&\to \Tm_0\,\SigTy_0\\
  & \down\,: \Con_1 &&\to \Tm_0\,\Con_0\\
  & \down\,: \Var_1\,\Gamma\,A &&\to \Tm_0\,(\Var_0\,(\down\!\Gamma)\,(\down\!A))\\
  & \down\,: \SigTm_1\,\Gamma\,A &&\to \Tm_0\,(\SigTm_0\,(\down\!\Gamma)\,(\down\!A))\\
  & \down\,: \Sub_1\,\Gamma\,\Delta &&\to \Tm_0\,(\Sub_0\,(\down\!\Gamma)\,(\down\!\delta))
\end{alignat*}
These functions are called ``lifting'' in the context of multi-stage
programming; see e.g.\ the $\ms{Lift}$ typeclass in Haskell
\cite{pickering-multistage}. There, like here, the point is to build
object-language terms from meta-level (``compile-time'') values.

Lowering is straightforward to define for types, contexts, variables and terms,
but there is a bit of a complication for $\Sub$. Unfolding the definitions, we
need to map from $\{A\} \to \Var_1\,\Delta\,A \to \SigTm_1\,\Gamma\,A$ to
$\Tm_0\,(\{A\} \to \Var_0\,(\down\Delta)\,A \to \SigTm_0\,(\down\Gamma)\,A)$. It
might appear problematic that we have types and variables in \emph{negative}
position, because we can't map inner types/variables to outer ones.
Fortunately, $\Sub_1\,\Gamma\,\Delta$ is isomorphic to a finite product type,
and we can lower a finite product component-wise.

Concretely, we define lowering by induction on $\Delta$, while making use of
a case splitting operation for $\Var_0$. We use an informal $\ms{case}$
operation below, which can be defined using inner induction. Note that since
$\Var_0\,\emptycon\,A$ is an empty type, case splitting on it behaves like
elimination for the empty type.
\begin{alignat*}{3}
  &\rlap{$\hspace{0.3em}\down_{\Delta} : \Sub_1\,\Gamma\,\Delta \to \Tm_0\,(\Sub_0\,(\down\!\Gamma)\,(\down\!\Delta))$}\\
  &\down_{\emptycon}\,&&\sigma \defn
      \lambda\,\{A\}\,(x : \Var_0\,\emptycon\,A).\,\ms{case}\,x\,\ms{of}\,()\\
  &\down_{\Delta\ext B}\,&&\sigma \defn
      \lambda\,\{A\}\,(x : \Var_1\,(\down\!\Delta\,\ext \down\!B)\,A).\,\ms{case}\,x\,\ms{of}\\
  & &&\vz\hspace{0.65em}\to\,\,\down\!(\sigma\,\vz)\\
  & &&\vs\,x \to\,\,\down_{\Delta}\!(\sigma \circ \vs)\,x
\end{alignat*}
In general, for finite $A$ type, functions of the form $A \to \Tm_0\,B$ can be
represented as inner types up to isomorphism; they can be viewed as finite
products of terms.

\emph{Remark.} For infinite $A$ this does not work anymore in our system. In
\cite{twolevel}, the assumption that this still works with $A \equiv \Nat_1$ is
an important axiom (``cofibrancy of $\Nat_1$'') which makes it possible to embed
higher categorical structures in 2LTT. From the metaprogramming perspective,
cofibrancy of $\Nat_1$ implies that the inner theory is \emph{infinitary}, since
we can form inner terms from infinite collections of inner terms. We don't
assume this axiom in 2LTT, although we will consider infinitary (object) type
theories in Chapters \ref{chap:fqiit} and \ref{chap:iqiit}.
\end{mydefinition}

\noindent
We continue to the definition of term algebras. We fix an $\Omega : \Con_1$, and
define $\ms{T} : \Ty_0$ as $\SigTm_0\,(\down\!\Omega)\,\iota$.
\begingroup
\allowdisplaybreaks
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^T : (A : \SigTy_1) \to \Tm_0\,(\SigTm_0\,(\down\!\Omega)\,(\down\!A)) \to A^A\,\ms{T}$} \\
  & \hspace{-5em}\iota^T\,&&t \defn t \\
  & \hspace{-5em}(\iota\to A)^T\,&&t \defn \lambda\,u.\,A^T\,(\app\,t\,u)\\
  & \hspace{-5em}&&\\
  & \hspace{-5em}\rlap{$\blank^T : (\Gamma : \Con_1) \to \Sub_1\,\Omega\,\Gamma \to \Gamma^A\,\ms{T}$}\\
  & \hspace{-5em}\rlap{$\Gamma^T\,\nu\,\{A\}\,x \defn A^T\,(\down\!(\nu\,x))$}\\
  & \hspace{-5em} && \\
  & \hspace{-5em}\rlap{$\TmAlg_{\Omega} : \Alg\,\Omega$}\\
  & \hspace{-5em}\rlap{$\TmAlg_{\Omega} \defn \Omega^T\,\Omega\,\id$}
\end{alignat*}
\endgroup
We omit the $\blank^T$ interpretation for terms and substitutions for now, as
they require a bit more setup, and they are not needed just for term algebras.

\subsection{Recursor Construction}

Recall from Section \ref{sec:simple-weak-initiality} that recursion is
implemented using the $\blank^A$ interpretation of terms. Since terms are now in
the inner theory, we need to define an inner version of the same interpretation.
We need to compute types by inner induction, so we additionally assume a
Russell-style inner $\U_0$ universe. The Russell style means that we may freely
coerce between $\Tm_0\,\U_0$ and $\Ty_0$. The following are defined the same way
as $\blank^A$ before.
\begin{alignat*}{3}
  &\blank^A : \Tm_0\,(\SigTy_0 \to \U_0 \to \U_0)\\
  &\blank^A : \Tm_0\,(\Con_0 \to \U_0 \to \U_0)\\
  &\blank^A : \Tm_0\,(\SigTm_0\,\Gamma\,A \to \{X : \U_0\} \to \Gamma^A\,X \to A^A\,X)\\
  &\blank^A : \Tm_0\,(\Sub_0\,\Gamma\,\Delta \to \{X : \U_0\} \to \Gamma^A\,X \to \Delta^A\,X)
\end{alignat*}
Since lowering preserves all structure, and $\blank^A$ is defined in the same
way in both the inner and outer theories, lowering is compatible with
$\blank^A$ in the following way.
\begin{mylemma}\label{lem:down-compat-alg} Assume $A : \SigTy_1$, $\Gamma : \Con_1$, $X : \Ty_0$, $\gamma : \Gamma^A\,X$ and $t : \SigTm_1\,\Gamma\,A$. We have the following:
  \begin{itemize}
  \item $(A^A_{\to},\,A^A_{\leftarrow}) : \Tm_0\,((\down\!A)^A\,X) \simeq A^A\,X$
  \item $(\Gamma^A_{\to},\,\Gamma^A_{\leftarrow}) : \Tm_0\,((\down\!\Gamma)^A\,X) \simeq \Gamma^A\,X$
  \item $t^A\,\gamma \equiv A^A_{\to}\,((\down\!t)^A\,(\Gamma^A_{\leftarrow}\,\gamma))$
  \end{itemize}
\end{mylemma}
\begin{proof}
By induction on $\Gamma$, $A$ and $t$.
\end{proof}
We construct recursors now, yielding strict algebra morphisms.  We
assume $(X,\,\omega) : \Alg\,\Omega$. Recall that $\omega : \Omega^A\,X$, thus
$\Omega^A_{\leftarrow}\,\omega : \Tm_0\,((\down\!\Omega)^A\,X)$. We define $\ms{R} :
\Tm_0\,\ms{T} \to \Tm_0\,X$ as $\ms{R}\,t \defn t^A\,(\Omega^A_{\leftarrow}\,\omega)$.
\begin{alignat*}{3}
& \hspace{-8em}\rlap{$\blank^R : (A : \SigTy_1)(t : \Tm_0\,(\SigTm_0\,(\down\!\Omega)\,(\down\!A))) \to A^M\,\ms{R}\,(A^T\,t)\,(\A^A_{\rightarrow}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega)))$}\\
& \hspace{-8em}\iota^R\,&&t : t^A\,(\Omega^A_{\leftarrow}\,\omega) \equiv \iota^A_{\to}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega))\\
& \hspace{-8em}(\iota\to A)^R\,&&t \defn \lambda\,u.\,A^R\,(\app\,t\,u)\\
& \hspace{-8em}&& \\
& \hspace{-8em}\rlap{$\blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)$}\\
& \hspace{-8em}\rlap{$\Gamma^R\,\nu\,\{A\}\,x \defn A^R\,(\down\!(\nu\,x))$}
\end{alignat*}
In the proof obligation for $t^A\,(\Omega^A_{\leftarrow}\,\omega) \equiv
\iota^A_{\to}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega))$, $\iota^A_{\to}$ computes
to the identity function; note that $\iota^A_{\to} : \Tm_0\,X \to \Tm_0\,X$. Hence
the equality becomes reflexive.

In $\Gamma^R\,\nu\,\{A\}\,x \defn A^R\,(\down\!(\nu\,x))$, we have that
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(A^A_{\to}\,(\down\!(\nu\,x)^A\,(\Omega^A_{\leftarrow}\,\omega)))
\]
Hence by Lemma \ref{lem:down-compat-alg}, we have
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,((\nu\,x)^A\,\omega)
\]
Hence, by the definition of $\blank^A$ for substitutions:
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(\nu^A\,\omega\,x)
\]
Which is exactly what is required when we unfold the expected return type:
\begin{alignat*}{3}
  & \blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)\\
  & \blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \{A\}(x : \Var_1\,\Gamma\,A) \to
    A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(\nu^A\,\omega\,x)
\end{alignat*}
The recursor is defined the same way as in Definition \ref{def:simple-recursor}:
\begin{alignat*}{3}
  & \Rec_{\Omega} : (\mi{alg} : \Alg\,\Omega) \to \Mor\,\TmAlg_{\Omega}\,\mi{alg}\\
  & \Rec_{\Omega}\,(X,\,\omega) \defn (\ms{R},\,\Omega^R\,\Omega\,\id)
\end{alignat*}

\subsection{Eliminator Construction}

For induction, we need to additionally define $\blank^D$ in the inner layer.
\begin{alignat*}{3}
  &\blank^D : \Tm_0\,((A : \SigTy_0)\{X\} \to (\Tm_0\,X \to \U_0) \to A^A\,X \to \U_0)\\
  &\blank^D : \Tm_0\,((\Gamma : \Con_0)\{X\} \to (\Tm_0\,X \to \U_0) \to \Gamma^A\,X \to \U_0)\\
  &\blank^D : \Tm_0\,((t : \SigTm_0\,\Gamma\,A) \to \Gamma^D\,X^D\,\gamma \to A^D\,X^D\,(t^A\,\gamma))\\
  &\blank^D : \Tm_0\,((\sigma : \Sub_0\,\Gamma\,\Delta) \to \Gamma^D\,X^D\,\gamma \to \Delta^D\,X^D\,(\sigma^A\,\gamma))
\end{alignat*}

\begin{mylemma}
We have again compatibility of lowering with $\blank^D$. Assuming
$(X,\,\gamma) : \Alg\,\Gamma$, $(X^D,\,\gamma^D) : \DispAlg\,(X,\,\gamma)$,
$t : \SigTm_1\,\Gamma\,A$, and $\alpha : A^A\,X$, we have
\begin{itemize}
  \item $(\A^D_{\to},\,\A^D_{\leftarrow}) :
    \Tm_0\,((\down\!\A)^D\,X^D\,(\A^A_{\leftarrow}\,\alpha)) \simeq \A^D\,X^D\,\alpha$
  \item $(\Gamma^D_{\to},\,\Gamma^D_{\leftarrow}) :
    \Tm_0\,((\down\!\Gamma)^D\,X^D\,(\Gamma^A_{\leftarrow}\,\gamma)) \simeq \Gamma^D\,X^D\,\gamma$
  \item $t^D\,\gamma^D \equiv A^D_{\to}\,((\down\!t)^D\,(\Gamma^D_{\leftarrow}\,\gamma^D))$
\end{itemize}
The equation for $t^D\,\gamma^D$ is well-typed because of the term equation in Lemma
\ref{lem:down-compat-alg}.
\end{mylemma}
\begin{proof} Again by induction on $\Gamma$, $A$ and $t$.
\end{proof}

We also need to extend $\blank^T$ with action on terms. Note that we return
an inner equality, since we can only compute such equality by induction on the
inner term input:
\[
\blank^T : (t : \SigTm_0\,(\down\!\Gamma)\,(\down\!A))(\nu : \Sub_1\,\Omega\,\Gamma) \to
  \Tm_0\,(A^A_{\leftarrow}\,(A^T\,(t[\down\!\nu])) = t^A\,(\Gamma^A_{\leftarrow}\,\nu))
\]
We assume $(X^D,\,\omega^D) : \DispAlg\,\TmAlg_\Omega$, and define elimination
as follows:
\begin{alignat*}{3}
  & \ms{E} : (t : \Tm_0\,\ms{T}) \to \Tm_0\,(X^D\,t) \\
  & \ms{E}\,t \defn t^D\,(\Omega^D_{\leftarrow}\,\omega^D)
\end{alignat*}
This definition is well-typed only up to $t^T\,\id : \Tm_0\,(t =
t^A\,(\Omega^A_{\leftarrow}\,(\Omega^T\,\Omega\,\id)))$. Since $t^T\,\id$ is an
inner equality, in a fully formal intensional presentation we would have to
write an explicit transport in the definition.

We shall skip the remainder of the eliminator construction; it goes the same way
as in Definition \ref{def:simple-eliminator-construction}. Intuitively, this is
possible since the inner theory has all necessary features to reproduce the
eliminator construction, and lowering preserves all structure.

Since $t^T$ yields inner equations, this implies that the displayed algebra
sections returned by the eliminator are \emph{weak sections}, i.e.\ they contain
$\beta$-rules expressed in inner equalities.

\section{Discussion}

\subsection{Evaluation}

Let's review how 2LTT addresses the shortcomings that we mentioned in Section
\ref{sec:2ltt-motivation}.
\\\\
\textbf{Generalized semantics.} For this purpose, there is minimal
technical overhead to using 2LTT; we only need to sprinkle $\Ty_0$ and $\Tm_0$
around a bit, and we get semantics internally to cwfs (including all finite product
categories).
\\\\
\textbf{Term algebra constructions.}
Here, we had to deal with significantly more noise, because of the necessary
lowerings and their preservation isomorphisms. However, this overhead should be
compared to reasoning about object-level definitional equality in a deeply
embedded way, which entails explicitly manipulating abstract syntax and its
substitutions and weakenings. Compared to that, 2LTT is tremendously easier. One
could also argue that lowering is an entirely mechanical affair, and we can just
omit most of it if we are comfortable enough with the formalism.

\subsection{Recursor vs. Eliminator Construction}

The essential extra detail that we
had to handle in Section \ref{sec:2ltt-simple-signatures} was the choice between
strict and weak equations. This choice brings along further implementation
constraints.

Strict equations are stronger as assumptions, because they represent
definitional equality of inner terms. However, we can only produce strict
equations by eliminating from outer types. Hence, if we aim to output strict
equations, we have to assume every dependency in the outer theory, which in turn
may require using lowering.

Weak equations are easier to produce: strict equality implies weak equality,
plus we can prove weak equality by inner induction. But we cannot use weak
equality to transport outer values.

In the recursor construction, we produced strict $\beta$-rules, which trivially
imply weak $\beta$-rules as well. In contrast, the eliminator construction
relies essentially on equations produced by $\blank^T$ for inner terms. Can we
somehow get strict equations from $\blank^T$? This does not seem possible, at
least without changing the approach in a major way: terms must be inner, or else
we have no hope of inner recursion/induction. And if terms are inner, then
$\ms{E}$ must act on arbitrary inner terms, hence $\blank^T$ must do so too.

It would be interesting to check if there is a possible alternative formulation of
term algebras and constructed eliminators, which makes it possible to get strict
eliminators. Looking back to Section \ref{sec:generic-programming}, it appears
that by using spine neutral terms, we get strict elimination for each
signature. However, this relies on the Agda implementation of pattern matching
and structurally recursive definitions, so it would require more work to translate
these definitions to 2LTT in a generic way.

\chapter[Finitary QII Signatures]{Finitary Quotient Inductive-Inductive Signatures}
\label{chap:fqiit}

In this chapter we bump the expressive power of signatures by a large margin,
and also substantially extend the semantics. However, we keep the basic approach
the same; indeed its advantages become apparent with the more sophisticated
signatures.

We use two different setups for semantics in this chapter.
\begin{itemize}
  \item In Sections \ref{sec:fqiit-tos}-\ref{sec:fqiit-semantics} we work in 2LTT, thereby
        getting a generalized semantics for signatures. However, we keep details about universe
        levels to the minimum.
  \item In Sections \ref{sec:fqiit-levels}-\ref{sec:fqiit-term-algebras}, we work in an
        extensional type theory with cumulative universes. This is more suited for the term
        algebra construction, where (as we will see) 2LTT does not bring any advantage, but
        we do need to be more precise about universes.
\end{itemize}


\section{Theory of Signatures}
\label{sec:fqiit-tos}

Signatures are once again given by contexts of a type theory, but now it is a
dependent type theory, given as a cwf with certain type formers, in the style
of Section \ref{sec:models-of-tts}.
\\\\
\textbf{Metatheory and notation.} We work in 2LTT with $\Ty_0$ and $\Tm_0$. We
make the following assumptions. Later, we may assume more type formers at either
levels as needed.
\begin{itemize}
  \item $\Ty_0$ is closed under $\top$, $\Sigma$ and extensional identity $\blank\!=\!\blank$.
        The inner identity reflects the outer one.
  \item The outer identity $\blank\!\equiv\!\blank$ is also extensional; it supports
        UIP, function extensionality, and it reflects strict equality in some
        unspeficied metatheory outside 2LTT. This reflection is used to justify
        omitting transports along $\blank\!\equiv\!\blank$ in our notation.
\end{itemize}
In the following we specify models of the theory of \emph{finitary quotient
inductive-inductive signatures}. The names involved are a bit of a mouthful, so
we abbreviate ``finitary quotient inductive-inductive'' as FQII, and like
before, we abbreviate ``theory of signatures'' as ToS. In this chapter, by
signature we mean an FQII signature unless otherwise specified.

\begin{mydefinition}
\label{def:fqiit-tos}
A \textbf{model of the theory of signatures} consists of the following.
  \begin{itemize}
    \item A \textbf{cwf} with underlying sets $\Con$, $\Sub$, $\Ty$ and $\Tm$, all returning in
      the outer $\Set$ universe of 2LTT.
    \item A \textbf{Tarski-style universe} $\U$ with decoding $\El$.
    \item An \textbf{extensional identity type} $\Id : \Tm\,\Gamma\,A \to
      \Tm\,\Gamma\,A \to \Ty\,\Gamma$, specified by $(\reflect,\,\refl) :
      \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t \equiv u)$.
    \item An \textbf{inductive function type} $\Pi : (a : \Tm\,\Gamma\,\U) \to
      \Ty\,(\Gamma\ext\El\,a) \to \Ty\,\Gamma$, specified by
      $(\app,\,\lam) : \Tm\,\Gamma\,(\Pi\,a\,B) \simeq \Tm\,(\Gamma \ext \El\,a)\,B$.
    \item An \textbf{external function type} $\Pie : (A : \Ty_0) \to (A \to \Ty\,\Gamma) \to \Ty\,\Gamma$, specified by
      $(\appe,\,\lame) : \Tm\,\Gamma\,(\Pie\,A\,B) \simeq ((x : A) \to \Tm\,\Gamma\,(B\,x))$.
  \end{itemize}
\end{mydefinition}
At this point we only have a notion of model for ToS, but as we will see in
Chapter \ref{chap:iqiit}, ToS is also an algebraic theory, more specifically an
infinitary QII one. It is infinitary because $\Pie$ and $\lame$ allow branching
over elements of arbitrary $A : \Ty_0$ types.

Because of the algebraic character of ToS, there is a category of ToS models
where morphisms strictly preserve all structure, and the initial model
corresponds to the syntax. In this chapter, we just assume that the ToS
syntax exists, and leave metatheoretical matters to Chapter \ref{chap:iqiit}.
\begin{mydefinition} An FQII \textbf{signature} is an element of $\Con$ in the syntax of ToS.
\end{mydefinition}
We review several example signatures in the following, using progressively
more ToS type formers.  We also introduce progressively more compact notation
for signatures. As a rule of thumb, we shall use compact notation for larger and
more complex signatures, but we shall be more explicit when we specify models of
ToS later in this chapter.
\begin{myexample}
  Simple inductive signatures can be evidently expressed using $\U$ and
  $\Pi$. By adding a single $\U$ to the signature, we introduce the inductive
  sort.
  \begin{alignat*}{3}
    & \ms{NatSig} &&\defn \emptycon \ext (N : \U) \ext (\mi{zero} : \El\,N)
                        \ext (\mi{suc} : \Pi (n : N) (\El\,N))\\
    & \ms{TreeSig} &&\defn \emptycon \ext (T : \U) \ext (\mi{leaf} : \El\,T)
                         \ext (\mi{node} : \Pi (t_1 : T) (\Pi (t_2 : T) (\El\,T)))
  \end{alignat*}
  Observe that the domains in $\Pi$ are terms with type $\U$, while the codomains are proper types.
\end{myexample}

\begin{notation} We write non-dependent function types in ToS as follows.
  \begin{itemize}
  \item $a \funi B$ for $\Pi\,(\_ : a)\,B$.
  \item $A \fune B$ for $\Pie\,A\,(\lambda\,\_.\,B)$.
  \end{itemize}
\end{notation}
\noindent
Using this notation, we may write $\mi{suc} : N \funi \El\,N$ and $\mi{node} : T
\funi T \funi \El\,T$.

\begin{notation}
The ``categorical'' application $\app$ with explicit substitutions is a bit
inconvenient. Instead, we simply write whitespace for $\Pii$ and $\Pie$
application:
\begin{alignat*}{3}
  & t\,u \defn (\appi\,t)[\id,\,u]\\
  & t\,u \defn (\appe\,t)\,u
\end{alignat*}
\end{notation}

\begin{myexample}
We may have any number of sorts by adding more $\U$ to the signatures. Moreover,
sorts can be indexed over previous sorts. Hence, using only $\U$, $\El$ and
$\Pi$, we can express any closed inductive-inductive type \cite{TODO}. The
following fragment of the the signature for categories is such:
\begin{alignat*}{3}
  & \emptycon \ext (\mi{Obj} : \U) \ext (\mi{Hom} : \mi{Obj} \funi \mi{Obj} \funi \U)
      \ext (\mi{id} : \Pi(i : \mi{Obj})\,(\El\,(\mi{Hom}\,i\,i)))n
\end{alignat*}
These inductive-inductive signatures are more flexible than those in prior works
\cite{TODO}, since we allow type constructors (sorts) and point constructors to
be arbitrarily mixed (as opposed to mandating that sorts are declared first). For example:
\begin{alignat*}{3}
  & \emptycon \ext (A : \U) \ext (a : \El\,A) \ext (B : A \funi \U) \ext (C : B\,a \funi \U)
\end{alignat*}
Here $C$ is indexed over $B\,a$, where $a$ is a point constructor of $a$, so a
sort specification mentions a point constructor.
\end{myexample}

\begin{myexample} $\Id$ lets us add equations to signatures. With this, we can write down the full
signature for categories:
\begin{alignat*}{3}
  & \emptycon &&\ext (\mi{Obj}   &&: \U)\\
  &           &&\ext (\mi{Hom}   &&: \mi{Obj} \funi \mi{Obj} \funi \U)\\
  &           &&\ext (\mi{id}    &&: \Pi(i : \mi{Obj})\,(\El\,(\mi{Hom}\,i\,i)))\\
  &           &&\ext (\mi{comp}  &&: \Pi\,(i\,j\,k : \mi{Obj})\,(\mi{Hom}\,j\,k \funi \mi{Hom}\,i\,j \funi \El\,(\mi{Hom}\,i\,k)))\\
  &           &&\ext (\mi{idr}   &&: \Pi\,(i\,j : \mi{Obj})(f : \mi{Hom}\,i\,j)\,(\Id\,(\mi{comp}\,i\,i\,j\,f\,(\mi{id}\,i))\,f))\\
  &           &&\ext (\mi{idl}   &&: \Pi\,(i\,j : \mi{Obj})(f : \mi{Hom}\,i\,j)\,(\Id\,(\mi{comp}\,i\,j\,j\,(\mi{id}\,j)\,f)\,f))\\
  &           &&\ext (\mi{assoc} &&: \Pi\,(i\,j\,k\,l : \mi{Obj})(f : \mi{Hom}\,j\,l)(g : \mi{Hom}\,j\,k)(h : \mi{Hom}\,i\,j)\\
  &           && &&\hspace{1.7em} (\Id
                 \,(\mi{comp}\,i\,j\,l\,(\mi{comp}\,j\,k\,l\,f\,g)\,h)
                 \,(\mi{comp}\,i\,k\,l\,f\,(\mi{comp}\,i\,j\,k\,g\,h))
\end{alignat*}
Now, this is already rather hard to read, even together with the compressed
notation for multiple $\Pi$ binders.
\begin{notation}
For more complex signatures, we may entirely switch to an internal notation,
where we mostly reuse the conventions in the metatheories. We use $(x :
a) \to B$ for inductive functions, $(x : A) \toe B$ for external functions,
but we still write $\Id$ for the identity type and make $\U$ and $\El$
explicit. In this notation, a signature is just a listing of binders. The category
signature becomes the following:
\begin{alignat*}{3}
  & \mi{Obj} &&: \U\\
  & \mi{Hom} &&: \mi{Obj} \to \mi{Obj} \to \U\\
  & \mi{id}  &&: \El\,(\mi{Hom}\,i\,i)\\
  & \mi{\blank\!\circ\!\blank} &&: \mi{Hom}\,j\,k \to \mi{Hom}\,i\,j \to \El\,(\mi{Hom}\,i\,k)\\
  & \mi{idr} &&: \Id\,(f \circ \mi{id})\,f\\
  & \mi{idl} &&: \Id\,(\mi{id} \circ f)\,f\\
  & \mi{assoc} &&: \Id\,(f \circ (g \circ h))\,((f \circ g) \circ h)
\end{alignat*}
\end{notation}
\end{myexample}

\begin{myexample}
The external function type makes it possible to reference inner types (in 2LTT)
in signatures. Here ``external'' is meant relative to a given signature, and
refers to types and inhabitants which are not introduced inside a signature.
For example, we give a signature for lists by assuming $A : \Ty_0$ for the
(external) type of list elements:
\begin{alignat*}{3}
  &\mi{List} &&: \U\\
  &\mi{nil}  &&: \El\,\mi{List}\\
  &\mi{cons} &&: A \toe \mi{List} \to \El\,\mi{List}
\end{alignat*}
Hence, ``parameters'' are always assumptions made in the metatheory. We can
also \emph{index} sorts by external values. Let's specify length-indexed vectors
now; we keep the $A : \Ty_0$ assumption, but also assume that $\Ty_0$ has
natural numbers, with $\Nat_0 : \Ty_0$, $\zero_0$ and $\suc_0$.
\begin{alignat*}{3}
  &\mi{Vec}  &&: \Nat_0 \toe \U \\
  &\mi{nil}  &&: \El\,(\mi{Vec}\,\zero_0)\\
  &\mi{cons} &&: (n : \Nat_0) \toe A \toe \mi{Vec}\,n \to \El\,(\mi{Vec}\,(\suc_0\,n))
\end{alignat*}
\end{myexample}

\begin{myexample}
We can also introduce \emph{sort equations} using $\Id$: this means equating
terms of $\U$, i.e.\ inductively specified sets. This is useful for specifying
certain strict type formers. For example, a signature for cwfs can be extended with
a specification for strict constant families.
\begin{alignat*}{3}
  & \mi{Con}     &&: \U\\
  & \mi{Sub}     &&: \mi{Con} \to \mi{Con} \to \U \\
  & \mi{Ty}      &&: \mi{Con} \to \U\\
  & \mi{Tm}      &&: (\Gamma : \mi{Con}) \to \mi{Ty}\,\Gamma \to \U\\
  & ...          &&\\
  & \mi{K}       &&: \mi{Con} \to \{\Gamma : \mi{Con}\} \to \El\,(\mi{Ty}\,\Gamma)\\
  & \mi{K_{spec}} &&: \Id\,(\mi{Tm}\,\Gamma\,(\mi{K}\,\Delta))\,(\mi{Sub}\,\Gamma\,\Delta)
\end{alignat*}
The equation for Russell-style universes is likewise a sort equation:
\begin{alignat*}{3}
  &\mi{Univ}    &&: \El\,(\mi{Ty}\,\Gamma)\\
  &\mi{Russell} &&: \Id\,(\mi{Tm}\,\Gamma\,\mi{Univ})\,(\mi{Ty}\,\Gamma)
\end{alignat*}
\end{myexample}

\begin{myexample}
\label{ex:presheaf-sig}
As we mentioned in Definition \ref{def:presheaf-type}, there is a signature for
presheaves, so let's look at that now. Assume a category $\mbbC$ in the inner
theory; this means that objects and morphisms of $\mbbC$ are in $\Ty_0$.
\begin{alignat*}{3}
  & \mi{Obj}         &&: |\mbbC| \toe \U\\
  & \mi{Hom}         &&: \mbbC(i,\,j) \toe \mi{Obj}\,j \to \El\,(\mi{Obj}\,i)\\
  & \mi{Hom_{\ms{id}}} &&: \Id\,(\mi{Hom}\,\id\,x)\,x\\
  & \mi{Hom_{\circ}}  &&: \Id\,(\mi{Hom}\,(f \circ g)\,x)\,(\mi{Hom}\,f\,(\mi{Hom}\,g\,x))
\end{alignat*}
We depart from the sugary naming scheme in Definition \ref{def:presheaf-type},
and name the action on objects $\mi{Obj}$ and the action on morphisms
$\mi{Hom}$. When we give semantics to this signature in Section \ref{sec:fqiit-semantics}, we
will get as algebras functors from $\mbbC^{\ms{op}}$ to the category of inner
types. That category has elements of $\Ty_0$ as objects and $\Tm_0\,A \to
\Tm_0\,B$ functions as morphisms.
\end{myexample}

\textbf{Strict positivity.} Only strictly positive signatures are expressible.
Similarly to the case with simple signatures, there is no way to abstract over a
inductive functions, since inductive function domains are in $\U$, and $\U$ has
no type formers at all. With $\Pie$, we can abstract over functions, but only on
ones which are external to a signature and don't depend on internally specified
constructors.

\section{Semantics}
\label{sec:fqiit-semantics}

\subsection{Overview}

For simple signatures, we only gave semantics in enough detail so that notions
of recursion and induction could be recovered. We aim to do more now. For each
signature, we would like to have
\begin{enumerate}
  \item A \emph{category} of algebras, with homomorphisms as morphisms.
  \item A notion of induction, which requires a notion of dependent algebras.
  \item A proof that for algebras, initiality is equivalent to supporting induction.
\end{enumerate}

We do this by creating a model of ToS where contexts (signatures) are categories
with certain extra structure and substitutions are structure-preserving
functors. Then, ToS signatures can be interpreted in this model, using the
initiality of ToS syntax (i.e.\ the recursor).

Our semantics has a type-theoretic flavor, which is inspired by the cubical set
model of Martin-Löf type theory by Bezem et al. \cite{cubicalmodel}. The idea is
to avoid strictness issues by starting from basic ingredients which are already
strict enough. Hence, instead of modeling ToS types as certain slices and
substitution by pullback, we model types as displayed categories with extra
structure, which naturally support strict reindexing/substitution.

We make a similar choice in the interpretation of signatures themselves: we use
structured cwfs of algebras, where types correspond to displayed algebras. This
choice is in contrast to having finitely complete categories of algebras.
Preliminarily, the reason is that ``native'' displayed algebras and sections
allow us to compute induction principles strictly as one would write in a type
theory. In fact, in this chapter we recover exactly the same semantics for
simple signatures that we already specified.

In contrast, displayed algebras are a derived notion in finitely complete
categories, and the induction principles would be only up to isomorphism.  This
issue is perhaps not relevant from a purely categorical perspective, but we are
concerned with eventually implementing QIITs in proof assistants. If we don't
compute induction principles here in an exact way, we don't get them from
anywhere else.

\subsection{Separate vs.\ Bundled Models}

Previously, we defined $\blank^A$, $\blank^M$, $\blank^D$ and $\blank^S$
interpretations of signatures separately, by doing induction anew for each
one. Formally, this amounts to giving a plain model of ToS in order to define
$\blank^A$, but then giving three \emph{displayed} models of ToS to specify the
other interpretations, because they sometimes need to refer to the recursors or
eliminators of other interpretations.

For example, $\blank^A : \Con \to \Set$ while $\blank^D : (\Gamma : \Con) \to
\Gamma^A \to \Set$, so displayed algebras already refer to $\blank^A$, which is
part of the recursor for the corresponding model.

However, this piecewise style can be avoided: we can give a single non-displayed
model which packs everything in a $\Sigma$-type, yielding just one
interpretation function for signatures. Let's call that function $\blank^M$ now:
\begin{alignat*}{5}
  & \blank^M : \Con &&\to \,&&(A &&: \Set)\\
  & &&\hspace{0.3em}\times &&(M  &&: A \to A \to \Set)\\
  & &&\hspace{0.3em}\times &&(D  &&: A \to \Set)\\
  & &&\hspace{0.3em}\times &&(S  &&: (a : A) \to D\,a \to \Set)
\end{alignat*}
Note that it is often not possible to merge multiple recursors/eliminators by
packing models together. For example, addition on natural numbers is defined by
recursion, and so is multiplication; but since multiplication calls addition in
an iterated fashion, it is not possible to define both operations by a single
algebra. Nevertheless, merging does work in our case. We will, in fact, get a
formal vocabulary for merging models (and manipulating them in other ways) from
the semantics of ToS itself.

In simple cases, and in Agda, the piecewise style is convenient, since we don't
have to deal with $\Sigma$-s. However, for larger models, important organizing
principles may become more apparent if we bundle things together.

In the following, we shall define a model $\bM : \ToS$ such that its $\Con$
component is a bundle containing all $A$, $M$, $D$, $S$ components, plus a
number of additional components. We present the components of $\bM$ in the same
order as in Definition \ref{def:fqiit-tos}. There is significant overlap in
names and notations, so we use \textbf{bold} font to disambiguate components of
$\bM$ from components of other structures. For example, we use $\bs{\sigma :
  \Sub\,\Gamma\,\Delta}$ to denote a substitution in $\bM$, while there could be
a $\Sub$-named components in other structures under consideration.

\subsection{Finite Limit Cwfs}

We define $\bCon : \Set$ as the type of finite limit cwfs. Recall that this
specifies the objects of the underlying cwf of $\bM$. In the following we
specify flcwfs and describe some internal constructions.

\begin{mydefinition}\label{def:flcwf}
We define $\flcwf : \Set$ as an iterated $\Sigma$-type with the following components:
\begin{enumerate}
  \item A cwf with $\Con$, $\Sub$, $\Ty$, $\Tm$ all returning in $\Set$. \emph{Remark:}
        this implies that $\flcwf : \Set$ is in a larger universe than all of these
        internal components. We continue to elide universe sizing details.
  \item $\Sigma$-types.
  \item Extensional identity type $\Id$ with $\refl$ and $\reflect$.
  \item Strict constant families $\K$.
\end{enumerate}
\end{mydefinition}
\begin{mydefinition}
We abbreviate the additional structure on cwfs consisting of $\Sigma$, $\Id$ and
$\K$ as \textbf{fl-structure}.
\end{mydefinition}

We recover previous concepts as follows. Assuming $\Gamma$ signature, we get an
flcwf by interpreting $\Gamma$ in $\bM$. In that flcwf we have
\begin{itemize}
  \item $\Con$ as the type of algebras.
  \item $\Sub$ as the type of algebra morphisms.
  \item $\Ty$ as the type of displayed algebras.
  \item $\Tm$ as the type of displayed algebra sections.
\end{itemize}
From this, notions of initiality and induction are apparent as well. Initiality
is the usual categorical notion. For induction, assuming $\bGamma : \bCon$, we
have the following predicate:
\begin{alignat*}{3}
  & \Inductive : \Con_{\bGamma} \to \Set\\
  & \Inductive\,\Gamma \defn (A : \Ty_{\bGamma}\,\Gamma)\ra \Tm_{\bGamma}\,\Gamma\,A
\end{alignat*}
In short, an algebra is inductive if every displayed algebra over it has a
section. Fortunately, we also know that induction and initiality are
equivalent.

\begin{theorem}\label{thm:initiality-induction}
An object $\Gamma : \Con_{\bGamma}$ in an flcwf $\bGamma$ supports induction if
and only if it is initial. Moreover, induction and initiality are both mere
properties.
\end{theorem}

\begin{proof}
First, we show that induction implies initiality. We assume $\Gamma : \Con$,
$\ms{ind} : \ms{Inductive}\,\Gamma$ and $\Delta : \Con$. We aim to show that
there is a unique inhabitant of $\Sub\,\Gamma\,\Delta$. We have
$\ms{ind}\,(\K\,\Delta) : \Tm\,\Gamma\,(\K\,\Delta)$, hence
$\ms{ind}\,(\K\,\Delta) : \Sub\,\Gamma\,\Delta$. We only need to show that this
is unique.  Assume $\delta : \Sub\,\Gamma\,\Delta$. Now,
$\ms{ind}\,(\Id\,\delta\,(\ms{ind}\,(\K\,\Delta))) :
\Tm\,\Gamma\,(\Id\,\delta\,(\ms{ind}\,(\K\,\Delta)))$, and it follows by
equality reflection that $\delta \equiv \ms{ind}\,(\K\,\Delta)$.

Second, the other direction. We assume that $\Gamma$ is initial, and also $A :
\Ty\,\Gamma$, and aim to inhabit $\Tm\,\Gamma\,A$. By initiality we get a unique
$\sigma : \Sub\,\Gamma\,(\Gamma \ext A)$. Now, $\q[\sigma] : \Tm\,\Gamma\,(A[\p \circ \sigma])$,
but since $\p \circ \sigma : \Sub\,\Gamma\,\Gamma$, it must be equal to $\id$ by the initiality
of $\Gamma$. Hence, $\q[\sigma] : \Tm\,\Gamma\,A$.

Lastly: it is well-known that initiality is a mere property, so let's show the
same for induction.  We assume $\ms{ind},\,\ms{ind'} : \ms{Inductive}\,\Gamma$
and $A : \Ty\,\Gamma$. We have
$\reflect\,(\ms{ind}\,(\Id\,(\ms{ind}\,A)\,(\ms{ind'}\,A))) : \ms{ind}\,A \equiv
\ms{ind'}\,A$. Since $A$ is arbitrary, by function extensionality we also have $\ms{ind} \equiv \ms{ind'}$.
\end{proof}

Note that the above proof does not rely on $\Sigma$-types in the flcwf, so why
do we include them in the semantics? One reason is the prior result by
Clairmabault and Dybjer \cite{clairambault2014biequivalence} that a slightly
different formulation of flcwfs is biequivalent to finitely complete
categories. More concretely, in ibid.\ there is a 2-category of cwfs with
$\Sigma$, $\Id$ and ``democracy'', the last of which is equivalent to the weak
formulation of constant families. Then, it is shown that this 2-category is
biequivalent to the 2-category of finitely complete categories. Thus, including
$\Sigma$ is a good deal, as this allows us to connect our semantics back to
finitely complete categories, which are more commonplace in categorical
settings.

We recover finite limits in an flcwf as follows. The product of $\Gamma$ and
$\Delta$ is given by $\Gamma \ext \K\,\Delta$, and we get projection and pairing
from context comprehension. The equalizer of $\sigma,\,\delta :
\Sub\,\Gamma\,\Delta$ is given by $\Gamma \ext \Id\,\sigma\,\delta$, which is
well-typed because morphisms can be viewed as terms, e.g.\ $\sigma :
\Tm\,\Gamma\,(\K\,\Delta)$. The unique morphism out of the equalizer is $\p :
\Sub\,(\Gamma \ext \Id\,\sigma\,\delta)\,\Gamma$.

Our flcwf is not exactly the same as in \cite{clairambault2014biequivalence}\,
because our constant families are strict. But we certainly don't lose anything
by having stricter semantics, since the weak version can be trivially
recovered.

In the following we present some concepts and results in flcwfs.

\begin{mydefinition}[Type categories, c.f.\ {\cite[Section 2.2]{clairambault2014biequivalence}}]
\label{def:type_categories} For each $\Gamma : \Con$, there is a category
whose objects are types $A : \Ty\,\Gamma$, and morphisms from $A$ to $B$ are
terms $t : \Tm\,(\Gamma\,\ext\,A)\,(B[\p])$. Identity morphisms are given by $\q
: \Tm\,(\Gamma\,\ext\,A)\,(A[\p])$, and composition $t \circ u$ by $t[\p,
  u]$. The assignment of type categories to contexts extends to a split indexed
category. For each $\sigma : \Sub\,\Gamma\,\Delta$, there is a functor from
$\Ty\,\Delta$ to $\Ty\,\Gamma$, which sends $A$ to $A[\sigma]$ and $t :
\Tm\,(\Gamma\,\ext\,A)\,(B[\p])$ to $t[\sigma\circ \p, \q]$.
\end{mydefinition}

\begin{notation}
  ~\\
  \begin{itemize}
  \item  \vspace{-1.7em}
         In any cwf, we use $\sigma : \Gamma \simeq \Delta$ to indicate
         that $\sigma : \Sub\,\Gamma\,\Delta$ is an isomorphism with inverse $\sigma^{-1}$.
    \item A \emph{type isomorphism}, written as $t : A \simeq B$ is an isomorphism in a
         type category, with inverse as $t^{-1}$.
  \end{itemize}
\end{notation}

\begin{theorem}[Equivalence of types and slices, c.f.\ {\cite[Section 2.2]{clairambault2014biequivalence}}]
Assume that we work in an flcwf $\bGamma$. For each $\Gamma : \Con$, the type
category $\Ty\,\Gamma$ is equivalent to the slice category $\bGamma/\Gamma$.
\end{theorem}

\emph{Remark.} In the flcwf of sets where types are $A \to \Set$ families, the
above theorem yields the equivalence of $A \to \Set$ and $(B : \Set) \times (B
\to A)$. This is sometimes called the ``family-fibration'' equivalence. It is
also a notable motivating example for univalence in type theory: it is not an
isomorphism of sets, but only an equivalence up to isomorphism of sets. So this
is an example for an equivalence which quite naturally arises even if we only
care about sets, but one which is not covered by set-level univalence, and
actually requires univalence for groupoids, if we want to prove it as a
propositional equality.

\subsection{The Cwf of Finite Limit Cwfs}

The next task is to define the cwf part of $\bM$. We already know that objects
are flcwfs.

\subsubsection{Category}

A \textbf{morphism} $\bsigma : \bSub\,\bGamma\,\bDelta$ is in an algebra
homomorphism, viewing flcwfs as algebraic structures. Hence, $\bsigma$ includes
a functor between underlying categories, but it also maps types to types and
terms to terms, and \emph{strictly preserves all structure}.

\begin{notation}
We may implicitly project out the underlying maps from $\bsigma$. Hence, we
have the following four maps:
\begin{alignat*}{3}
  & \bsigma &&: \Con_{\bGamma} \to \Con_{\bDelta} \\
  & \bsigma &&: \Sub_{\bGamma}\,\Gamma\,\Delta \to \Sub_{\bDelta}\,(\bsigma\,\Gamma)\,(\bsigma\,\Delta)\\
  & \bsigma &&: \Ty_{\bGamma}\,\Gamma \to \Ty_{\bDelta}\,(\bsigma\,\Gamma)\\
  & \bsigma &&: \Tm_{\bGamma}\,\Gamma\,A \to \Tm_{\bDelta}\,(\bsigma\,\Gamma)\,(\bsigma\,A)
\end{alignat*}
We list some of the preservation equations as examples of usage:
\begin{alignat*}{3}
  \bsigma\,\emptycon &\equiv \emptycon \\
  \bsigma\,(\Gamma \ext A) &\equiv \bsigma\,\Gamma \ext \bsigma\,A\\
  \bsigma\,(A[\sigma]) &\equiv (\bsigma\,A)[\bsigma\,\sigma]\\
  \bsigma\,(t[\sigma]) &\equiv (\bsigma\,t)[\bsigma\,\sigma]\\
  \bsigma\,(\Sigma\,A\,B) &\equiv \Sigma\,(\bsigma\,A)\,(\bsigma\,B)\\
  \bsigma\,(\proj_1\,t) &\equiv \proj_1\,(\bsigma\,t)
\end{alignat*}
Above, we could have also included subscripts indicating the $\bGamma$ or
$\bDelta$ flcwf, as in $\bsigma\,\emptycon_{\bGamma} \equiv
\emptycon_{\bDelta}$; but these are quite easily inferable, so we omit them.
\end{notation}

\textbf{Identity morphisms} and \textbf{composition} are defined in the evident
way using identity functions and function composition in underlying maps, and
they satisfy the category laws.

The terminal object $\bemptycon:\bCon$ is given by having $\Con_{\bemptycon} \defn
\top$, $\Sub_{\bemptycon}\,\Gamma\,\Delta \defn \top$, $\Ty_{\bemptycon}\,\Gamma \defn \top$ and
$\Tm_{\bemptycon}\,\Gamma\,A \defn \top$, and all structure and equations are defined trivially.

\subsubsection{Family structure}
\label{sec:fqiit-family}

A type $\bA : \bTy\,\bGamma$ is a displayed flcwf over $\bGamma$.  As we have
seen before, displayed algebras can be computed as logical predicate
interpretations of algebraic signatures. Every $\bA$ component lies over the
corresponding $\bGamma$ component. Also note that a displayed flcwf includes a
displayed category, for which some results have been worked out in
\cite{displayedcats}.

\begin{notation} In situations where we need to refer to both ``base'' and
displayed things, we give \ul{underlined} names to contexts, substitutions,
types and terms in a base flcwf. For example, we may have $\ulGamma :
\Con_{\bGamma}$ living in $\bs{\Gamma : \Con}$, and $\Gamma :
\Con_{\bA}\,\ulGamma$ living in a displayed flcwf over $\bGamma$. We only use
underlining on 2LTT variable names, and overload flcwf component names for
displayed counterparts. For example, a $\Con$ component is named the same in
a base flcwf and a displayed one.
\end{notation}

Concretely, a displayed flcwf $\bA$ over $\bGamma$ has the following underlying
sets, which we call displayed contexts, substitutions, types and terms
respectively.
\begin{alignat*}{3}
  & \Con_{\bA} && : \Con_{\bGamma}\ra \Set\\
  & \Sub_{\bA} && : \Con_{\bA}\,\ulGamma \ra \Con_{\bA}\,\ulDelta \ra \Sub_{\bGamma}\,\ulGamma\,\ulDelta \ra \Set \\
  & \Ty_{\bA}  && : \Con_{\bA}\,\ulGamma \ra \Ty_{\bGamma}\,\ulGamma \ra \Set\\
  & \Tm_{\bA}  && : (\Gamma : \Con_{\bA}\,\ulGamma)\ra \Ty_{\bA}\,\Gamma\,\ulA \ra \Tm_{\bGamma}\,\ulGamma\,\ulA \ra \Set
\end{alignat*}
We list select components of $\bA$ below; note how every $\bA$ operation lies
over the corresponding $\bGamma$ operation. In our notation with implicit
arguments, equations in $\bA$ can be written the same way as in $\bGamma$, but
of course there is extra indexing involved, and the displayed equations are
well-typed because of their counterparts in the base.
\begin{alignat*}{3}
  & \id_{\bA} &&: \Sub\,\Gamma\,\Gamma\,\ul{\id_{\bGamma}}\\
  & \blank\circ_{\bA}\blank &&: \Sub\,\Delta\,\Xi\,\ulsigma \to \Sub\,\Gamma\,\Delta\,\uldelta
    \to \Sub\,\Gamma\,\Xi\,(\ulsigma \circ_{\bGamma} \uldelta)\\
  & \ms{idl}_{\bA} &&:  \id_{\bA} \circ_{\bA} \sigma \equiv \sigma \\
  & \ms{idr}_{\bA} &&:  \sigma \circ_{\bA} \id_{\bA} \equiv \sigma \\
  & \emptycon_{\bA} && : \Con_{\bA}\,\emptycon_{\bGamma}\\
  & \blank\ext_{\bA}\blank && : (\Gamma : \Con_{\bA}\,\ulGamma)\ra \Ty_{\bA}\,\Gamma\,\ulA \ra
                     \Con_{\bA}\,\Gamma\,(\ulGamma \ext_{\bGamma} \ulA)\\
  & \blank[\blank]_{\bA} && : \Ty_{\bA}\,\Delta\,\ulA \ra \Sub_{\bA}\,\Gamma\,\Delta\,\ulsigma
                     \ra \Ty_{\bA}\,\Gamma\, (\ulA[\ulsigma]_{\bGamma})\\
  & \blank[\blank]_{\bA} && : \Tm_{\bA}\,\Delta\,A\,\ult \ra (\sigma : \Sub_{\bA}\,\Gamma\,\Delta\,\ulsigma)
                        \ra \Tm_{\bA}\,\Gamma\, (A[\sigma]_{\bA})\,(\ult[\ulsigma]_{\bGamma})\\
  &\Id_{\bA} &&: \Tm_{\bA}\,\Gamma\,A\,\ult \to \Tm_{\bA}\,\Gamma\,A\,\ulu \to \Ty_{\bA}\,\Gamma\,(\Id_{\bGamma}\,\ult\,\ulu)\\
  &\K_{\bA} &&: \Con_{\bA}\,\ulDelta \to \{\Gamma : \Con_{\bA}\,\ulGamma\} \to \Ty_{\bA}\,\Gamma\,(\K_{\bGamma}\,\ulDelta)\\
  &\Sigma_{\bA} &&: (A : \Ty_{\bA}\,\Gamma\,\ulA) \to \Ty_{\bA}\,(\Gamma \ext_{\bA} A)\,\ulB \to
                   \Ty_{\bA}\,\Gamma\,(\Sigma_{\bGamma}\,\ulA\,\ulB)
\end{alignat*}
In the following we will often omit $_{\bGamma}$ and $_{\bA}$ subscripts on
components; for example, in the type $\Con_{\bA}\,\emptycon$, the $\emptycon$ is
clearly a base component in $\bGamma$.

A substituted type $\bs{A[\sigma] : \Ty\,\Gamma}$ is defined as follows, for
$\bs{A : \Ty\,\Delta}$ and $\bs{\sigma : \Sub\,\Gamma\,\Delta}$. We simply compose
underlying functions in $\bsigma$ with the underlying predicates in $\bA$:
\begin{alignat*}{3}
  & \Con_{\bs{A[\sigma]}}\,\ulGamma && \defn \Con_{\bA}\,(\bsigma\,\ulGamma)\\
  & \Sub_{\bs{A[\sigma]}}\,\Gamma\,\Delta\,\ulsigma && \defn
    \Sub_{\bA}\,\Gamma\,\Delta\,(\bsigma\,\ulsigma)\\
  & \Ty_{\bs{A[\sigma]}}\,\Gamma\,\ulA && \defn
      \Ty_{\bA}\,\Gamma\,(\bsigma\,\ulA)\\
  & \Tm_{\bs{A[\sigma]}}\,\Gamma\,A\,\ult && \defn
      \Tm_{\bA}\,\Gamma\,A\,(\bsigma\,\ult)
\end{alignat*}
It should be clear that $\bs{A[\sigma]}$ thus defined still supports all
displayed flcwf structure. For example, the displayed contexts in
$\bs{A[\sigma]}$ are elements of $\Con_{\bA}\,(\bsigma\,\ulGamma)$, but since
$\bsigma$ preserves all $\bGamma$-structure, we can also recover all displayed
structure. For example, if $\ulGamma$ is $\ul{\emptycon}$, we have
$\bsigma\,\ul{\emptycon} \equiv \ul{\emptycon}$, and we can reuse
$\emptycon_{\bA} : \Con_{\bA}\,\ul{\emptycon}$ to define the displayed empty
context in $\bs{A[\sigma]}$, and we can proceed analogously for all other
structure in $\bs{A[\sigma]}$.

Additionally, type substitution is functorial, i.e.\ $\bs{A[\id]} \equiv \bA$
and $\bs{A[\sigma \circ \delta]} \equiv \bs{A[\sigma][\delta]}$. This holds
because the underlying set families are defined by function composition.

\emph{Remark.} Types could be equivalently defined as slices in the category of
flcws, and type substitution could be given as pullback, but in that case we
would run into the well-known strictness issue, that type substitution is
functorial only up to isomorphism \cite{TODO}. This is not a critical issue, as
there are standard solutions for recovering strict substitutions from weak ones
\cite{TODO}. But if we ever need to look inside the definitions in the model,
using displayed algebras yields a lot less encoding overhead than strictifying
pullbacks.

A term $\bs{t : \Tm\,\Gamma\,A}$ is a displayed flcwf section, which again
strictly preserves all structure. We use the same notation for the action of
$\bt$ that we use for $\bSub$. We have the following underlying maps:
\begin{alignat*}{3}
  & \bt &&: (\ulGamma : \Con_{\bGamma}) \to \Con_{\bA}\,\ulGamma \\
  & \bt &&: (\ulsigma : \Sub_{\bGamma}\,\Gamma\,\Delta) \to
             \Sub_{\bA}\,(\bt\,\Gamma)\,(\bt\,\Delta)\,\ulsigma\\
  & \bt &&: (\ulA : \Ty_{\bGamma}\,\Gamma) \to \Ty_{\bA}\,(\bt\,\Gamma)\,\ulA\\
  & \bt &&: (\ult : \Tm_{\bGamma}\,\Gamma\,A) \to \Tm_{\bA}\,(\bt\,\Gamma)\,(\bt\,A)\,\ult
\end{alignat*}

A substituted term $\bs{t[\sigma]}$ for $\bs{t : \Tm\,\Delta\,A}$ and
$\bs{\sigma : \Sub\,\Gamma\,\Delta}$ is again given by component-wise function
composition.

An extended context $\bs{\Gamma \ext A}$ is the \emph{total flcwf} of
$\bA$. This is defined by combining corresponding underlying sets with
$\Sigma$-types:
\begin{alignat*}{3}
  & \Con_{\bs{\Gamma \ext A}} &&\defn (\ulGamma : \Con_{\bGamma}) \times \Con_{\bA}\,\ulGamma\\
  & \Sub_{\bs{\Gamma \ext A}}\,(\ulGamma,\,\Gamma)\,(\ulDelta,\,\Delta) &&\defn (\ulsigma : \Sub_{\bGamma}\,\ulGamma\,\ulDelta) \times \Sub_{\bA}\,\Gamma\,\Delta\,\ulsigma\\
  & \Ty_{\bs{\Gamma \ext A}}\,(\ulGamma,\,\Gamma) &&\defn (\ulA : \Ty_{\bGamma}\,\ulGamma) \times \Ty_{\bA}\,\Gamma\,\ulA\\
  & \Tm_{\bs{\Gamma \ext A}}\,(\ulGamma,\,\Gamma)\,(\ulA,\,A) &&\defn (\ult : \Tm_{\bGamma}\,\ulGamma\,\ulA) \times \Tm_{\bA}\,\Gamma\,A\,\ult
\end{alignat*}
All structure is defined pointwise, using $\bGamma$-structure for first
projections and $\bA$-structure for second projections. $\bs{\Gamma \ext A}$ may
be viewed as a dependent generalization of direct products of flcwfs.

\textbf{Comprehension structure} follows from the above definition: $\bs{\p}$ is
component-wise first projection, $\bs{\q}$ is second projection and substitution
extension $\bs{\blank,\blank}$ is pairing.

With this, we have a cwf of flcws. \emph{Remark:} flcwf itself is algebraic, and
has a finitary QII signature. Hence, if we succeed building semantics for
finitary QII signatures, we get ``for free'' an flcwf of flcwfs. Of course, we
cannot rely on this when we're in the process of defining the $\bM$ model in the
first place. Checking that the $\bM$ model indeed works, is the somewhat tedious
task that we have to perform \emph{once}, in order to get semantics for any
other finitary QII theory.

\subsection{Type Formers}

\subsubsection{Strict constant families}

This was not included in the ToS specification, but it's quite useful, so we
shall define it. $\bs{\K\,\Delta : \Ty\,\Gamma}$ is defined by ignoring
$\bGamma$ inhabitants in all underlying sets:
\begin{alignat*}{3}
  & \Con_{\bs{\K\,\Delta}}\,\ulGamma &&\defn \Con_{\bDelta}\\
  & \Sub_{\bs{\K\,\Delta}}\,\Gamma\,\Delta\,\ulsigma &&\defn \Sub_{\bDelta}\,\Gamma\,\Delta\\
  &  \Ty_{\bs{\K\,\Delta}}\,\Gamma\,\ulA &&\defn \Ty_{\bDelta}\,\Gamma\\
  &  \Tm_{\bs{\K\,\Delta}}\,\Gamma\,A\,\ult &&\defn \Tm_{\bDelta}\,\Gamma\,A
\end{alignat*}
All structure is inherited from $\bDelta$. There is also a type substitution
rule, expressing that for $\bs{\sigma : \Sub\,\Gamma\,\Xi}$, we have
$\bs{(\K\,\{\Xi\}\,\Delta)[\sigma]} \equiv \bs{\K\,\{\Gamma\}\,\Delta}$. This
follows immediately from the above definition and the definition of type
substitution, since the base inhabitants are ignored the same way on both sides
of the equation. We also need to show $\bs{\Tm\,\Gamma\,(\K\,\Delta)} \equiv
\bs{\Sub\,\Gamma\,\Delta}$. This again follows directly from the $\bK$
definition. From $\bK$, we get
\begin{itemize}
\item The unit type, defined as $\bK\,\bemptycon : \bTy\,\bGamma$.
\item Direct products of $\bGamma$ and $\bDelta$, defined as $\bs{\Gamma \ext \K\,\Delta}$.
\item The ability to define closed type formers as elements of $\bCon$.
\end{itemize}

\subsubsection{Universe}

Similarly to what we did in Definition \ref{def:presheaf-univ}, we define $\bU$
as a context, and use $\bK$ later to get the universe as a type. $\bU :
\bCon$ is defined to be the flcwf where objects are inner types, and morphisms
are outer functions between them:
\begin{alignat*}{3}
  &\Con_{\bU} &&\defn \Ty_0 \\
  &\Sub_{\bU}\,\Gamma\,\Delta &&\defn \Tm_0\,\Gamma \to \Tm_0\,\Delta \\
  &\Ty_{\bU}\,\Gamma    &&\defn \Tm_0\,\Gamma \to \Ty_0\\
  &\Tm_{\bU}\,\Gamma\,A &&\defn (\gamma : \Tm_0\,\Gamma) \to \Tm_0\,(A\,\gamma)
\end{alignat*}
Substitution for types and terms is defined by function composition. The empty
context is defined as the inner unit type $\top_0$, and context extension
$\Gamma \ext_{\bU} A$ is defined as $(\gamma : \Gamma) \times A\,\gamma$ using
inner $\Sigma$. We can also define $\Sigma_{\bU}$ and $\Id_{\bU}$ using inner
$\Sigma$ and identity.

For constant families, we don't need any additional assumption in the inner
theory, since it can be defined as $\K_{\bU}\,\{\Gamma\}\,\Delta \defn \Delta$,
and $\Sub_{\bU}\,\Gamma\,\Delta \equiv \Tm_{\bU}\,\Gamma\,(\K_{\bU}\,\Delta)$
follows immediately.
\\\\
\indent For $\bs{a : \Sub\,\Gamma\,\U}$, we have to define $\bs{\El\,a :
  \Ty\,\Gamma}$. This is given as the \emph{displayed flcwf of elements} of
$\ba$.

Background: from any functor $F : \mbbC \to \bs{\Set}$ we can construct the
category of elements $\int\!F$, where objects are in $(i : |\mbbC|) \times F\,i$
and morphisms between $(i,\,x)$ and $(j,\,y)$ are in $(f : \mbbC(i,\,j)) \times
(F\,f\,x \equiv y)$. If we take the second projections of components in $\int\!F$,
we get the displayed category of elements, which lies over $\mbbC$. We may also call
this a \emph{discrete displayed category}, in analogy to discrete categories, whose
objects are elements of sets.

We extend this to flcwfs in the definition of $\bs{\El\,a}$. With this
definition, $\bs{\Gamma \ext \El\,a}$ will yield the flcwf of elements of $\ba$.
\begin{alignat*}{3}
  &\Con_{\bs{\El\,a}}\,\ulGamma &&\defn \Tm_0\,(\ba\,\ulGamma) \\
  &\Sub_{\bs{\El\,a}}\,\Gamma\,\Delta\,\ulsigma &&\defn \ba\,\ulsigma\,\Gamma \equiv \Delta \\
  &\Ty_{\bs{\El\,a}}\,\Gamma\,\ulA &&\defn \Tm_0\,(\ba\,\ulA\,\Gamma)\\
  &\Tm_{\bs{\El\,a}}\,\Gamma\,A\,\ult &&\defn \ba\,\ult\,\Gamma \equiv A
\end{alignat*}
Let's check that we have all other structure as well.
\begin{itemize}
  \item For contexts and types, the task is to exhibit elements of $\ba$ lying over
        specific base contexts and types.
  \item For terms and substitutions, the task is to exhibit equations which
    specify the action of $\ba$.
  \item Equations between terms and substitutions are trivial because of UIP (we need
    to show equations between equality proofs).
\end{itemize}
We summarize below the additional structure on top of the displayed category
part of $\bs{\El\,a}$.
\begin{itemize}
  \item
  For $\emptycon_{\bs{\El\,a}} : \Con_{\bs{\El\,a}}\,\ulemptycon$, the type can
  be simplified along the definition of $\Con_{\bs{\El\,a}}$ and
  structure-preservation by $\ba$ to $\Tm_0\,\top_0$. Hence,
  $\emptycon_{\bs{\El\,a}} \defn \tt_0$ is the unique definition. For $\epsilon
  : \Sub_{\bs{\El\,a}}\,\Gamma\,\emptycon_{\bs{\El\,a}}\,\ul{\epsilon}$, we have to show
  $\ba\,\ul{\epsilon}\,\Gamma \equiv \tt_0$, which holds by the uniqueness of $\tt_0$.


  \item
  For $\Gamma \ext_{\bs{\El\,a}} A : \Con_{\bs{\El\,a}}\,(\ulGamma \ext \ulA)$,
  the target type unfolds to $\Tm_0\,(\ba\,(\ulGamma \ext \ulA))$, which in
  turn simplifies to $\Tm_0\,((\gamma : \ba\,\ulGamma) \times \ba\,\ulA\,\gamma)$.
  Since $\Gamma : \Tm_0\,(\ba\,\ulGamma)$ and $A : \Tm_0\,(\ba\,\ulA\,\Gamma)$,
  we define $\Gamma \ext_{\bs{\El\,a}} A$ as $(\Gamma,\,A)$.

  \item
  For comprehension, we have to show the following, after simplifying types:
  \begin{alignat*}{3}
    & \p &&: \ba\,\ul{\p}\,(\Gamma,\,A) &&\equiv \Gamma \\
    & \q &&: \ba\,\ul{\q}\,(\Gamma,\,A) &&\equiv A \\
    & (\sigma,\,t) &&: \ba\,(\ulsigma,\,\ult)\,\Gamma &&\equiv (\Delta,\,A)
  \end{alignat*}
  For $\p$ and $\q$, equations follow from preservation by $\ba$. For pairing,
  the goal further simplifies to $(\ba\,\ulsigma\,\Gamma,\,\ba\,\ult\,\Gamma)
  \equiv (\Delta,\,A)$. Then, the first and second components are equal by
  the $\sigma$ and $t$ hypotheses.

  \item
  Assuming $A : \Ty_{\bs{\El\,a}}\,\Delta\,\ulA$ and $\sigma :
  \Sub_{\bs{\El\,a}}\,\Gamma\,\Delta\,\ulsigma$, we aim to define
  $A[\sigma]_{\bs{\El\,a}} :
  \Ty_{\bs{\El\,a}}\,\Gamma\,(\ulA[\ulsigma])$. Simplifying types, $A :
  \Tm_0\,(\ba\,\ulA\,\Delta)$, $\sigma : \ba\,\ulsigma\,\Gamma \equiv \Delta$
  and the target type is $\Tm_0\,(\ba\,(\ulA[\ulsigma])\,\Gamma)$, which is the
  same as $\Tm_0\,(\ba\,\ulA\,(\ba\,\ulsigma\,\Gamma))$, by the preservation of
  $\blank[\blank]$ by $\ba$. Hence, by the $\sigma$ assumption, the target
  type is $\Tm_0\,(\ba\,\ulA\,\Delta)$, so we give the following definition:
  \[
    A[\sigma]_{\bs{\El\,a}} \defn A
  \]
  This is clearly functorial; moreover, substitution rules for the other type
  formers hold trivially.
  \item Term substitution is given by transitivity of equality.

  \item For $\Id_{\bs{\El\,a}}\,t\,u : \Ty_{\bs{\El\,a}}\,\Gamma\,(\Id\,\ult\,\ulu)$,
    the goal type is $\Tm_0\,(\ba\,(\Id\,\ult\,\ulu)\,\Gamma)$, hence
    $\Tm_0\,(\ba\,\ult\,\Gamma = \ba\,\ulu\,\Gamma)$. This holds by
    $t : \ba\,\ult\,\Gamma \equiv A$ and $u : \ba\,\ult\,\Gamma \equiv A$.
    Reflexivity and equality reflection are trivial by UIP.

  \item
    For $A : \Ty_{\bs{\El\,a}}\,\Gamma\,\ulA$ and $B :
    \Ty_{\bs{\El\,a}}\,(\Gamma \ext A)\,\ulB$, we aim to define
    $\Sigma_{\bs{\El\,a}}\,A\,B :
    \Ty_{\bs{\El\,a}}\,\Gamma\,(\Sigma\,\ulA\,\ulB)$, hence
    \begin{alignat*}{3}
      &\Sigma_{\bs{\El\,a}}\,A\,B : \Tm_0\,(\ba\,(\Sigma\,\ulA\,\ulB)\,\Gamma)\\
      &\Sigma_{\bs{\El\,a}}\,A\,B : \Tm_0\,((A : \ba\,\ulA\,\Gamma) \times \ba\,\ulB\,(\Gamma,\,A))\\
      &\Sigma_{\bs{\El\,a}}\,A\,B \defn (A,\,B)
    \end{alignat*}
    Projections and pairing proceed analogously to what we did for comprehension.
  \item
  For $\K_{\bs{\El\,a}}\,\Delta : \Ty_{\bs{\El\,a}}\,\Gamma\,(\K\,\ulDelta)$,
  the target type simplifies to $\Tm_0\,(\ba\,\ulDelta)$, hence we have
  $\K_{\bs{\El\,a}}\,\Delta \defn \Delta$. For the specifying sort equation of $\K$,
  we have to show
  \[
  \Sub_{\bs{\El\,a}}\,\Gamma\,\Delta\,\ulsigma \equiv
  \Tm_{\bs{\El\,a}}\,\Gamma\,(\K_{\bs{\El\,a}}\,\Delta)\,\ulsigma
  \]
  where $\ulsigma : \Sub\,\ulGamma\,\ulDelta$ but at the same time $\ulsigma :
  \Tm\,\ulGamma\,(\K\,\ulDelta)$ because of the $\K$ sort equation in the base.
  Fortunately, both sides simplify to $\ba\,\ulsigma\,\Gamma \equiv \Delta$.
\end{itemize}

\noindent We still have to check $\bs{(\El\,a)[\sigma]} \equiv \bs{\El\,(a \circ
  \sigma)}$, the naturality rule for $\bEl$. We only have to check equality of
underlying sets, $\Con$ and $\Ty$ formers, since terms and substitutions are
equal by UIP. For underlying sets, both sides compute to the following:
\begin{alignat*}{3}
  &\Con\,\ulGamma &&\defn \Tm_0\,(\ba\,(\bsigma\,\ulGamma)) \\
  &\Sub\,\Gamma\,\Delta\,\ulsigma &&\defn \ba\,(\bsigma\,\ulsigma)\,\Gamma \equiv \Delta \\
  &\Ty\,\Gamma\,\ulA &&\defn \Tm_0\,(\ba\,(\bsigma\,\ulA)\,\Gamma)\\
  &\Tm\,\Gamma\,A\,\ult &&\defn \ba\,(\bsigma\,\ult)\,\Gamma \equiv A
\end{alignat*}
Since $\bsigma$ also strictly preserves all structure, and we simply replace $\ba$ action
by the composite $\bs{a \circ \sigma}$ action, it is straightforward to check that $\Con$
and $\Ty$ formers are also the same on both sides.

At this point, we have $\bs{\U : \Con}$ and $\bs{\El : \Sub\,\Gamma\,\U}$. Let's
rename them to $\bU'$ and $\bEl'$ respectively, and define the usual ``open''
versions:
\begin{alignat*}{3}
  &\bs{\U} : \bs{\Ty\,\Gamma} &&\bs{\El} : \bs{\Tm\,\Gamma\,\U} \to \bs{\Ty\,\Gamma}\\
  &\bs{\U} \defn \bs{\K\,\U'}\hspace{2em}&&\bs{\El}\,\ba \defn \bEl'\,\ba
\end{alignat*}

\subsubsection{Identity}

Assuming $\bs{t,\,u : \Tm\,\Gamma\,A}$, extensional identity $\bs{\Id\,t\,u}$ is
defined as component-wise equality:
\begin{alignat*}{3}
  & \Con_{\bs{\Id\,t\,u}}\,\ulGamma &&\defn \bt\,\ulGamma \equiv \bu\,\ulGamma\\
  & \Sub_{\bs{\Id\,t\,u}}\,\Gamma\,\Delta\,\ulsigma &&\defn \bt\,\ulsigma \equiv \bu\,\ulsigma\\
  & \Ty_{\bs{\Id\,t\,u}}\,\Gamma\,\ulA &&\defn \bt\,\ulA \equiv \bu\,\ulA\\
  & \Tm_{\bs{\Id\,t\,u}}\,\Gamma\,A\,\ult &&\defn \bt\,\ult \equiv \bu\,\ult
\end{alignat*}
All other structure follows from structure-preservation of $\bt$ and $\bu$. For
the simplest example, $\emptycon_{\bs{\Id\,t\,u}} : \bt\,\ulemptycon \equiv
\bu\,\ulemptycon$ holds because $\bt$ and $\bu$ both preserve $\ulemptycon$. The
rule $\bs{(\Id\,t\,u)[\sigma]} \equiv \bs{\Id\,(t[\sigma])\,(u[\sigma])}$ is
straightforward to check: we only have to look at the underlying sets, where
e.g. both sides have $\Con\,\ulGamma \equiv (\bt\,(\bsigma\,\ulGamma) \equiv
\bu\,(\bsigma\,\ulGamma))$. It's also evident that
$\bs{\Tm\,\Gamma\,(\Id\,t\,u)}$ is equivalent to $\bt \equiv \bu$, that is, we
have reflexivity and equality reflection.

\subsubsection{Inductive function type}

For $\bs{a : \Tm\,\Gamma\,\U}$ and $\bs{B : \Ty\,(\Gamma \ext \El\,a)}$, we aim
to define $\bs{\Pi\,a\,B : \Ty\,\Gamma}$. This is dependent product of displayed
flcwfs, indexed over a \emph{discrete} domain. Discreteness is critical: since
morphisms in $\bs{\El\,a}$ are proof-irrelevant and invertible (because they are
equations), we avoid the variance issues that preclude general $\Pi$-types in
the cwf of categories \cite[Secion~A1.5]{johnstone2002sketches}.

The direct definition would be to define underlying sets as products, indexed
over corresponding components in $\bs{\El\,a}$:
\begin{alignat*}{3}
  & \Con_{\bs{\Pi\,a\,B}}\,\ulGamma &&\defn (\gamma : \ba\,\ulGamma) \to \Con_{\bB}\,(\ulGamma,\,\gamma)\\
  & \Sub_{\bs{\Pi\,a\,B}}\,\Gamma\,\Delta\,\ulsigma &&\defn
    \{\gamma : \ba\,\ulGamma\}\{\delta : \ba\,\ulDelta\}(\sigma : \Sub_{\bs{\El\,a}}\,\gamma\,\delta\,\ulsigma) \to \Sub_{\bB}\,(\Gamma\,\gamma)\,(\Delta\,\delta)\,(\ulsigma,\,\sigma)\\
  & \Ty_{\bs{\Pi\,a\,B}}\,\Gamma\,\ulA &&\defn
    \{\gamma : \ba\,\ulGamma\}(\alpha : \ba\,\ulA\,\gamma) \to \Ty_{\bB}\,(\Gamma\,\gamma)\,(\ulA,\,\alpha)\\
  & \Tm_{\bs{\Pi\,a\,B}}\,\Gamma\,A\,\ult &&\defn
    \{\gamma : \ba\,\ulGamma\}\{\alpha : \ba\,\ulA\,\gamma\}(t : \Tm_{\bs{\El\,a}}\,\gamma\,\delta\,\ult)
      \to
    \Tm_{\bB}\,(\Gamma\,\gamma)\,(\A\,\alpha)\,(\ult,\,t)
\end{alignat*}
But just like in Definitions \ref{def:simple-morphism} and
\ref{def:simple-section}, we can contract the $\Sub$ and $\Tm$ definitions,
since $\Sub_{\bs{\El\,a}}\,\gamma\,\delta\,\ulsigma \equiv
(\ba\,\ulsigma\,\gamma \equiv \delta)$ and
$\Tm_{\bs{\El\,a}}\,\gamma\,\alpha\,\ult \equiv (\ba\,\ult\,\gamma \equiv
\alpha)$.
\begin{alignat*}{3}
  & \Con_{\bs{\Pi\,a\,B}}\,\ulGamma &&\defn (\gamma : \ba\,\ulGamma) \to \Con_{\bB}\,(\ulGamma,\,\gamma)\\
  & \Sub_{\bs{\Pi\,a\,B}}\,\Gamma\,\Delta\,\ulsigma &&\defn
    (\gamma : \ba\,\ulGamma)\to \Sub_{\bB}\,(\Gamma\,\gamma)\,(\Delta\,(\ba\,\ulsigma\,\gamma))\,(\ulsigma,\,\refl)\\
  & \Ty_{\bs{\Pi\,a\,B}}\,\Gamma\,\ulA &&\defn
  \{\gamma : \ba\,\ulGamma\}(\alpha : \ba\,\ulA\,\gamma)
  \to \Ty_{\bB}\,(\Gamma\,\gamma)\,(\ulA,\,\alpha)\\
  & \Tm_{\bs{\Pi\,a\,B}}\,\Gamma\,A\,\ult &&\defn
    (\gamma : \ba\,\ulGamma) \to \Tm_{\bB}\,(\Gamma\,\gamma)\,(\A\,(\ba\,\ult\,\gamma))\,(\ult,\,\refl)
\end{alignat*}
With the contracted definition, $\Sub$ and $\Tm$ are only indexed over displayed
objects, but not over displayed morphisms or terms anymore. So it is apparent
that we cannot have issues with indexing variance. All structure in
$\bs{\Pi\,a\,B}$ is pointwise inherited from $\bB$. We list some examples below
for definitions.
\begin{alignat*}{3}
  &\emptycon_{\bs{\Pi\,a\,B}}\,\gamma &&\defn \emptycon_{\bB}\\
  &(\Gamma \ext_{\bs{\Pi\,a\,B}} A)\,(\gamma,\,\alpha) &&\defn (\Gamma\,\gamma \ext_{\bB} A\,\alpha)\\
  &\id_{\bs{\Pi\,a\,B}}\,\gamma &&\defn \id_{\bB}\\
  &(\sigma \circ_{\bs{\Pi\,a\,B}} \delta)\,\gamma &&\defn \sigma\,\gamma \circ_{\bB} \delta\,\gamma\\
  &A[\sigma]_{\bs{\Pi\,a\,B}}\,\{\gamma\}\,\alpha &&\defn (A\,\alpha)[\sigma\,\gamma]_{\bB}\\
  &\K_{\bs{\Pi\,a\,B}}\,\Delta\,\alpha &&\defn \K_{\bB}\,(\Delta\,\alpha)
\end{alignat*}

For the specifying isomorphism $\bs{(\app,\,\lam) : \Tm\,\Gamma\,(\Pi\,a\,B)
  \simeq \Tm\,(\Gamma \ext \El\,a)\,B}$, note that the difference in
presentation is exactly component-wise currying and uncurrying. For instance, in
$\bs{t : \Tm\,\Gamma\,(\Pi\,a\,B)}$, the underlying action on contexts has the following
type:
\[
  (\ulGamma : \Con_{\bGamma})(\gamma : \ba\,\ulGamma) \to \Con_{\bB}\,(\ulGamma,\,\gamma)
\]
While in $\bs{t : \Tm\,(\Gamma \ext \El\,a)\,B}$, we have
\[
  ((\ulGamma,\,\gamma) : (\ulGamma : \Con_{\bGamma}) \times \ba\,\ulGamma) \to \Con_{\bB}\,(\ulGamma,\,\gamma)
\]
So $\bs{\app}$ and $\bs{\lam}$ are defined as component-wise uncurrying and
currying respectively.  Naturality of $\bs{\Pi}$ and $\bs{\app}$ again follows
from the fact that flcwf morphisms strictly preserve all structure, and
substitution is component-wise function composition.

\subsubsection{External function type}

For $\Ix : \Ty_0$ and $\bB : \Tm_0\,\Ix \to \bs{\Ty\,\Gamma}$, we define
$\bs{\Pie}\,\Ix\,\bB : \bs{\Ty\,\Gamma}$ as the $\Ix$-indexed direct product of
a family of displayed flcwfs.
\begin{alignat*}{3}
  & \Con_{\bs{\Pie}\,\Ix\,\bB}\,\ulGamma &&\defn (i : \Tm_0\,\Ix) \to \Con_{\bB\,i}\,\ulGamma\\
  & \Sub_{\bs{\Pie}\,\Ix\,\bB}\,\Gamma\,\Delta\,\ulsigma &&\defn (i : \Tm_0\,\Ix) \to \Sub_{\bB\,i}\,(\Gamma\,i)\,(\Delta\,i)\,\ulsigma\\
  &  \Ty_{\bs{\Pie}\,\Ix\,\bB}\,\Gamma\,\ulA &&\defn (i : \Tm_0\,\Ix) \to \Ty_{\bB\,i}\,(\Gamma\,i)\,\ulA\\
  &  \Tm_{\bs{\Pie}\,\Ix\,\bB}\,\Gamma\,A\,\ult &&\defn (i : \Tm_0\,\Ix) \to \Tm_{\bB\,i}\,(\Gamma\,i)\,(A\,i)\,\ult
\end{alignat*}
All structure is defined in the evident pointwise way. $\bs{\appe}$ and $\bs{\lame}$ are
defined by component-wise flipping of function arguments.

\todo{Examples for computed semantics here maybe}

\section{Discussion of Semantics}

\subsection{Flcwfs For Free}

We give a quick summary for using the semantics of FQII signatures. As input we
pick a) a signature $\Gamma$ b) a cwf $\mbbC$ with $\Sigma$, $\top$ and
extensional $\Id$. Then, we interpret the signature in $\bM$, thereby getting an
flcwf in 2LTT. Then, we interpret that in presheaves over $\mbbC$, and we get
the flcwf whose objects are internal $\Gamma$-algebras in $\mbbC$.

One use case is in building models of certain type theories. Usually, this
starts with constructing the base cwf. But if the objects can be specified using
an FQII signature, we get an flcwf for free. In some cases, we get exactly
what's needed. For example, the flcwf of presheaves can be used as it is in the
presheaf models of type theories.

In other cases, the flcwf that we get ``for free'' has to be extended in some
ways. This often happens if the objects in the model have an internal notion of
``equivalence'' which has to be respected by types.
\begin{itemize}
  \item In the setoid model, objects are setoids and types are displayed
    setoids with additional fibrancy structure \cite{TODO}.
  \item The groupoid model \cite{hofmann96groupoidmodel} is analogous; again types are displayed groupoids
    with fibrancy structure.
  \item Likewise, in the cubical set model \cite{cubical}, types are displayed
    presheaves together with fibrancy structure (Kan composition).
\end{itemize}

In all these cases, the semantic objects have FQII signatures. We can interpret
their flwcfs in $\bs{\Set}$ and add fibrancy conditions. The cubical set model
is presented exactly in this way in \cite{cubical}, using displayed
algebras. The groupoid model in \cite{hofmann96groupoidmodel} instead presents
types as $\bs{\Gamma} \to \bs{\ms{Gpd}}$ functors, i.e.\ uses an indexed style
instead of the displayed style.

In the indexed-style groupoid model, we get strictly functorial type
substitution, just like in the displayed style. However, the displayed style
appears to be a more general way to get strict substitution, as it works for
every FQII theory. Again, although finitely complete categories can be always
strictified to cwfs, if we ever need to perform calculations with the
internal definitions of a model, the displayed style is much more compact.

\subsection{Variations of the Semantics}

In Section \ref{sec:fqiit-tos}, we required that the inner theory has $\Sigma$,
$\top$ and extensional $\Id$. Hence, when we interpret a signature, we again
need to assume these type formers in $\mbbC$. We used the assumed type formers
in the definition of $\bU$.

However, we can drop $\Id$ from the requirements on the inner theory, and
likewise drop the identity type from flcwfs, and the model still works. In this
case we have a somewhat more general semantics. In particular, like in Section
\ref{sec:2ltt-simple-algebras}, we can interpret signatures in finite product
categories, because $\top$ and $\Sigma$ can be derived from finite products in
the constructed ``simply typed'' cwf. On the other hand, we get less out of the
semantics. For instance, we cannot show equivalence of initiality and induction
without $\Id$.

If we want to trim down the assumptions on the inner theory to the minimum, we
can make do with simply an inner cwf with no type formers at all. This
implies that for each signature we can build a category of algebras, plus extra
structure which does not require $\Sigma$ or $\top$ in the $\bU$ definition. So
we may have displayed algebras, sections, and also functorial substitution for
these, but we don't have terminal algebras and total algebras (i.e.\ $\blank\!\ext_{\bU}\!\blank$).

We could also add more type formers to the semantics. We may add \emph{small
  limits} via the external function type $\Pie$ that we already have in
signatures. Extending flcwfs with $\Pie$ requires $\Pi$-types in the inner
theory of 2LTT, hence in $\mbbC$ as well. The reason is that indexed products of
algebras require functions in the underlying sorts. More concretely, in the
definition of $\bU$, we have to interpret
\[
  \Pie_{\bU} : (\Ix : \Ty_0) \to (\Tm_0\,\Ix \to \Ty_{\bU}\,\Gamma) \to \Ty_{\bU}\,\Gamma
\]
hence
\[
  \Pie_{\bU} : (\Ix : \Ty_0) \to (\Tm_0\,\Ix \to \Tm_0\,\Gamma \to \Ty_0) \to \Tm_0\,\Gamma \to \Ty_0
\]
This works if we can return an inner $\Pi$ in the definition:
\[
  \Pie_{\bU}\,\Ix\,B\,\gamma \defn (i : \Ix) \to B\,i\,\gamma
\]
In this case, the ``small limit'' cwf semantics can be completed. We omit
checking the details here. From $\Pie$, we also recover indexed products, by
using $\Pie\,\Ix\,(\lambda\,i.\,\K\,\Gamma_i)$, where $\Gamma_i$ is an indexed
family of objects.

With the small limit semantics, if we want to have a simply typed
interpretation, we can start with a cartesian closed $\mbbC$.

\subsection{Substitutions}

Interpreting signatures is not the only potentially useful thing that we get out
of the semantics. Each $\sigma : \Sub\,\Gamma\,\Delta$ can be viewed as a free
interpretation of the $\Delta$ theory in $\Gamma$, and we get a strict flcwf
morphism from the semantics.

\subsubsection{Ornaments}

One use case of $\Sub$ is to specify \emph{ornaments} \cite{TODO}, i.e.\ ways
to decorate structures with additional information, or dually, to erase parts of
some structure. Ornaments differ from the usual forgetful maps, because they
forget structure in \emph{negative} position, i.e.\ in assumptions of
construction rules.

\begin{myexample}
We assume $A : \Ty_0$. We define the substitution which forgets elements of
$A$-lists.
\begin{alignat*}{3}
  & \sigma : \Sub\,&&
  (\emptycon \ext (\mi{Nat} : \U) \ext (\mi{zero} : \El\,\mi{Nat}) \ext (\mi{suc} : \mi{Nat}))\\
  & &&(\emptycon \ext (\mi{List} : \U) \ext (\mi{nil} : \El\,\mi{List}) \ext (\mi{cons} : A \toe \mi{List} \to \mi{List}))
\end{alignat*}
The map goes from numbers to lists because of the ``contravariant''
forgetfulness. We define $\sigma$ by listing its component definitions.
\begin{alignat*}{3}
  &\mi{List} &&\defn \mi{Nat}\\
  &\mi{nil} &&\defn \mi{zero}\\
  &\mi{cons} &&\defn \lambda^{ext}\,\_.\,\lambda\,n.\,\mi{suc}\,n
\end{alignat*}
\end{myexample}

\begin{myexample}
  We assume $\Nat_0 : \Ty_0$ with $\zero_0$ and $\suc_0$, and define $\sigma : \Sub\,\ms{NatSig}\,\ms{FinSig}$, where $\ms{FinSig}$ is as follows:
\begin{alignat*}{3}
  &\mi{Fin}  &&: \Nat_0 \toe \U\\
  &\mi{zero} &&: (n : \Nat_0) \toe \El\,(\mi{Fin}\,(\suc_0\,n))\\
  &\mi{suc}  &&: (n : \Nat_0) \toe \mi{Fin}\,n \to \El\,(\mi{Fin}\,(\suc_0\,n))
\end{alignat*}
$\sigma$ is defined as
\begin{alignat*}{3}
  &\mi{Fin}  &&\defn \mi{Nat}\\
  &\mi{zero} &&\defn \lambda^{ext}\,\_.\,\mi{zero}\\
  &\mi{suc}  &&\defn \lambda^{ext}\,\_.\,\lambda\,n.\,\mi{suc}\,n
\end{alignat*}
\end{myexample}
For a specific programming use case, if we have any recursive function defined
on an ``erased'' type, we can convert that to a recursive function which acts on
an ``ornamented'' type. For example, if we have some $\Nat$-algebra $\Gamma$,
the recursor yields a morphism from the initial algebra to $\Gamma$. We can map
$\Gamma$ to a list-algebra or a $\ms{Fin}$-algebra, and then we can also use
recursors for lists or $\ms{Fin}$. Equivalently, we can map the unique morphism
to $\Gamma$ directly to a morphism between ornamented algebras.

Note though that a number of features and concepts from prior work on ornaments
are not yet reproduced. For example, we don't yet have an analogue of
\emph{algebraic ornaments}, which would allow us produce an ornamented signature
as an \emph{output} of a generic operation, instead of assuming it to begin
with. Exploring ornaments with QII signatures could be part of future work.

\subsubsection{Model constructions}

In a broader context, ToS provides a synthetic language for specifying
\emph{model constructions}.

\begin{myexample}
For a simple example, we might want to show that constant families are
equivalent to democracy in cwfs. Democracy means that for each $\Gamma : \Con$
there is a $\overline{\Gamma} : \Ty\,\emptycon$ such that $\Gamma \simeq
(\emptycon\ext\overline{\Gamma})$ \cite[Section~3.1]{flccc-undecidability}.

We can define a $\sigma : \Sub\,\ms{cwf^K}\,\ms{cwf^{dem}}$ which interprets
democracy using constant families. It is the identity morphism on the cwf parts
and interprets democracy as $\overline{\Gamma} \defn \ms{K}\,\Gamma$. The
isomorphism $\Gamma \simeq (\emptycon \ext \K\,\Gamma)$ follows from the
specification of $\K$. We can also define a morphism $\sigma^{-1} :
\Sub\,\ms{cwf^K}\,\ms{cwf^{dem}}$, which interprets $\K\,\Delta$ as
$\overline{\Delta}[\epsilon]$. It is easy to check that $\sigma^{-1}$ is indeed
the inverse of $\sigma$. Thus we get an isomorphism of categories of models
from the ToS semantics.

This construction is very simple, and would not be difficult to check without
the ToS semantics. But it is generally not obvious that a certain mapping from
models to models extends to a functor (or flcwf-morphism), so it may be helpful
to work inside ToS.
\end{myexample}

\begin{myexample}
There is a simple way to show that if a type theory does not support $\eta$ for
$\Pi$, then function extensionality is not provable in the theory
\cite{next700}\footnote{It is also possible to show unprovability of function
extensionality \emph{assuming} $\eta$ for functions, but in significantly more
complicated ways. To the author's best knowledge, the set-based polynomial model
is the easiest solution \cite{TODO}.}.  Assume some type theory with $\Sigma$,
$\Pi$, $\Id$ and $\Bool$, and abbreviate its signature as $\ms{TT}$. We define a
$\sigma : \Sub\,\ms{TT}\,\ms{TT}$ which has identity action everywhere except on
$\Pi$. There, we have
\begin{alignat*}{3}
  &\Pi    &&\defn \lambda\,A\,B.\,\Pi\,A\,B \times \Bool \\
  &\app   &&\defn \lambda\,t.\,\app\,(\proj_1\,t)\\
  &\lam   &&\defn \lambda\,t.\,(\lam\,t,\,\true)
\end{alignat*}
In short, we tag functions with a $\Bool$ value. This equips $\Pi$ with
``intensional'' information, contradicting extensionality. If we have two
functions which are pointwise equal, that only specifies that the function parts
are equal, but does not say anything about the $\Bool$ tags. Hence, if we take
any model of $\ms{TT}$, we get a new model by the semantic action of $\sigma$,
where function extensionality is false. Note though that the $\eta$ rule also
fails in the new model, so we had to drop $\eta$ from the $\ms{TT}$ signature
as well.

In \cite{next700}, this construction is presented for the special case where the
starting model is initial. While it is easy to generalize to arbitrary starting
models, it is less obvious to extend the construction to a functor of categories
of models - which we do get for free here.
\end{myexample}

\textbf{Limitations.} In the finitary ToS syntax, when defining substitutions
(that is, model constructions) we can only ever use assumed type constructors.
For a counter-example, take the substitution in
$\Sub\,\ms{MonoidSig}\,\ms{CatSig}$ which maps a monoid to a single-object
category. Assuming $\ms{M} : \U$ is the carrier set in $\ms{MonoidSig}$, we would
need to have the following:
\begin{alignat*}{3}
  &\ms{Obj} &&\defn \top \\
  &\ms{Hom} &&\defn \lambda\,\_\,\_.\, \ms{M}
\end{alignat*}
But we have $\Obj : \U$ in $\ms{CatSig}$, so we would need to have $\top : \U$.
In Chapter \ref{chap:iqiit}, we present a more expressive ToS which does include
$\top : \U$, and it will be sufficient to rephrase a wide range of constructions
as signature substitutions.

\subsection{Recovering AMDS Interpretations}

We have defined the $\bM$ model in a ``bundled'' fashion, but sometimes we will
also need to refer to pieces of it. On Figure \ref{fig:fqiit-model} we have a
summary of the model. On the left, the rows are labeled with components of ToS,
while on the top we have components of flcwf. The individual rows can be further
unfolded, as each of them contains multiple components. Likewise the $\Sigma$,
$\Id$ and $\K$ columns can be unfolded. We get the whole model by filling every
cell of the unfolded table with a definition. Of course, many of these cells are
equations between equations, hence trivial by UIP.

This setup is very regular and convenient, because we can extract a displayed
ToS model from any column, which may depend on columns to the left. The whole
model is the total model of all columns. For example, the $\Con$ column doesn't
depend on anything, so it's a plain model. The $\Ty$ column is displayed over
$\Con$. The $\Tm$ column depends on $\Con$ and $\Ty$, but it does not depend on $\Sub$.

From each displayed model, we get an eliminator, i.e.\ a family of
interpretation functions. We note $\blank^A$, $\blank^M$, $\blank^D$ and
$\blank^S$ in the table, but in principle we could refer to the eliminators of
other columns as well. The interpretation functions can be defined in two ways:
\begin{itemize}
\item By separately taking the eliminators of each column, and referring to previous
      eliminators in each displayed model; e.g.\ referring to the eliminator functions $\blank^A$ in
      the definition of the $\Ty$ column.
\item By taking the recursor for the entire model, and projecting out components from the result. E.g.\
      we get $\blank^A$ by projecting out the first components of the interpretations of ToS objects.
\end{itemize}
However, the two versions coincide because of the initiality of ToS syntax.


\begin{figure}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|  }
 \hline
   & \multicolumn{5}{|c|}{cwf} & \multicolumn{3}{c|}{fl}\\
 \cline{2-9}
   & $\Con$ & $\Sub$ & $\Ty$ & $\Tm$ & $...$ & $\Sigma$ & $\Id$ & $\K$ \\
 \hline
   cwf    & \multirow{5}{2em}{$\blank^A$}&\multirow{5}{2em}{$\blank^M$}&\multirow{5}{2em}{$\blank^D$}&\multirow{5}{2em}{$\blank^S$}& & & & \\
   $\U$   &                              &              &                  &    & & & & \\
   $\Id$  &                              &              &                  &    & & & & \\
   $\Pi$  &                              &              &                  &    & & & & \\
   $\Pie$ &                              &              &                  &    & & & & \\
 \hline
\end{tabular}
\end{center}
\caption{The flcwf model of the theory of signatures}
\label{fig:fqiit-model}
\end{figure}


\section{Term Algebras}
\label{sec:fqiit-term-algebras}

In this section we proceed with the construction of term algebras for FQII
signatures, together with their recursors and eliminators. First we make two
significant modifications to the setup.
\\\\
\indent First, \textbf{we drop the outer theory}, and work exclusively inside an
extensional type theory. The reason is the following. The main purpose of 2LTT
is to generalize the semantics of signatures. In the previous section, we
presented semantics for signatures, where algebras are internal to arbitrary
cwfs with $\Sigma$, $\top$ and extensional $\Id$. This is quite general; in
particular we can interpret signatures in any finitely complete category. We
also allowed dropping $\Id$ from the assumptions.


In contrast, we make a lot more assumptions in the inner theory when we develop
initial term algebras; we essentially have to replicate the outer features
verbatim.  Thus, we gain nothing by using 2LTT, compared to working in a model
of an extensional TT.

What about the term model construction for simple signatures in Section
\ref{sec:simple-2ltt-term-algebras}, why did we use 2LTT there? In that case,
the inner theory was \emph{intensional}, i.e.\ lacked equality reflection. So
there remained an interesting distinction between the inner and outer layer,
which allowed us to prove \emph{definitional} $\beta$-rules for recursors. In
contrast, here we assume inner equality reflection, so we have no distinction
between propositional and definitional inner equality.
\\\\
\indent Second, \textbf{we make universe levels explicit} in the semantics and
constructions. So far, we have been consistently ignoring universe levels. Now,
size questions are less obvious, and quite relevant to a) ensuring the
consistency of assumed induction principles b) laying groundwork for
bootstrapped semantics and self-describing signatures in Chapter \ref{TODO}. In
the following, we describe the new universe setup, and adapt the previously
described signatures and semantics to it.

\subsection{Universes \& Metatheory}
\label{sec:cumulative-ett}

We have countable Russell-style $\Set_i$ universes, which are \emph{cumulative},
meaning that any type in $\Set_i$ is also an element of $\Set_{i+1}$. We use a
surface syntax which is similar to Coq, where cumulativity is implicit. This
contrasts the formal (``algebraic'') specification of cumulativity
\cite{sterling2019algebraic,kovacs2021generalized}, which involves a substantial
amount of explicit annotations.

Also following Coq, we have implicit \emph{cumulative subtyping}
\cite{timany18cumulative}. In our case, this means that cumulativity commutes
through basic type formers. Concretely, we have a $\blank\!\leq\!\blank$
subtyping relation on types, specified by the following rules:
\begin{figure}
\begin{mathpar}
  \inferrule*{i \leq j}
             {\Gamma \vdash \Set_i \leq \Set_j}

  \inferrule*{\Gamma,\,x : A \vdash B \leq B'}
             {\Gamma \vdash (x : A)\ra B \leq (x : A)\ra B'}

  \inferrule*{\Gamma\vdash A \leq A' \\ \Gamma,\,x : A \vdash B \leq B'}
             {\Gamma \vdash (x : A)\times B \leq (x : A') \times B'}

  \inferrule*{\\}
             {\Gamma \vdash A \leq A}

  \inferrule*{\Gamma \vdash A \leq B \\ \Gamma\vdash B \leq C}
             {\Gamma \vdash A \leq C}

  \inferrule*{\Gamma\vdash A \leq A' \\ \Gamma\vdash t : A}
             {\Gamma \vdash t : A'}
\end{mathpar}
\caption{Rules for cumulative subtyping}
\label{fig:cumulativity}
\end{figure}
These rules specify subtyping for \emph{surface syntax}; it is expected that
surface syntax can be elaborated to \emph{coercions} in a formal syntax with
algebraic cumulativity.

Note that we have an \emph{invariant} rule for function domain types. This is to
match Coq and \cite{timany18cumulative}, and also because we will not need a
contravariant rule in any case.

We assume that $\Pi$ and $\Sigma$ types return in least upper bounds of levels. For instance,
assuming $A : \Set_i$ and $B : A \to \Set_j$, we have $(x : A) \to B : \Set_{i \lub j}$.

\subsection{Signatures \& Semantics}
\label{sec:ett-signatures}

First, we parameterize the notion of ToS-model with levels.
\begin{mydefinition}
\label{def:ftos-models}
For levels $i$ and $j$, $\ToS_{i,j} : \Set_{i+1\lub j+1}$ is the type of ToS
models, defined as before, but where $\Con$, $\Sub$, $\Ty$ and $\Tm$ all return
in $\Set_i$, and $\Pie$ abstracts over $\Set_j$.
\end{mydefinition}

We have that $\ToS_{i,j} \leq \ToS_{i+1,j}$. This follows from the rules
in Figure \ref{fig:cumulativity}. All underlying sets return in $\Set_i$, which
can be bumped to $\Set_{i + 1}$.  Th $j$ level doesn't change, which is as
expected, since $\Set_j$ appears in a negative position in the type of $\Pie$,
and has to be invariant.

\textbf{Assumption.} We assume that for all $j$, there exists an inhabitant of
$\syn_j : \ToS_{j+1,j}$ which supports induction. Note the level bump in the first index;
this is to avoid inconsistency from type-in-type:
\begin{alignat*}{3}
  &\Ty &&: \Con \to \Set_{j+1}\\ &\Pie &&: (A : \Set_j) \to (A \to \Ty\,\Gamma)
  \to \Ty\,\Gamma
\end{alignat*}
With $\Ty$ returning in $\Set_j$, $\Pie$ would ``contain'' a $\Set_j$, but at
the same time return in a type in $\Set_j$, and by induction we would be able to
derive a Russell-like paradox \cite{TODO}. Likewise, all other underlying sets
must be bumped to $\Set_{j+1}$, because of their mutual nature: contexts, terms
and substitutions all ``contain'' types through some of their constructors.

\begin{mydefinition}[\textbf{Signatures}]
We define $\Sig_j : \Set_{j+1}$ as the type of signatures where $\Pie$ may
abstract over $\Set_j$, so we have $\Sig_j \defn \Con_{\syn_j}$.
\end{mydefinition}

\begin{mydefinition}[\textbf{Flwcf model}]
For levels $i$ and $j$, we have $\bM_{i,j} : \ToS_{(i+1\lub j)+1,j}$ as the
model where contexts are flcwfs, and objects in the flcwf are algebras.  The
model is defined in essentially the same way as in Section
\ref{sec:fqiit-semantics}. The algebras have underlying sets in $\Set_i$ and
(semantic) external functions have types in $\Set_j$ as domain. Hence, every
algebra in $\bM_{i,j}$ is in $\Set_{i+1\lub j}$.
\end{mydefinition}

\begin{myexample}
We may define $\ms{NatSig}$ as an element of $\Sig_0$. Then, by interpreting the
signature in $\bM_{i,0}$, we get $\ms{NatSig}^A \equiv (N : \Set_i) \times (N
\to N) \times N$, hence $\ms{NatSig}^A : \Set_{i + 1 \lub 0}$.
\end{myexample}

\begin{notation}
For a signature $\Gamma : \Sig_j$ and level $i$, we may write $\Gamma^A_i$ for
the type of $\Gamma$-algebras with underlying sets in $\Set_i$, which is
computed by interpreting $\Gamma$ in $\bM_{i,j}$. We may use similar notation
for $\blank^M$, $\blank^D$ and $\blank^S$.
\end{notation}

\noindent\textbf{Cumulativity of algebras.} In the following, we shall assume
that for $\Gamma : \Sig_j$ and $i \leq i'$, we have $\Gamma^A_i \leq
\Gamma^A_{i'}$. For any concrete signature $\Gamma$, this is clearly the case,
but $\blank\!\leq\!\blank$ is not subject to propositional reasoning, so we
cannot prove this by internal induction on signatures. We could prove that there
exists a \emph{lifting}, a $\ms{Lift}\,\Gamma^A_i : \Set_{i'+1 \lub j}$
which is isomorphic to $\Gamma^A_{i}$. Instead, we take liberties, and work as
if we had actual cumulative subtyping. This seems acceptable, since by using
implicit cumulativity, we are already taking the same liberty everywhere, by
omitting formal lifts and isomorphisms.

\subsection{Term Algebra Construction}
\label{sec:fqii-term-algebra-construction}

\label{sec:fqiit-term-algebras}
We fix $\Omega : \Sig_j$ for some $j$ level. We define $\blank^T$ by induction
on $\syn_j$. In the following we write $\blank^A$ for $\blank^A_{j+1}$,
i.e.\ the algebra interpretation where underlying sets are in
$\Set_{j+1}$. Formally, we need a displayed model over $\syn_j$, but we instead
present the resulting eliminator, which is perhaps easier to read. The
underlying functions have the following types.
\begin{alignat*}{3}
  &\blank^T &&: (\Gamma : \Con)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^A\\
  &\blank^T &&: (\sigma : \Sub\,\Gamma\,\Delta)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Delta^T\,(\sigma \circ \nu) \equiv \sigma^A\,(\Gamma^T\,\nu)\\
  &\blank^T &&: (A : \Ty\,\Gamma)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Tm\,\Omega\,(A[\nu])
  \to A^A\,(\Gamma^T\,\nu)\\
  &\blank^T &&: (t : \Tm\,\Gamma\,A)&&(\nu : \Sub\,\Omega\,\Gamma) \to A^T\,\nu\,(A[\nu]) \equiv t^A\,(\Gamma^T\,\nu)
\end{alignat*}
We review the idea of term algebras. In any model of ToS, we might think of a
$\Sub\,\emptycon\,\Gamma$ as a $\Gamma$-algebra internal to the model. In the
$\blank^T$ interpretation we can assume $\Omega \equiv \emptycon$; this means
that from any internal $\Gamma$-algebra, in any model of ToS, we can extract an
``external'' $\Gamma$-algebra. This is possible because every sort $a :
\Tm\,\Gamma\,\U$ in ToS induces an external type of terms as
$\Tm\,\Gamma\,(\El\,a)$.

We can view the generalization from $\emptycon$ to arbitrary $\Omega$ as
switching from working in the syntactic model $\syn_j$, to working in the
\emph{slice model} $\syn_j/\Omega$, where contexts are $\Omega$ extended with
zero or more entries. And in $\syn_j/\Omega$, we have an $\Omega$-algebra quite
trivially, by taking the identity morphism $\id :
\Sub\,\Omega\,\Omega$\footnote{Writing $\blank^{\syn_j/\Omega}$ for the interpretation
of syntax in the slice model,
$\Sub_{\syn_j/\Omega}\,\emptycon\,(\Omega^{\syn_j/\Omega})$ is isomorphic to, but not
strictly the same as $\Sub_{\syn_j}\,\Omega\,\Omega$.}. Hence, term algebras
arise by first taking the trivial internal algebra $\id$ in $\syn_j/\Omega$,
then converting it to an external algebra as $\Omega^T\,\id : \Omega^A$.

\emph{Remark.} We could have presented $\blank^T$ and slice models in an
explicit separate way. We instead chose to merge them into the current
$\blank^T$, since we don't use slice models elsewhere, and we can skip their
definition this way. Slice models would require the specification of
\emph{telescopes}, used to extend the base context, but this entails a fair
amount of bureaucratic detail.

We explain the $\blank^T$ specification in the following. Term and substitution
equations are given by UIP. We omit cases for substitutions and terms.

For \textbf{contexts}, we simply recurse on the entries. We use a pattern
matching notation for
$\Sub\,\Omega\,(\Gamma\ext A)$, since any $\nu$ with
this type is uniquely determined by its first and second projections
$\p\circ\nu$ and $\q[\nu]$.
\begin{alignat*}{3}
  &\emptycon^T\,\nu           &&\defn \tt\\
  &(\Gamma \ext A)^T(\nu,\,t) &&\defn (\Gamma^T\,\nu,\,A^T\,\nu\,t)
\end{alignat*}
\textbf{Type substitution} with $\sigma : \Sub\,\Gamma\,\Delta$ is as follows. This is well-typed by
$\sigma^T\,\nu : \Delta^T\,(\sigma \circ \nu) \equiv \sigma^A\,(\Gamma^T\,\nu)$.
\[ (A[\sigma])^T\,\nu\,t \defn A^T\,(\sigma\circ\nu)\,t \]
For the \textbf{universe}, note that $\U^A_{j+1}\,\gamma \equiv \Set_{j+1}$.  As we
mentioned before, this is the key part when we map from internal sorts to
external sets. The levels line up, since in $\syn_j$ we have $\Tm$ returning in $\Set_{j+1}$.
\begin{alignat*}{3}
  &\U^T : (\nu : \Sub\,\Omega\,\Gamma) \to \Tm\,\Omega\,\U \to
          \Ty\\
  &\U^T\,\nu\,a \defn \Tm\,\Omega\,(\El\,a)
\end{alignat*}
For $\El$, we have to define
\[
  (\El\,a)^T : (\nu : \Sub\,\Omega\,\Gamma)
          \to \Tm\,\Omega\,(\El\,(a[\nu])) \to a^A\,(\Gamma^T\,\nu)
\]
but since $a^T\,\nu : \Tm\,\Omega\,(\El\,(a[\nu]))
      \equiv a^A\,(\Gamma^T\,\nu)$, we have
\begin{alignat*}{3}
  &(\El\,a)^T : (\nu : \Sub\,\Omega\,\Gamma)
          \to \Tm\,\Omega\,(\El\,(a[\nu])) \to \Tm\,\Omega\,(\El\,(a[\nu]))\\
  &(\El\,a)^T\,\nu\,t \defn t
\end{alignat*}
The $a^T\,\nu$ equation is worth noting. If we have $\nu \equiv \id$, the
equation is $a^T\,\id : \Tm\,\Omega\,(\El\,a) \equiv
a^A\,(\Omega^T\,\id)$, that is, if we evaluate a signature sort in the term
model $\Omega^T\,\id$, we get a type of inner terms.

For the \textbf{identity type}, we have to show that provably equal terms are evaluated
to the same value in the term model.
\begin{alignat*}{3}
  &(\Id\,t\,u)^T : (\nu : \Sub\,\Omega\,\Gamma)
    \to \Tm\,\Omega\,(\Id\,(t[\nu])\,(u[\nu])) \to t^A\,(\Gamma^T\,\nu) \equiv u^A\,(\Gamma^T\,\nu)
\end{alignat*}
We know by equality reflection that $t[\nu] \equiv u[\nu]$, and
we also get
\begin{alignat*}{3}
  &t^T\,\nu &&: A^T\,\nu\,(t[\nu]) &&\equiv t^A\,(\Gamma^T\,\nu)\\
  &u^T\,\nu &&: A^T\,\nu\,(u[\nu]) &&\equiv u^A\,(\Gamma^T\,\nu)
\end{alignat*}
from which the target equality follows. Equality reflection for inner $\Id$ is
crucial here. It is the reason why $\blank^T$ works for \emph{quotient
signatures}; equality reflection is in fact the ``quotient'' rule which
identifies provably equal terms. For a simple example, terms with type
\[
  \Tm\,
  (\emptycon \ext (I : \U) \ext (\mi{left} : \El\,I) \ext (\mi{right} : \El\,I) \ext (\mi{seg} : \Id\,l\,r))\,
  (\El\,I)
\]
are quotiented by $\mi{seg}$, which is a provable equation in the context.

For the \textbf{inductive function type}, we have to convert an inner term with
$\Pi$ type to an outer function.
\begin{alignat*}{3}
  &(\Pi\,a\,B)^T : (\nu : \Sub\,\Omega\,\Gamma)
                 &&\to \Tm\,\Omega\,(\Pi\,(a[\nu])\,(B[\nu\circ\p,\,\q]))\\
  &              &&\to (\alpha : a^A\,(\Gamma^T\,\nu)) \to B^A\,(\Gamma^T\,\nu,\,\alpha)\\
  &\rlap{$(\Pi\,a\,B)^T\,\nu\,t \defn \lambda\,\alpha.\,B^T\,(\nu,\,\alpha)\,(t\,\alpha)$}
\end{alignat*}
This is well-typed by $a^T\,\nu :
\Tm\,\Omega\,(\El\,(a[\nu])) \equiv
a^A\,(\Gamma^T\,\nu)$, which allows us to consider $\alpha$ to be an inner term
in $\lambda\,\alpha.\,B^T\,(\nu,\,\alpha)\,(t\,\alpha)$.

For the \textbf{external function type} we just recurse through the specifying
isomorphism:
\begin{alignat*}{3}
  &(\Pie\,A\,B)^T : (\nu : \Sub\,\Omega\,\Gamma)
                 &&\to \Tm\,\Omega\,(\Pie\,A\,(\lambda\,\alpha.\,(B\,\alpha)[\nu]))\\
  &              &&\to (\alpha : A) \to (B\,\alpha)^A\,(\Gamma^T\,\nu)\\
  &\rlap{$(\Pie\,A\,B)^T\,\nu\,t \defn \lambda\,\alpha.\,(B\,\alpha)^T\,(\nu,\,\alpha)$}
\end{alignat*}
This concludes the definition of $\blank^T$.

\begin{mydefinition}
For an $\Omega : \Con_{\syn_j}$ signature, the corresponding \textbf{term
algebra} is given as $\Omega^T\,\id : \Omega^A_{j+1}$.
\end{mydefinition}

\emph{Remark.} If we start with a signature in $\syn_j$, then the underlying
sets in the term algebra are all in $\Set_{j+1}$. Hence, the term algebra for
$\NatSig : \Sig_0$ has an underlying set in $\Set_1$. This is perhaps
inconvenient, since normally we would have natural numbers in $\Set_0$. However,
we argue that this is no issue, because we are free to specify $\Set_0$ as we
like. In particular, we can say that $\Set_0$ is an \emph{empty universe},
closed under no type formers at all (or explicitly isomorphic to $\bot$) in
which case $\Sig_0$ stands for \emph{closed} signatures (since $\Pie$ cannot be
constructed), and it is expected that any closed inductive type would be placed
in $\Set_1$. Alternatively, we could name the bottom-most universe
$\Set_{empty}$ or $\Set_{-1}$, and start counting non-empty universes from
$\Set_0$.

\subsection{Recursor Construction}

We continue with the construction of recursors. This is not necessary, strictly
speaking, since recursion is derivable from elimination, so it would suffice to
only construct eliminators. We still present recursors, for the sake of matching
the presentation in Chapter \ref{chap:simple-inductive-signatures}. Also, the
Böhm-Beraducci encodings in Section \ref{TODO} will support recursion but not
elimination, so it makes sense to try to ``warm up'' to that case as well.

The goal is to construct a morphism from a term algebra to any other $\omega
: \Omega^A$ algebra. However, we have to handle universe levels as well. We want
to be able to eliminate from the term algebra, which was constructed at the
lowest possible level, to any other universe. Right now we don't have a notion
of ``heterogeneous'' morphism, between algebras at different levels.  We prefer
to skip this, and keep matters as simple as possible. We do the following:
\begin{itemize}
  \item We assume $\Omega : \Sig_j$, for which we already have the term algebra $\Omega^T\,\id : \Omega^A_{j+1}$.
  \item We assume some $k \geq j + 1$, and an $\omega : \Omega^A_{k}$, the target of recursion.
  \item We implicitly lift $\Omega^T\,\id$ from level $j + 1$ to level $k$ by cumulativity, and construct
        a ``homogeneous'' morphism from the lifted term algebra to $\omega$.
\end{itemize}
This allows us to eliminate from $\Omega^T\,\id$ to any level. If we want to
eliminate to $k \geq j + 1$, we can lift the term algebra, and use a constructed
recursor. On the other hand, if we want to eliminate to $k < j + 1$, we can
instead lift the target $\omega : \Omega^A_{k}$ algebra to $j + 1$, and again
use a constructed recursor.

\todo{maybe give example}

We define $\blank^R$ by induction on $\syn_j$. From this, we will obtain the
recursor as $\Omega^R\,\id$.
\begin{alignat*}{3}
  &\blank^R &&: (\Gamma : \Con)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^M\,(\nu^A\,(\Omega^T\,\id))\,(\nu^A\,\omega)\\
  &\blank^R &&: (\sigma : \Sub\,\Gamma\,\Delta)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Delta^R\,(\sigma \circ \nu) \equiv \sigma^M\,(\Gamma^R\,\nu)\\
  &\blank^R &&: (A : \Ty\,\Gamma)&&(\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(A[\nu]))
     \to A^M\,(t^A\,(\Omega^T\,\id))\,(t^A\,\omega)\,(\Gamma^R\,\nu)\\
  &\blank^R &&: (t : \Tm\,\Gamma\,A)&&(\nu : \Sub\,\Omega\,\Gamma) \to A^R\,\nu\,(t[\nu]) \equiv t^M\,(\Gamma^R\,\nu)
\end{alignat*}
\todo{Maybe do an appendix with full AMDS}
Let's refresh some details about the involved operations.
\begin{itemize}
\item For $\nu : \Sub\,\Gamma\,\Delta$, we get $\nu^A : \Gamma^A \to \Delta^A$. In the semantics, $\nu$
  is a functor, and $\nu^A$ is its action on objects. Analogously, for a term $\Tm\,\Gamma\,A$, we
  have $t^A : (\gamma : \Gamma^A) \to A^A\,\gamma$, also an action on objects.
\item
  $\Gamma^M$ is the set of $\Gamma$-morphisms. $A : \Ty\,\Gamma$ is a displayed
  flcwf in the semantics. $A^M$ yields sets of displayed morphisms,
  corresponding to the semantic $\Sub$ component. So we have
  \[ A^M : A^A\,\gamma_0 \to A^A\,\gamma_1 \to \Gamma^M\,\gamma_0\,\gamma_1 \to \Set_{k} \]
\item $t^M$ and $\sigma^M$ yield actions on morphisms. For $t : \Tm\,\Gamma\,A$ and $\sigma : \Sub\,\Gamma\,\Delta$, we have
  \begin{alignat*}{3}
    &t^M      &&: (\gamma^M : \Gamma^M\,\gamma_0\,\gamma_1) \to A^M\,(t^A\,\gamma_0)\,(t^A\,\gamma_1)\,\gamma^M\\
    &\sigma^M &&: (\gamma^M : \Gamma^M\,\gamma_0\,\gamma_1) \to \Delta^M\,(\sigma^M\,\gamma_0)\,(\sigma^M\,\gamma_1)
  \end{alignat*}
\end{itemize}

Again, we follow the ``sliced'' pattern that we have seen in the term model
construction. Another way to view this, is that getting term algebras or
recursors by direct induction on signatures is futile, since in the
construction we have to refer to the \emph{whole} $\Omega$ signature, but when
we recurse inside $\Omega$ we necessarily get \emph{smaller} signatures.

Hence, the sliced induction can be viewed as induction on arbitrary $\Gamma$
signatures which are smaller than $\Omega$, in the sense that there is a
$\Sub\,\Omega\,\Gamma$. Of course, $\Sub\,\Omega\,\Gamma$ includes ``being
smaller'', but it is more general.

We look at the interpretation of type formers. Again, term and substitution
equations are given by UIP, and we omit term and substitution formers.  For
\textbf{contexts}, we again simply recurse:
\begin{alignat*}{3}
  &\emptycon^R\,\nu           &&\defn \tt\\
  &(\Gamma \ext A)^R(\nu,\,t) &&\defn (\Gamma^R\,\nu,\,A^R\,\nu\,t)
\end{alignat*}
\textbf{Type substitution} with $\sigma : \Sub\,\Gamma\,\Delta$ also follows
the same pattern. The following is well-typed by $\sigma^R\,\nu : \Delta^R\,(\sigma\circ\nu) \equiv \sigma^M\,(\Gamma^R\,\nu)$.
\[ (A[\sigma])^R\,\nu\,t \defn A^R\,(\sigma\circ\nu)\,t \]
For the \textbf{universe}, we have the following.
\begin{alignat*}{3}
  &\U^R : (\nu : \Sub\,\Omega\,\Gamma)(a : \Tm\,\Omega\,\U) \to \U^M\,(a^A\,(\Omega^T\,\id))\,(a^A\,\omega)\,(\Gamma^R\,\nu)
\end{alignat*}
Morphisms in the semantics of $\U$ are simply functions. Moreover, we have
$a^T\,\id : \Tm\,\Omega\,(\El\,a) \equiv a^A\,(\Omega^T\,\id)$.
\begin{alignat*}{3}
  &\U^R : (\nu : \Sub\,\Omega\,\Gamma)(a : \Tm\,\Omega\,\U) \to \Tm\,\Omega\,(\El\,a) \to a^A\,\omega\\
  &\U^R\,\nu\,a\,t \defn t^A\,\omega
\end{alignat*}
Thus, we evaluate $t$ in the $\omega$ algebra, the same way as we did in Chapter
\ref{chap:simple-inductive-signatures}.
\\\\
\noindent For \textbf{$\El$}, we need to show
\[
  (\El\,a)^R : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Gamma\,(\El\,(a[\nu]))) \to a^M\,(\Gamma^R\,\nu)\,(t^A\,(\Omega^T\,\id)) \equiv t^A\,\omega
\]
We have $a^R\,\nu : U^R\,\nu\,(a[\nu]) \equiv a^M\,(\Gamma^R\,\nu)$. Hence,
$U^R\,\nu\,(a[\nu])\,t \equiv a^M\,(\Gamma^R\,\nu)\,t$, and by computing $\U^R$
we have $t^A\,\omega \equiv a^M\,(\Gamma^R\,\nu)\,t$. The target equation then
follows by $t^T\,\id : t^A\,(\Omega^T\,\id) \equiv t$.
\\\\
\noindent For \textbf{the identity type}, we need to show:
\[
(\Id\,t\,u)^R : (\nu : \Sub\,\Omega\,\Gamma)(e : \Tm\,\Gamma\,(\Id\,(t[\nu])\,(u[\nu])))
  \to t^M\,(\Gamma^R\,\nu) \equiv u^M\,(\Gamma^R\,\nu)
  \]
This follows from equality reflection on $e$, together with
\begin{alignat*}{3}
  & t^R\,\nu &&: A^R\,\nu\,(t[\nu]) \equiv t^M\,(\Gamma^R\,\nu)\\
  & u^R\,\nu &&: A^R\,\nu\,(u[\nu]) \equiv u^M\,(\Gamma^R\,\nu)
\end{alignat*}
For the \textbf{inductive function type}, we get the following target type after unfolding $(\Pi\,a\,B)^M$:
\begin{alignat*}{3}
 &(\Pi\,a\,B)^R : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\Pi\,(a[\nu])\,(B[\nu\circ\p,\,\q])))\\
 & \hspace{2em}\to (\alpha : a^A\,(\nu^A\,(\Omega^T\,\id))) \to B^M\,(t^A\,(\Omega^T\,\id)\,\alpha)\,(t^A\,\omega\,(a^M\,(\Gamma^R\,\nu)\,\alpha))\,(\Gamma^R\,\nu,\,\refl)
\end{alignat*}
We have
\begin{alignat*}{3}
  & \nu^T\,\id &&: \Gamma^T\,\nu \equiv \nu^A\,(\Omega^T\,\id) \\
  & a^T\,\nu   &&: a^A\,(\Gamma^T\,\id) \equiv \Tm\,\Omega\,(\El\,(a[\nu]))
\end{alignat*}
Hence, $a^A\,(\nu^A\,(\Omega^T\,\id)) \equiv \Tm\,\Omega\,(\El\,(a[\nu]))$. We
also have $a^R\,\nu : (\lambda\,\alpha.\,\alpha^A\,\omega) \equiv a^M\,(\Gamma^R\,\nu)$, therefore
$\alpha^A\,\omega \equiv a^M\,(\Gamma^R\,\nu)$. With this in mind, the goal type can be rewritten as
\begin{alignat*}{3}
 &(\Pi\,a\,B)^R : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\Pi\,(a[\nu])\,(B[\nu\circ\p,\,\q])))\\
 & \hspace{2em}\to (\alpha : \Tm\,\Omega\,(\El\,(a[\nu]))) \to B^M\,(t^A\,(\Omega^T\,\id)\,\alpha)\,(t^A\,\omega\,(\alpha^A\,\omega))\,(\Gamma^R\,\nu,\,\refl)
\end{alignat*}
We have the following typing now:
\[
  B^R\,(\nu,\,\alpha)\,(t\,\alpha) : B^M\,((t\,\alpha)^A\,(\Omega^T\,\id))\,((t\,\alpha)^A\,\omega)\,(\Gamma^T\,\nu,\,\refl)
\]
By the action of $\blank^A$ on inductive function application, we have
\[
   B^R\,(\nu,\,\alpha)\,(t\,\alpha) :
      B^M\,(t^A\,(\Omega^T\,\id)\,(\alpha^A\,(\Omega^T\,\id)))\,(t^A\,\omega\,(\alpha^A\,\omega))\,(\Gamma^T\,\nu,\,\refl)
\]
But since $\alpha^T\,\id : \alpha^A\,(\Omega^T\,\id) \equiv \alpha$, this is
exactly the target type. Therefore the definition is:
\[
  (\Pi\,a\,B)^R\,\nu\,t \defn \lambda\,\alpha.\,B^R\,(\nu,\,\alpha)\,(t\,\alpha)
\]
For the \textbf{external function type}, we again simply recurse through the indexing:
\begin{alignat*}{3}
  & (\Pie\,A\,B)^R : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\Pie\,A\,(\lambda\,\alpha.\,(B\,\alpha)[\nu])))\\
  & \hspace{2em}\to (\alpha : A) \to (B\,\alpha)^M\,(t^A\,(\Omega^T\,\id)\,\alpha)\,(t^A\,\omega\,\alpha)\,(\Gamma^R\,\nu)\\
  &(\Pie\,A\,B)^R\,\nu\,t \defn \lambda\,\alpha.\,(B\,\alpha)^R\,\nu\,(t\,\alpha)
\end{alignat*}
This concludes the definition of $\blank^R$.

\begin{mydefinition}[\textbf{Recursors}]
Assuming $\Omega : \Sig_j$, a $k$ level such that $k \geq j + 1$ and $\omega :
\Omega^A_{k}$, we have $\Omega^R\,\id : \Omega^M\,(\Omega^T\,\id)\,\omega$ as
the recursor for the term algebra.
\end{mydefinition}

\subsection{Eliminator Construction}
\label{sec:fqii-eliminator-construction}

We assume $\Omega : \Sig_j$ and $\omega^D : \Omega^D_{k}\,(\Omega^T\,\id)$,
where $k \geq j + 1$. Again we implicitly lift the term algebra from level $j+1$
to $k$. Here, $\omega^D$ is a displayed algebra over the term algebra. We seek
to construct an inhabitant of $\Omega^S\,(\Omega^T\,\id)\,\omega^D$. We define
$\blank^E$ by induction.

Constructing eliminators is on the whole quite similar to the recursor
construction. The switch from morphisms to sections is mechanical. We shall only
look at $\U$, $\El$ and $\Pi$ here.
\begin{alignat*}{3}
  &\blank^E &&: (\Gamma : \Con)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^S\,(\nu^A\,(\Omega^T\,\id))\,(\nu^D\,\omega^D)\\
  &\blank^E &&: (\sigma : \Sub\,\Gamma\,\Delta)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Delta^E\,(\sigma \circ \nu) \equiv \sigma^S\,(\Gamma^E\,\nu)\\
  &\blank^E &&: (A : \Ty\,\Gamma)&&(\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(A[\nu]))
     \to A^S\,(t^A\,(\Omega^T\,\id))\,(t^D\,\omega^D)\,(\Gamma^E\,\nu)\\
  &\blank^E &&: (t : \Tm\,\Gamma\,A)&&(\nu : \Sub\,\Omega\,\Gamma) \to A^E\,\nu\,(t[\nu]) \equiv t^S\,(\Gamma^E\,\nu)
\end{alignat*}
For the \textbf{universe}, we have the following.
\begin{alignat*}{3}
  &\U^E : (\nu : \Sub\,\Omega\,\Gamma)(a : \Tm\,\Omega\,\U) \to (\alpha : a^A\,(\Omega^T\,\id)) \to a^D\,\omega^D\,\alpha
\end{alignat*}
By $a^T\,\id : a^A\,(\Omega^T\,\id) \equiv \Tm\,\Omega\,(\El\,a)$, we can give the following definition:
\begin{alignat*}{3}
  &\U^E : (\nu : \Sub\,\Omega\,\Gamma)(a : \Tm\,\Omega\,\U) \to (\alpha : \Tm\,\Omega\,(\El\,a)) \to a^D\,\omega^D\,\alpha\\
  &\U^E\,\nu\,a\,\alpha \defn \alpha^D\,\omega^D
\end{alignat*}
In other words, we evaluate $\alpha$ in the $\omega^D$ displayed algebra. Let's check that this is well-typed:
\begin{alignat*}{3}
  & \alpha^D &&: \{\omega : \Omega^A\}(\omega^D : \Omega^D\,\omega) \to a^D\,\omega^D\,(\alpha^A\,\omega)\\
  & \alpha^D\,\omega^D &&: a^D\,\omega^D\,(\alpha^A\,(\Omega^T\,\id) \\
  & \alpha^T\,\id      &&: \alpha^A\,(\Omega^T\,\id) \equiv \alpha
\end{alignat*}
Thus $\alpha^D\,\omega^D : a^D\,\omega^D\,\alpha$. Recall that $\alpha^D$ can
be viewed as the logical predicate interpretation of $\alpha$, which expresses
that $\alpha^A$ preserves $\blank^D$ predicates.
\\\\
\noindent For \textbf{$\El$}, we need to show
\[
  (\El\,a)^S : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Gamma\,(\El\,(a[\nu]))) \to a^S\,(\Gamma^E\,\nu)\,(t^A\,(\Omega^T\,\id)) \equiv t^D\,\omega^D
\]
This follows from $t^T\,\id : t^A\,(\Omega^T\,\id) \equiv t$ and $a^E\,\nu : (\lambda\,t.\,t^D\,\omega^D) \equiv a^S\,(\Gamma^E\,\nu)$.
\\\\
\noindent The \textbf{inductive function} interpretation is defined similarly as before:
\begin{alignat*}{3}
 &(\Pi\,a\,B)^E : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\Pi\,(a[\nu])\,(B[\nu\circ\p,\,\q])))\\
 & \hspace{2em}\to (\alpha : \Tm\,\Omega\,(\El\,(a[\nu]))) \to B^S\,(t^A\,(\Omega^T\,\id)\,\alpha)\,(t^D\,\omega^D\,(\alpha^D\,\omega^D))\,(\Gamma^E\,\nu,\,\refl)\\
 &\rlap{$(\Pi\,a\,B)^E\,\nu\,t \defn \lambda\,\alpha.\,B^E\,(\nu,\,\alpha)\,(t\,\alpha)$}
\end{alignat*}
We make use of $\nu^T\,\id$, $u^T\,\id$, $a^E\,\nu$ and $a^T\,\nu$ to type-check the definition.

Interpretations for contexts and other type formers are also essentially the same as with recursors.

\begin{mydefinition}[\textbf{Eliminators}]
\label{def:fqiit-eliminator}
Assuming $\Omega : \Sig_j$, a $k$ level such that $k \geq j + 1$ and $\omega^D :
\Omega^D_{k}\,(\Omega^T\,\id)$, we have $\Omega^E\,\id : \Omega^S\,(\Omega^T\,\id)\,\omega^D$ as
the eliminator.
\end{mydefinition}

\begin{theorem}
  $\Omega^T\,\id$ is initial when lifted to any $k \geq j + 1$ level.
\end{theorem}
\begin{proof}
  $\Omega^T\,\id : \Omega^A_{k}$ supports elimination by Definition \ref{def:fqiit-eliminator},
  and elimination is equivalent to initiality by Theorem \ref{thm:initiality-induction}.
\end{proof}


\todo{Some discussion, blah blah}
\todo{Should we just pare down elims/recursors and put them in an appendix?}

\section{Levitation and Bootstrapping for Closed Signatures}
\label{sec:closed-levitation}

When we previously introduced the ToS, we only specified the notion of model,
and simply assumed that there is an evident notion of model morphism, and also a
notion of induction. For the theory of \emph{closed} signatures, we can do
better, because that ToS is itself a closed FQII theory. This is
\emph{levitation} \cite{TODO}, i.e.\ the situation where a ToS contains a
signature for itself. Levitation is useful for bootstrapping: it shall be
sufficient to specify \emph{only the notion of model} for ToS, and notions of
ToS-morphisms, initiality and induction can be computed from that. This
bootstrapping process eliminates the need for either
\begin{itemize}
  \item Assuming that the syntax of ToS already exists as a QIIT. This is
        not too elegant, since we are in the process of building metatheory
        for QII theories.
  \item Bootstrapping the ToS syntax as ``raw'' syntax, using simple
        inductive types, typing/conversion relations and quotients. This
        would be very tedious and none too enlightening.
\end{itemize}

In this section we describe levitation for closed signatures. The theory of
closed signatures does not have $\Pie$, but is otherwise the same as before.  As
we have seen, the inclusion of $\Pie$ yields a ToS which is itself infinitary,
which breaks levitation. Moving to a theory of infinitary signatures will
restore levitation; we revisit this is Section \ref{TODO}.

\subsection{Models \& Signatures}

Since we don't have $\Pie$, we only need a single universe level for indexing models.

\begin{mydefinition} For some $i$ level, we have $\ToS_i : \Set_{i+1}$ as the type of
models of ToS, where all underlying sets return in $\Set_i$.
\end{mydefinition}

\begin{mydefinition}[\textbf{Flcwf model}]
For $i$, we have $\bM_{i} : \ToS_{i + 2}$ as the model where contexts are flcwfs
of algebras, and algebras have underlying sets in $\Set_i$. To see how $i + 2$
checks out: if algebras contain $\Set_i$-s, the category of algebras has a
$\Set_{i + 1}$ for a set of objects, and $\bM_{i}$ itself includes a category of
these categories.
\end{mydefinition}
So far, this can be defined while only using the notion of model for ToS. What
about signatures though? Previously we had that signatures are contexts in ToS
\emph{syntax}, and to talk about syntax, we need to know at least the notion of
ToS model morphism.

Actually, if we only want to be able to write down signatures and interpret them
in the semantics, we don't need a ToS syntax. A functional encoding suffices.

\begin{mydefinition} A \textbf{signature} is a function which for every ToS model
yields a signature in that model. The type of signatures is:
\[
  \ms{Sig} \defn (i : \ms{Level}) \to (M : \ToS_i) \to \Con_{M}
\]
Note that this is a universe-polymorphic type. This is not an issue; universe
polymorphism is a sensible feature in type theories, or alternatively we may
assume that quantification over levels takes place in some outer theory.
\end{mydefinition}

\begin{myexample}
For $\ms{NatSig}$, we define the expected signature, but we specify it in an arbitrary
$M$ model instead of the syntax.
\begin{alignat*}{3}
  & \NatSig : \Sig\\
  & \NatSig \defn \lambda (i :\ms{Level})(M : \ToS_i).\\
  & \hspace{5.2em}(\emptycon_M\,\ext_M\, (N : \U_M) \,\ext_M\,(\mi{zero} : \El_M\,N)
      \ext_M (\mi{suc} : N\arri_M\El_M\,N))
\end{alignat*}
\end{myexample}
We might as well use the same notations for signatures as in Section
\ref{sec:fqiit-tos}, as every signature from before can be unambiguously
rewritten as an encoded signature.

With this, we can interpret each signature in an arbitrary ToS model, by
applying a signature to a model. $\Sig_j$ can be viewed as a precursor to a
Böhm-Berarducci-encoding for the theory of signatures, but we only need contexts
encoded in this way, and not other ToS components. In functional programming,
this style of encoding is sometimes called ``finally tagless''
\cite{carette2007finally}.

If we only want to build the 2LTT-based semantics of signatures, we are done
with bootstrapping right now. In the 2LTT semantics, we never needed induction
on ToS, we only needed to be able to write down signatures and interpret them in
models - which we can do. Going forward, we only need to assume an inner
$(\Ty_0,\,\Tm_0)$ layer with appropriate type formers, and define the flcwf model
the same way as before.

On the other hand, if we want to consider term models, we do need a notion of
induction on ToS.

\begin{mydefinition}[\textbf{Signature for ToS}]
We define $\ToSSig : \Sig$ as the signature for the theory of signatures.  We
present an excerpt from $\ToSSig$ below using internal notation; it should be
clear that every component can be reproduced. We use $\ms{SigU}$ and
$\ms{SigEl}$ to disambiguate components inside the signature from ToS
components.
\begin{alignat*}{3}
  & \Con       &&: \U\\
  & \Sub       &&: \Con \to \Con \to \U\\
  & \Ty        &&: \Con \to \U\\
  & \Tm        &&: (\Gamma : \Con) \to \Ty\,\Gamma \to \U\\
  & ...        &&\\
  & \ms{SigU}  &&: \{\Gamma : \Con\} \to \El\,(\Ty\,\Gamma)\\
  & \ms{SigEl} &&: \{\Gamma : \Con\} \to \Tm\,\Gamma\,\ms{SigU} \to \El\,(\Ty\,\Gamma)\\
  & \Pi        &&: \{\Gamma : \Con\}(a : \Tm\,\Gamma) \to \Ty\,(\Gamma\ext\,\ms{SigEl}\,a)
                   \to \El\,(\Ty\,\Gamma)\\
  & ...        &&
\end{alignat*}
\end{mydefinition}
For each $i$, the interpretation of $\ToSSig$ in $\bM_{i}$ yields an flcwf where
$\bGamma$ such that $\Con_{\bGamma} \equiv \ToS_{i}$, that is, objects are
models of ToS at level $i$. This yields a model theory for ToS, including the notion
of induction.

\section{Reductions to Basic Type Formers}

From the construction of term algebras and eliminators, we get a reduction of
all QIITs to a single infinitary QIIT, namely the syntax of ToS. We spell this out:

\begin{theorem} If an extensional type theory supports syntax for $\ToS_{j+1,j}$, it supports
initial algebras for each signature in $\Sig_j$.
\end{theorem}

Ideally, we would like to reduce QIITs to some collection of basic type
formers. The ToS syntax is far from being a basic type former, it is rather
large and complicated. Therefore, the remaining job is to reduce the ToS syntax
to basic type formers.

We do not attempt here to construct the entire ToS syntax as specified. The
reason is the following: \cite[Section 9]{lumsdaineShulman} shows that
infinitary QIITs are not constructible from inductive types and simple
quotienting with relations. We do not actually know what is the basic type
former, the magic ingredient from which infinitary QIITs are actually
constructible, and which is simple enough. Simplicity is key, of course; in
Chapter \ref{chap:iqiit} we construct infinitary QIITs from the infinitary ToS
syntax, but that's again far from simple.

In \cite[Section~2.2]{ttintt}, there is an argument that infinitary quotient
inductive types extend the base type theory with constructive choice
principles. We conjecture that the magic ingredient would be an infinitary QIT
which expresses some kind of generic choice principle. We leave this to future
work.

What we can do is to show constructions of certain fragments of the full ToS
syntax. In the following, we first give a general description of QIIT constructions,
then describe two specific constructions, for a) finitary inductive-inductive signatures
b) closed QII signatures.

\subsection{Finitary QIIT Constructions}
\label{sec:fqiit-constructions}

The general recipe of constructing finitary QIITs from basic type formers is the
following. This is more or less adapted from Streicher \cite{streicher93habil}
and Brunerie et al.\ \cite{brunerie}.
\begin{enumerate}
  \item
    We define the \emph{raw} syntax, using at most inductive families, but
    no induction-induction. These definitions include all value constructors of
    the goal QIIT, but there is no indexing involved, constructors only store
    the raw inductive data. For example, the raw syntax of closed ToS would
    include the following:
    \begin{alignat*}{3}
      & \Con &&: \Set \\
      & \Sub &&: \Set \\
      & \Ty  &&: \Set \\
      & \Tm  &&: \Set \\
      & \emptycon &&: \Con \\
      & \blank\!\ext\!\blank &&: \Con \to \Ty \to \Ty \\
      & \id &&: \Con \to \Sub \\
      & \blank\!\circ\!\blank &&: \Con \to \Con \to \Con \to \Sub \to \Sub \to \Sub\\
      & ... &&
    \end{alignat*}
    This can be given by a simple mutual inductive definition, which can be
    represented as an indexed inductive family. Indexed families can be
    reduced in turn to indexed W-types \cite{mutualinductive}, which can be
    reduced in turn to W-types and the identity type.
  \item
    We define typing and conversion relations on the raw syntax. For dependent
    type theories, the two are usually mutual: typing includes the rule which
    coerces terms along type conversion, and conversion is usually defined only
    on well-typed terms.  However, it is still possible to define everything
    using only indexed inductive families.
  \item
    The underlying sets are given as follows: we take raw syntactic objects
    which are \emph{merely} well-formed (i.e.\ proofs of well-formedness are
    propositionally truncated, or defined in a universe of irrelevant
    propositions to begin with), and quotient them by conversion.
  \item
    We show that these underlying sets support all constructor of the target
    QIIT: value constructors are defined using raw constructors, while
    equality constructors follow from conversion rules and quotienting.
  \item
    We construct a unique morphism from the above term model to an arbitrary
    model of the QII theory. This usually requires several steps. One approach
    is to first define by induction on raw syntax a family of \emph{partial
    functions} into the assumed model, then separately show that these functions
    are total on well-typed input. The separation is necessary because the
    induction principle for the raw syntax is \emph{too weak}: it cannot express
    the inductive-inductive indexing dependencies which would be required to
    construct the morphism in one go. For instance, if we have the QIIT syntax
    for ToS, and we have some displayed model $A$ over the syntax, the
    eliminator contains the following:
    \begin{alignat*}{3}
      &\Con^S &&: (\Gamma : \Con) \to \Con_A\,\Gamma \\
      &\Sub^S &&: (\Gamma\,\Delta : \Con)(\sigma : \Sub\,\Gamma\,\Delta) \to \Sub_{A}\,(\Con^S\,\Gamma)\,(\Con^S\,\Delta)\,\sigma
    \end{alignat*}
    But with the raw syntax, we can only eliminate using a displayed model of
    the raw syntax, and the eliminator contains the following:
    \begin{alignat*}{3}
      &\Con^S &&: (\Gamma : \Con) \to \Con_A\,\Gamma \\
      &\Sub^S &&: (\sigma : \Sub) \to \Sub_A\,\sigma
    \end{alignat*}
    Lastly, we show that the constructed morphism is unique. This is done by
    induction on raw syntax, and is generally possible in just one elimination.
\end{enumerate}

Note that the above recipe permits a large number of design variations. Some
examples:
\begin{itemize}
\item We may omit fields from raw syntax which are fully determined by type indices.
      This may make subsequent work easier or harder depending on particulars.
\item We may start from a \emph{well-scoped} raw syntax, if there is a notion of
      scoping in the goal QIIT. In general, we may start from some kind of partially
      raw syntax, which is well-typed to some extent. This extent is bounded by what
      is expressible only using indexed inductive families but not
      induction-induction.
\item We may move along a spectrum of ``paranoia'' in the specification of
      well-typing \cite[Section~9.2]{winterhalter-thesis}. A paranoid typing rule
      assumes the well-formedness of everything involved, for example assumes the
      well-formedness of a context $\Gamma$ before it assumes well-formedness of a
      type in $\Gamma$. In contrast, an ``economic'' specification tries to make the
      minimum necessary assumptions, relying on admissibility properties. It's
      possible that well-formedness of $\Gamma$ is derivable from the
      well-formedness of a type in $\Gamma$, so the assumption can be dropped.

      However, if we omit too much, then some other admissibility properties may
      break! Design decisions along the paranoia spectrum are often all tangled
      up like this; hence the name ``paranoid'', which probably stems from the
      anxiety of breaking things by making too much shortcuts.
    \item Instead of using partial maps from raw syntax to the the assumed model
      in step 5, we may define \emph{relations} between \emph{well-formed} raw
      syntax and the given model, and later show that these relations are
      functional.  This seems to be a technically easier approach. The reason is
      that we do not have decidable definedness of the partial maps, which makes
      them more complicated.  A decidably defined partial function has type $A
      \to \ms{Maybe}\,B$. For any $a : A$ we can look at whether the function is
      defined on it. A more general partial function has type $A \to ((P :
      \ms{Prop}) \times (P \to B))$.  If we forget about the $\ms{Prop}$-ness of
      $P$ for the time being, we can equivalently have a relation $A \to B \to
      \Set$ instead.  This is a more ``indexed'' definition compared to the
      ``fibered'' presentation with $P : \ms{Prop}$, and indexed presentations
      in type theory usually enjoy more definitional computation rules - this
      is also the reason why displayed algebras are better-behaved computationally
      than fibered algebras.
\end{itemize}

It should be apparent that constructing QIITs is tedious, and especially so for
large QIITs like type theories. Hence, it is best if we do it just once, for a
theory of signatures from which every other QIIT can be constructed.

\subsubsection{Connection to the initiality conjecture}

The initiality conjecture was made by Voevodsky \cite{voevodsky-initiality}, and
it is essentially the conjecture that the above construction (``initiality
construction'') can be carried out in sufficient formal detail for ``usual''
type theories.

There has been much debate about the merits of initiality constructions. See
\cite{initiality-project} for a hub of such discussions.  On one hand, some
people believed that the initiality construction is essential for reconciling
the usage of raw syntax and categorical notions of models. On the other hand,
some people dismissed the initiality construction as a pointless exercise,
considering the categorical syntax to be the actual syntax, and raw syntax as
merely notation for that. The author of this thesis is of a somewhat different
opinion than either of the above.

First, as a moral justification for the usage of raw syntax, the initiality
construction is indeed mostly pointless. That's because \emph{elaboration}
comprises the true justification for that. Elaboration is the effective
algorithm which converts raw syntax to ``core syntax'', i.e.\ typed categorical
syntax. Given a piece of raw syntax, even if I have done the initiality
construction, I have no effective way of learning which core syntactic object it
corresponds to!  The elaboration literature is \emph{all about} practical
justifications for using certain raw syntaxes, and it comes with established
ways to talk about power and correctness of elaboration algorithms.

Second, there is a different motivation for the initiality construction:
\emph{foundational minimalism}, the reduction of a complicated QIIT to basic
type formers. Elaboration merely assumes that a categorical core syntax already
exists, as the target of elaboration, but it is orthogonal to the construction of
the core syntax. If we have elaboration, we may still want to show a reduction
of the core syntax, but now are free do perform this construction in whatever
way is the easiest. We don't have to construct the QIIT out of a raw syntax
which is intentionally close to the raw syntax that we use in practice! In the
author's opinion, a great deal of confusion arises from the conflation of the
two different motivations for the initiality construction. And of these, the second
motivation is actually valid.

As to which way of construction is easiest: there does not seem to be any truly
easy way to construct QIITs, but this thesis show that we only have to do it
once, for a theory of signatures, and then we can construct all other QIITs from
that in a generic way. In particular, almost all type theories in the wild are
closed QII theories (with the notable exceptions of our ToS-es), so if we can
construct closed signatures, we can construct initial models of almost all type
theories.

What about generic ways to formalize elaboration algorithms? This seems to be a
lot more difficult. To the author's knowledge there have not been notable
research in this area. Decidability of conversion is already very hard to
analyze in a generic way, and the simplest possible bidirectional elaboration
algorithms rely on decidable conversion. To formalize practically realistic
elaboration (i.e.\ elaboration which includes unification) is yet more
difficult.

\subsection{Reduction of Finitary Inductive-Inductive Types}

This section is based on the author's joint work with Kaposi and Lafont
\cite{ind-ind-reduction}. The core idea is the following: a certain fragment of
ToS can be constructed in a far simpler way than what we described in Section
\ref{sec:fqiit-constructions}, with fewer assumptions in the ambient theory.  We
call this fragment the theory of \emph{finitary inductive-inductive} signatures.
This theory has the following type formers (on the top of the base cwf):
\begin{itemize}
  \item The $\U$ universe with $\El$.
  \item Inductive function type $\Pi$, but without $\lami$, and thus without $\beta\eta$-rules.
  \item External function type $\Pie$, but again without $\lame$.
\end{itemize}
Concretely, this ToS is tuned so that
\begin{enumerate}
  \item No quotients are required in its construction.
  \item The generic term model construction still goes through for every signature in
        the ToS.
\end{enumerate}
We explain in the following. First, the equational theory of ToS only specifies
substitution, but it contains no computation rules for type formers. Thus, ToS
is a theory of \emph{neutral terms} and substitutions. This allows us to define
a raw syntax which only includes normal forms, and to define substitution as
recursive functions acting on normal forms. This trivializes the conversion
relation: conversion is simply propositional equality of raw terms. Thus, there
is no need to quotient by conversion. Note that our raw syntax is infinitary,
because we have to represent the branching in $\Piinf$. This is fine though: we
only run into the issue of the missing ``choice'' principle if we try to mix
quotients and infinite branching. Without quotients, infinite branching is not
an issue.

Second, we do not include an identity type in ToS. This blocks the other way for
quotients to enter the picture. With identity types, the generic term model
construction relies on equality reflection in ToS. But when we construct ToS
syntax, the only way to show equality reflection is to quotient raw syntax by
internally provable equalities.

Third, it remains to check that the generic term model construction works with
the pared-down ToS. We only need to check that the omission of $\lam$ and
$\lame$ does not mess things up. Looking at Sections
\ref{sec:fqii-term-algebra-construction} and
\ref{sec:fqii-eliminator-construction}, we see that they don't: the
interpretations of $\Pi$ and $\Pie$ only require applications in ToS, not
abstractions.

\emph{Remark.} Although we have not yet talked about infinitary signatures, we
can give a short summary why the current construction fails to work for their
ToS.  The generic term algebra construction in Section
\ref{sec:iqii-term-algebra-construction} for infinitary signatures relies on
there being both $\lam$ and $\app$ for ``infinitary'' function types, with
$\beta\eta$-rules. This makes the equational theory of ToS non-trivial, so
quotients are necessary in the construction of the syntax. However, this
requires mixing quotients and infinite branching, and in this case we do not
even know how to construct the syntax.

We summarize the construction of the ToS syntax below. We refer the reader to
\cite{ind-ind-reduction}.

\begin{enumerate}
\item We define raw syntax by mutual induction. Substitution are in normal form:
      they are just lists of raw terms. Variables are also normalized as de Bruijn indices.
      We define the action of substitution by recursion on raw syntax. In \cite{ind-ind-reduction},
      raw syntax is not well-scoped, and substitution is partial, but it would be also possible
      to start from well-scoped raw syntax.
\item We inductively define well-formedness relations for contexts,
      substitutions, types and terms, and show by induction on raw syntax that
      well-formedness is propositional, i.e.\ proof-irrelevant. Alternatively, we
      could have defined well-formedness by recursion on raw syntax.
\item We construct a term model of ToS from well-formed raw syntax. All equations in the model
      are provable from the properties of recursive substitution on raw terms.
\item We pick a ToS model, and inductively define a family of relations between
      the term model and the given model, which define the function graphs of the
      model morphism that we aim to define. Then we show in order:
      \begin{enumerate}
        \item Right-uniqueness of the relation, by induction on well-formedness derivations.
        \item Stability of the relation under substitution.
        \item Left-totality of the relation, by induction on well-formedness derivations.
      \end{enumerate}
      We then define the actual model morphism using the functionality of the relation.
\item For the uniqueness of the constructed morphism, we exploit
      right-uniqueness of the relation: it is enough to show that any other model
      morphism maps syntactic input to related semantic output.
\end{enumerate}

This construction is formalized in Agda; see \cite{ind-ind-reduction}. It uses
indexed inductive families, UIP, function extensionality, and equality
reflection in the form of Agda rewrite rules, although the latter could be in
principle omitted from the formalization. Thus, it follows that any model
of ETT with inductive families supports finitary inductive-inductive types.

\subsection{Reduction of Closed QIITs}

For closed QIITs, there is unfortunately no direct formalization which
constructs the ToS. There is one though which is \emph{close enough}, by Menno
de Boer and Guillaume Brunerie \cite{initiality-agda}, see also De Boer's thesis
\cite{deboer-initiality}. This constructs a type theory with the following
features:
\begin{itemize}
  \item A contextual category for base (instead of a cwf).
  \item Countable predicative universes.
  \item $\mathbb{N}$, $\Sigma$, $\Pi$, $\top$, $\bot$, $\blank\!+\!\blank$ and
        intensional $\Id$.
\end{itemize}
The construction follows the 1-5 steps that we described previously. It makes the following assumptions:
\begin{itemize}
\item A universe of strict propositions $\ms{Prop}$. Every type in this universe
      enjoys definitional proof-irrelevance. This $\ms{Prop}$ is used to define
      partial functions and well-formedness relations.
\item Function extensionality.
\item Propositional extensionality for $\ms{Prop}$.
\item Quotients of relations valued in $\ms{Prop}$.
\item Indexed inductive families returning in $\Set$ or in $\ms{Prop}$.
\end{itemize}
Notably, UIP is not assumed. It appears that the irrelevance of equalities in
$\ms{Prop}$ in sufficient to obviate UIP.

It is very plausible that this construction can be adapted to our theory of
closed QII signatures. De Boer and Brunerie construct a complicated open
finitary QIIT, while ours is a fairly similar closed QIIT, with fewer and more
restricted type formers. The openness comes from the use of contextual
categories, which involve indexing by external natural numbers. Contextuality
does not make much difference in the construction though, since raw syntax is
always contextual by the inductive nature of raw contexts.

Hence, it is safe to say that any model of a type theory which supports the
assumptions of De Boer and Brunerie, also supports all closed QIITs.


\chapter[Infinitary QII Signatures]{Infinitary Quotient Inductive-Inductive Signatures}
\label{chap:iqiit}

In this chapter we present another theory of signatures, for \emph{infinitary
quotient inductive-inductive} signatures. As we will see, the reason for
considering the finitary and infinitary cases separately is that they support
different semantics.

First, we specify signatures and define semantics in 2LTT. Then, like in the
previous chapter, we switch to a extensional TT setting and look at term
algebras and related constructions.

\section{Theory of Signatures}

\textbf{Metatheory.} We work in 2LTT. We assume the following type formers in
the inner theory: $\top$, $\Sigma$, extensional identity $\blank\!=\!\blank$ and
$\Pi$. Note that $\Pi$ is an extra assumption compared to what we had in the
finitary case.

\begin{mydefinition}
\label{def:iqiit-tos}
A \textbf{model of the theory of signatures} consists of the following.
  \begin{itemize}
    \item A \textbf{cwf} with underlying sets $\Con$, $\Sub$, $\Ty$ and $\Tm$, all returning in
      the outer $\Set$ universe of 2LTT.
    \item A \textbf{Tarski-style universe} $\U$ with decoding $\El$. $\U$ is closed under the following type formers:
      \begin{itemize}
        \item The \textbf{unit type} $\top$.
        \item \textbf{$\Sigma$-types} $\Sigma : (a : \Tm\,\Gamma\,\U) \to \Tm\,(\Gamma\,\ext\,\El\,a)\,\U \to \Tm\,\Gamma\,\U$, with specifying isomorphism
          \[(\proj,\,\blank\!,\!\blank) : \Tm\,\Gamma\,(\El\,(\Sigma\,a\,b))\simeq (t : \Tm\,\Gamma\,(\El\,a)) \times \Tm\,\Gamma\,(\El\,(b[\id,\,t]))\]
        \item \textbf{Extensional identity} $\Id : \Tm\,\Gamma\,(\El\,a) \to \Tm\,\Gamma\,(\El\,a) \to \Tm\,\Gamma\,\U$,
          specified by $(\reflect,\,\refl) : \Tm\,\Gamma\,(\El\,(\Id\,t\,u)) \simeq (t \equiv u)$.
        \item \textbf{Infinitary functions} $\Piinf : (A : \Ty_0) \to (A \to \Tm\,\Gamma\,\U) \to \Tm\,\Gamma\,\U$, specified by $(\appinf,\,\laminf) : \Tm\,\Gamma\,(\Piinf\,A\,b) \simeq ((\alpha : A) \to \Tm\,\Gamma\,(\El\,(b\,\alpha)))$.
      \end{itemize}
    \item An \textbf{inductive function type} $\Pi : (a : \Tm\,\Gamma\,\U) \to
      \Ty\,(\Gamma\ext\El\,a) \to \Ty\,\Gamma$, specified by
      $(\app,\,\lam) : \Tm\,\Gamma\,(\Pi\,a\,B) \simeq \Tm\,(\Gamma \ext \El\,a)\,B$.
    \item An \textbf{external function type} $\Pie : (A : \Ty_0) \to (A \to \Ty\,\Gamma) \to \Ty\,\Gamma$, specified by
      $(\appe,\,\lame) : \Tm\,\Gamma\,(\Pie\,A\,B) \simeq ((\alpha : A) \to \Tm\,\Gamma\,(B\,\alpha))$.
  \end{itemize}
\end{mydefinition}
Once again we assume that an initial model for ToS exists, and a signature is a
context in the initial model.

\begin{notation}
  We employ the same notations for signatures as in Section \ref{sec:fqiit-tos}. In addition to that,
  we have the usual internal notation for $\top$ and $\Sigma$, and we write $(x : A) \toinf B$ for $\Piinf$
  and $\lambdainf$ for $\laminf$.
\end{notation}

Let's do a comparison to the finitary case. First, the new signatures do not
support sort equations, since there is no identity type for arbitrary terms,
only for terms with types in $\U$. Second, the universe is not empty anymore, it
supports $\top$, $\Sigma$ and the infinitary function type $\Piinf$, which can
be viewed as an analogue of $\Pie$ inside $\U$. We look at example signatures.

\begin{myexample}
Infinitary constructors can be given with $\Piinf$. A classic example is
W-types. Assuming $S : \Ty_0$ and $P : S \to \Ty_0$, we have the following
signature for $P$-branching well-founded trees:
\begin{alignat*}{3}
  &W &&: \U\\
  &\ms{sup} &&: (s : S) \toe (P\,s \toinf W) \to \El\,W
\end{alignat*}
Note that since $P\,s \toinf W$ is in $\U$, it can appear on the left side of
$\to$. Hence the naming ``infinitary'': if $P\,s$ is an infinite type,
$\ms{sup}$ branches with an infinite number of inductive subtrees. Of course,
finitary branching can be also expressed with $\Piinf$, but that use case was
already possible with finitary signatures, by iterating $\to$ finite times.
\end{myexample}

\begin{myexample} Equations can appear as assumptions now. The simplest
example would be set truncation for some $A : \Ty_0$:
\begin{alignat*}{3}
  &|A|_0      &&: \U\\
  &\mi{embed} &&: A \toe \El\,|A|_0 \\
  &\mi{trunc} &&: (x\,y : |A|_0)(p\,q : \Id\,x\,y) \to \El\,(\Id\,p\,q)
\end{alignat*}
However, this ends up being redundant in our semantics, since we assume UIP,
and every semantic underlying type will be a set. Does this mean that recursive
equations are useless? We don't think so. In the specification of cubical type
theories, there are \emph{boundary conditions} which can be given as $\Id$
assumptions \cite{cchm,angiuli2016computational,angiuli2018cartesian}. Also, it
seems that these conditions cannot be easily contracted away, or expressed
equivalently without recursive equation. For an example of contraction, the
signature
\[\emptycon \ext (A : \U) \ext (c_1 : \El\,A) \ext (c_2 : (x : A) \to \Id\,x\,c_1 \to \El\,A)\]
can be rewritten to the equivalent
\[\emptycon \ext (A : \U) \ext (c_1 : \El\,A) \ext (c_2 : \El\,A)\]
signature. However, we can't mechanically eliminate the $\Id$ from the following signature.
\begin{alignat*}{3}
  &A   &&: \U\\
  &B   &&: A \to \U\\
  &b_1 &&: A \to \El\,B\\
  &b_2 &&: A \to \El\,B\\
  &...&&\\
  &a   &&: (x\,y : A) \to \Id\,(b_1\,x)\,(b_2\,y) \to \El\,A
\end{alignat*}
Whether we can reformulate $a$ without the $\Id$ condition depends on what kind
of equational theory we specify for $B$ in the omitted parts of the signature.
\end{myexample}

\begin{myexample}
All theories of signatures that we discussed so far, have (infinitary)
signatures.

For finitary signatures, the ToS is itself infinitary because of $\Pie$. We
assume an universe $\U_0$ in $\Ty_0$. In the signature, we have
\begin{alignat*}{3}
  &\mi{Con} &&: \U \\
  &\mi{Ty} &&: \mi{Con} \to \U\\
  &\Pie &&: \{\Gamma : \mi{Con}\} \to (A : \U_0) \toe (A \toinf \mi{Ty}\,\Gamma) \to \El\,(\mi{Ty}\,\Gamma)\\
\end{alignat*}
In the signature for infinitary ToS, we have
\begin{alignat*}{3}
  &\mi{Univ} &&: \{\Gamma : \mi{Con}\} \to \mi{Ty}\,\Gamma\\
  &\Piinf    &&: \{\Gamma : \mi{Con}\} \to (A : \U_0) \toe (A \toinf \mi{Tm}\,\Gamma\,\mi{Univ}) \to \mi{Tm}\,\Gamma\,\mi{Univ}
\end{alignat*}
\emph{Remark.}
When we will take the semantics of the above signature, we won't exactly get
back the theory of signatures that we're using right now. We have ToS in 2LTT
now, but the semantics is in the inner theory. What we can do though, is to
assume that the inner theory is also a 2LTT. Then we might assume that the inner
theory of \emph{that} is again a 2LTT, and so on. This is a possible (and quite
natural) generalization of 2LTT to n-level type theory. In this setting, one
round of self-description requires a bumping of levels in the sense of n-level TT. In
this thesis we don't explore this, instead we use a more conventional universe
hierarchy in an extensional TT, to investigate self-description.
\end{myexample}

\begin{myexample}
We have seen in Example \ref{ex:presheaf-sig} that $\Ty_0$-valued presheaves have finitary signatures.
With infinitary signatures, we can also cover monads on $\Ty_0$. We assume a
universe $\U_0 : \Ty_0$.
\begin{alignat*}{3}
  &M              &&: \U_0 \to \U\\
  &\mi{map}       &&: (A \to B) \toe M\,A \to \El\,(M\,B)\\
  &\mi{map_{id}}   &&: \El\,(\Id\,(\mi{map}\,\id\,x)\,x)\\
  &\mi{map_{\circ}} &&: \El\,(\Id\,(\mi{map}\,(f \circ g)\,x)\,(\mi{map}\,f\,(\mi{map}\,g\,x)))\\
  &\mi{return}    &&: A \toe \El\,(M\,A)\\
  &\mi{bind}      &&: M\,A \to (A \toinf M\,B) \to \El\,(M\,B)
\end{alignat*}
We rely on $\toinf$ to specify binding. The $\mi{join}$-based specification
would not work, since $M\,(M\,A)$ is not valid in signatures. The above
signature can be helpful for deriving some of the metatheory of Dijkstra monads
\cite[Section~5]{dijkstramonad}.

In the 2LTT-based semantics, we will get $M : \U_0 \to \Ty_0$, which is not
quite an endofunctor, but it would be straightforward to refine the semantics so
that we can pick universes for underlying types of algebras, and have $M : \U_0
\to \U_0$. Alternatively, we will also have the ETT-based semantics, where
universe levels are explicitly handled.
\end{myexample}

\begin{myexample}
It is worth to note that every set-truncated higher inductive type from the
Homotopy Type Theory book \cite{hottbook} is covered. This includes
\begin{itemize}
\item The cumulative hierarchy of sets \cite[Section~10.5]{hottbook}.
\item Cauchy real numbers \cite[Section~11.3]{hottbook}.
\item Surreal numbers \cite[Section~11.6]{hottbook}.
\end{itemize}
\end{myexample}

\section{Semantics}

\subsection{Overview}

As we mentioned, we need a different semantics for infinitary signatures.
First, we look at why the previous semantics fails. We try to model signatures
again as flcwfs, and morphisms as strict flcwf-morphisms. The simplest point of
failure is the interpretation of the unit type $\bs{\top : \Tm\,\Gamma\,\U}$.

In the semantics, this is the same as defining $\bs{\top :
  \Sub\,\Gamma\,\Ty_0}$, where $\bs{\Ty_0}$ is the flcwf of inner types. The
only sensible definition here is the functor which is constantly $\top_0$. But
this does not strictly preserve comprehension or the finite limit type formers.
If we have
\begin{alignat*}{3}
  &\bs{\top} : \Con_{\bGamma} \to \Ty_0\\
  &\bs{\top}\,\Gamma \defn \top_0
\end{alignat*}
then we have $\bs{\top}\,(\Gamma \ext_{\bGamma} A) \equiv \top_0$, but
$\bs{\top}\,\Gamma \ext_{\bs{\Ty_0}} \bs{\top}\,A \equiv \top_0 \times \top_0$.
Thus, $\top_0 \not\equiv \top_0 \times \top_0$, but of course $\top_0 \simeq
\top_0 \times \top_0$.

Let's look at $\bs{\Piinf} : (A : \bs{\Ty_0}) \to (A \to \bs{\Tm\,\Gamma\,\U}) \to
\bs{\Tm\,\Gamma\,\U}$ as well, since that's a more interesting new feature than the
unit type. The only viable definition is to take the $A$-indexed product of
$\bs{\Sub\,\Gamma\,\Ty_0}$ morphisms, so we map objects of $\bGamma$ to function types:
\begin{alignat*}{3}
  &\Con_{\bs{\Piinf\,A\,b}}\,\Gamma \defn (\alpha : A) \to \Con_{\bb\,\alpha}\,\Gamma
\end{alignat*}
But now we have
\[(\bs{\Piinf\,A\,b})\,\emptycon_{\bGamma} \equiv (\alpha : A) \to \Con_{\bb\,\alpha}\,\emptycon_{\bGamma}
   \equiv A \to \top_0\]
Hence, $(\bs{\Piinf\,A\,b})\,\emptycon_{\bGamma} \not\equiv \top_0$, although
$(\bs{\Piinf\,A\,b})\,\emptycon_{\bGamma} \simeq \top_0$.

Intuitively, if $\bU$ has no type formers, the terms in $\bU$ are neutral,
i.e.\ variables applied to zero or more neutral terms. But variables in the
semantics simply project out components from iterated $\Sigma$-types. For
example, the action of $\bs{\q} : \bs{\Tm\,(\Gamma \ext A)\,(A[\p])}$ on
objects, types, morphisms and terms is given by taking second
projections. Since all structure in $\bs{\Gamma\,\ext\,A}$ is given by pairing
things, $\bs{\q}$ strictly preserves all structure, and the same goes
for all variables.

Substitutions and terms in the finitary ToS are only allowed to freely reshuffle
structure. We can forget, duplicate, or permute signature entries, or build
neutral expressions from assumptions. In contrast, the infinitary ToS allows us
to take small limits of assumptions, using $\bs{\top}$, $\bs{\Sigma}$, $\bs{\Id}$ and $\bs{\Piinf}$
to build new inhabitants of $\bU$. We summarize the process of getting the new
semantics:
\begin{enumerate}
\item Strict structure-preservation for type formers in $\bU$ generally fails, but they still
      preserve structure up to isomorphism.
\item Hence, we switch from strict flcwf-morphisms to weak ones, which preserve $\emptycon$, comprehension
      and fl-structure weakly.
\item However, in the finitary case we often relied on transporting along
      preservation equations. We need to recover transports along isomorphism.
\item Hence, we extend semantic types from displayed flcwfs to \emph{isofibrations}, which
      support the required transports.
\item However, this rules out sort equations, because they are not stable under
      isomorphisms. For example, for sets $A$, $B$, $C$ such that $A \simeq B$ and
      $A \simeq C$, it's not necessarily the case that $B \equiv C$.
\end{enumerate}

\subsubsection{Univalent semantics}

The isofibrant semantics will turn out to be significantly more technical than
the strict semantics. Instead of working with isofibrations in an extensional
setting, could we work with univalent structures in homotopy type theory? In
other words, work with univalent categories of algebras, and univalent displayed
categories over them \cite{displayedcats}. A major benefit of the univalent
setting is that we would get a \emph{structure identity principle} \cite{TODO}
out of the semantics, which says that for algebras, isomorphism is the same as
equality.

However, it appears that univalent \emph{cwfs} are overall yet more technical to
handle than isofibrations. In an univalent cwf, objects and types are generally
h-groupoids, so we would have groupoids of algebras instead of sets of
algebras. This implies that \emph{type equalities} are between groupoids, so
they need to be coherent, if we want them to be well-behaved. Hence, $\Ty$ is
not an 1-presheaf over contexts, but rather a $(2,1)$-presheaf.

Alternatively, we could simplify the task by only constructing univalent
categories of algebras, and skipping the family structure (and
fl-structure). This would be the minimum amount of effort that would yield the
structure identity principle.

Both of these would be interesting to check in future work. As a third
alternative, instead of stopping at set-truncated algebras in HoTT, we might as
well consider types at arbitrary h-level, and construct
$(\omega,\,1)$-categories of algebras. This comprises a semantics of higher
inductive-inductive signatures. We do not present a full higher-categorical
semantics in this thesis; we only present a fragment of it in Chapter
\ref{chap:hiit}.

\todo{Refer to Sattler \& Capriotti in HIIT chapter, or here?}

\subsection{Model of the Theory of Signatures}

In the following we present a model of ToS. We call it $\bM$, and like before,
we use \textbf{bold} font to refer to components of $\bM$.

\subsubsection{Contexts}

$\bGamma : \bCon$ is again an flcwf, but with a minor change: $\K$ is not strict
anymore, so we have $(\appK,\,\lamK) : \Tm\,\Gamma\,(\K\,\Delta) \simeq
\Sub\,\Gamma\,\Delta$. As well will see shortly, $\bs{A[\sigma]}$ does not
support strict displayed $\K$ anymore, hence the change.

\subsubsection{Substitutions}
\label{sec:iqiit-substitutions}

$\bs{\sigma : \Sub\,\Gamma\,\Delta}$ is a \emph{weak flcwf-morphism}, that is, a
functor between underlying categories, which also maps types to types and terms
to terms, and satisfies the following mere properties:
  \begin{enumerate}
    \item $\bsigma\,(A[\sigma]) \equiv (\bsigma\,A)\,[\bsigma\,\sigma]$
    \item $\bsigma\,(t[\sigma]) \equiv (\bsigma\,t)\,[\bsigma\,\sigma]$
    \item The unique map $\epsilon : \Sub\,(\bsigma\,\emptycon)\,\emptycon$ has a retraction.
    \item Each $(\bsigma\,\p,\,\bsigma\,\q) : \Sub\,(\bsigma\,(\Gamma\,\ext\,A))\,(\bsigma\,\Gamma\,\ext\,\bsigma\,A)$ has an inverse.
  \end{enumerate}

In short, $\bsigma$ preserves substitution strictly and preserves empty context
and context extension up to isomorphism. We notate the evident isomorphisms as
$\bsigma_{\emptycon} : \bsigma\,\emptycon \simeq \emptycon$ and $\bsigma_{\ext}
: \bsigma\,(\Gamma\,\ext\,A)\,\simeq\,\bsigma\,\Gamma\,\ext\,\bsigma\,A$. Our
notion of weak morphism is the same as in \cite{dependentrightadjoints}, when
restricted to cwfs.

\begin{theorem}\label{thm:flpres}
Every $\bs{\sigma : \Sub\,\Gamma\,\Delta}$ preserves fl-structure up to
type isomorphism. That is, we have
\begin{alignat*}{3}
  & \bsigma_{\Sigma} : \bsigma\,(\Sigma\,A\,B) \simeq \Sigma\,(\bsigma\,A)\,((\bsigma\,B)[\bsigma_{\ext}^{-1}]) \\
  & \bsigma_{\K} : \bsigma\,(\K\,\Delta) \simeq \K\,(\bsigma\,\Delta) \\
  & \bsigma_{\Id} : \bsigma\,(\Id\,t\,u) \simeq \Id\,(\bsigma\,t)\,(\bsigma\,u)
\end{alignat*}
These are all natural in the following sense: for $\sigma :
\Sub_{\bGamma}\,\Gamma\,\Delta$, if we have $\bsigma_{\Sigma}$ as a type
isomorphism in $\bsigma\,\Delta$, if we reindex it by $\sigma$, we get
$\bsigma_{\Sigma}$ as a type isomorphism in $\bsigma\,\Gamma$. The same holds
for $\bsigma_{\K}$ and $\bsigma_{\Id}$.

Moreover, $\bsigma$ preserves all term and substitution formers in the
fl-structure. For example, $\bsigma\,(\proj1\,t) \equiv \proj1\,
(\bsigma_{\Sigma}[\id, \bsigma\,t])$.
\end{theorem}
\begin{proof}
For $\bsigma_{\Sigma}$, we construct the following context isomorphism:
\begin{alignat*}{3}
& (\bsigma\,\Gamma\,\ext\,\bsigma\,(\Sigma\,A\,B)) \simeq
  (\bsigma\,\Gamma\,\ext\,\bsigma\,A\,\ext\,(\bsigma\,B)[\bsigma_{\ext}^{-1}]) \\
& \simeq (\bsigma\,\Gamma\,\ext\,\Sigma\,(\bsigma\,A)\,((\bsigma\,B)[\bsigma_{\ext}^{-1}]))
\end{alignat*}
This isomorphism is the identity on $\bsigma\,\Gamma$, hence we can extract the
desired $\bsigma_{\Sigma} : \bsigma\,(\Sigma\,A\,B) \simeq
\Sigma\,(\bsigma\,A)\,((\bsigma\,B)[\bsigma_{\ext}^{-1}])$ from it.

For $\bsigma_{\K}$, note the following:
\begin{alignat*}{3}
  & (\emptycon\,\ext\,\bsigma\,(\K\,\Delta)) \simeq
    (\bsigma\,\emptycon\,\ext\,\bsigma\,(\K\,\Delta)) \simeq
    \bsigma\,(\emptycon\,\ext\,\K\,\Delta)\\
  & \simeq \bsigma\,\Delta \simeq (\emptycon\,\ext\,K\,(\bsigma\,\Delta))
\end{alignat*}
This yields a type isomorphism $\bsigma\,(\K\,\Delta) \simeq
\K\,(\bsigma\,\Delta)$ in the empty context, and we can use the functorial action of
$\epsilon : \Sub\,\Gamma\,\emptycon$ to weaken it to any $\Gamma$ context.

For $\bsigma_{\Id}$, both component morphisms can be constructed by $\refl$ and
equality reflection, and the morphisms are inverses by UIP. We omit here the
verification of naturality and that $\bsigma$ preserves term and substitution
formers in the fl-structure.
\end{proof}

\subsubsection{Identity and composition}
\label{sec:idcomp}

$\bid : \bSub\,\bGamma\,\bGamma$ is defined in the obvious way, with identities for
underlying functions and for preservation morphisms.

For $\bs{\sigma \circ \delta}$, the underlying functions are given by
function composition, and the preservation morphisms are given as follows:
\begin{alignat*}{3}
  & (\bs{\sigma \circ \delta})_{\emptycon}^{-1} \defn
    \bsigma\,\bdelta_{\emptycon}^{-1} \circ \bdelta_{\emptycon}^{-1} \\
  & (\bs{\sigma \circ \delta})_{\ext}^{-1} \defn
    \bsigma\,\bdelta_{\ext}^{-1} \circ \bdelta_{\ext}^{-1}
\end{alignat*}

It is easy to verify the left and right identity laws and associativity for
$\bs{\blank\circ\blank}$.

\begin{mylemma}\label{lem:idcomppres}
The derived preservation isomorphisms for the fl-structure can be decomposed
analogously; all derived isomorphisms in $\bid$ are identities, and we have
\begin{alignat*}{3}
  & (\bs{\sigma \circ \delta})_{\Sigma} \equiv
  \bsigma\,\bdelta_{\Sigma} \circ \bdelta_{\Sigma}\\
  & (\bs{\sigma \circ \delta})_{\K} \equiv
  \bsigma\,\bdelta_{\K} \circ \bdelta_{\K}\\
  & (\bs{\sigma \circ \delta})_{\Id} \equiv
  \bsigma\,\bdelta_{\Id} \circ \bdelta_{\Id}
\end{alignat*}
On the right sides, $\blank\circ\blank$ refers to composition of type morphisms.
\end{mylemma}
\begin{proof}
In the case of $\Id$, the equations hold immediately by UIP. For $\Sigma$ and
$\K$, we prove by flcwf computation and straightforward unfolding of
definitions.
\end{proof}

\subsubsection{Empty context}
The empty context $\bemptycon : \bCon$ is the same as before, i.e.\ the terminal
flcwf. Since the unique $\bs{\epsilon} : \bSub\,\bGamma\,\bemptycon$ morphism
strictly preserves all structure, it also a weak morphism.

\subsubsection{Types}
We define $\bs{\Ty\,\Gamma} : \Set$ as the type of split flcwf-isofibrations
over $\bGamma$. This consists of a displayed flcwf together with \emph{iso-cleaving}
structure. For the displayed flcwf part, we reuse previous notation from Section
\ref{sec:fqiit-family}. For the iso-cleaving, we make some auxiliary definitions first.

\begin{mydefinition}[Displayed type categories]
For each $\Gamma : \Con_{\bA}\,\ulGamma$, there is a displayed category over the
type category $\Ty_{\bGamma}\,\ulGamma$, whose objects over $\ulA :
\Ty_{\bGamma}\,\ulGamma$ are elements of $\Ty_{\bA}\,\Gamma\,\ulA$, and
displayed morphisms over $\ult : \Tm_{\bGamma}\,(\ulGamma \ext
\ulA)\,(\ulB[\p])$ are elements of $\Tm_{\bA}\,(\Gamma \ext
A)\,(B[\p])\,\ult$. The identity morphism is given by $\q_{\bA}$, and the
composition of $t$ and $u$ is $t[\p_{\bA},u]$. Analogously to Definition
\ref{def:type_categories}, this extends to a displayed split indexed category.
\end{mydefinition}

\begin{mydefinition}[Displayed isomorphisms]
\label{def:displayed-iso}
A \emph{displayed context isomorphism} over $\ulsigma : \ulGamma \simeq
\ulDelta$, notated $\sigma : \Gamma \simeq_{\ulsigma} \Delta$, is an invertible
displayed morphism $\sigma : \Sub_{\bA}\,\Gamma\,\Delta\,\ulsigma$, with inverse
$\sigma^{-1} : \Sub_{\bA}\,\Delta\,\Gamma\,\ulsigma^{-1}$. A \emph{displayed
  type isomorphism} over $\ult : \ulA \simeq \ulB$, notated $t : A \simeq_{\ult}
B$, is an isomorphism in a displayed type category.
\end{mydefinition}

\begin{mydefinition}
A \emph{vertical morphism} lies over an identity morphism. We use this
definition for context morphisms (substitutions) and type morphisms as well.
\end{mydefinition}

\begin{mydefinition}[Context iso-cleaving] This lifts a base context isomorphism to a displayed one. It consists of
\begin{alignat*}{3}
  & \coe &&: \ulGamma \simeq \ulDelta \ra \Con_{\bA}\,\ulGamma \ra \Con_{\bA}\,\ulDelta\\
  & \coh &&: (\ulsigma : \ulGamma \simeq \ulDelta)(\Gamma : \Con_{\bA}\,\ulGamma)
           \ra \Gamma \simeq_{\ulsigma} \coe\,\ulsigma\,\Gamma\\
  & \coe^{\id} && : \coe\,\id\,\Gamma \equiv \Gamma\\
  & \coe^{\circ} && : \coe\,(\ulsigma\circ\uldelta)\,\Gamma \equiv \coe\,\ulsigma\,(\coe\,\uldelta\,\Gamma)\\
  & \coh^{\id} && : \coh\,\id\,\Gamma \equiv \id\\
  & \coh^{\circ} && : \coh\,(\ulsigma\circ\uldelta)\,\Gamma \equiv \coh\,\ulsigma\,(\coe\,\uldelta\,\Gamma)
          \circ \coh\,\uldelta\,\Gamma
\end{alignat*}
Here, $\coe$ and $\coh$ abbreviate ``coercion'' and ``coherence'' respectively.
\end{mydefinition}

\begin{mydefinition}[Type iso-cleaving] This consists of
\begin{alignat*}{3}
  & \coe &&: \ulA \simeq \ulB \ra \Ty_{\bA}\,\Gamma\,\ulA \ra \Ty_{\bA}\,\Gamma\,\ulB\\
  & \coh &&: (\ult : \ulA \simeq \ulB)(A : \Ty_{\bA}\,\Gamma\,\ulA)
           \ra A \simeq_{\ult} \coe\,\ult\,A\\
  & \coe^{\id} && : \coe\,\id\,A \equiv A\\
  & \coe^{\circ} && : \coe\,(\ult\circ\uldelta)\,A \equiv \coe\,\ult\,(\coe\,\uldelta\,A)\\
  & \coh^{\id} &&: \coh\,\id\,A \equiv \id\\
  & \coh^{\circ} &&: \coh\,(\ult\circ\uldelta)\,A \equiv \coh\,\ult\,(\coe\,\uldelta\,A)
          \circ \coh\,\uldelta\,A
\end{alignat*}
Additionally, for $\sigma : \Sub_{\bA}\,\Gamma\,\Delta\,\ulsigma$, we have
\begin{alignat*}{3}
  & \coe[] &&: \coe\,(\ult[\ulsigma])\,(A[\sigma]) \equiv (\coe\,\ult\,A)[\sigma]\\
  & \coh[] &&: \coh\,(\ult[\ulsigma\circ \p,\q])\,(A[\sigma]) \equiv (\coh\,\ult\,A)[\sigma]
\end{alignat*}

\end{mydefinition}

\begin{mydefinition} A \emph{split flcwf isofibration} is a displayed flCwF equipped with iso-cleaving for contexts and types.
\end{mydefinition}

\emph{Remark.} It is not possible to model types as fibrations or opfibrations,
because we have no restriction on the variance of ToS types. For example, the
type which extends a pointed set signature to a natural number signature, is
neither a fibration nor an opfibration.

\subsubsection{Type substitution}
We aim to define $\bs{\blank[\blank] : \Ty\,\Delta \ra \Sub\,\Gamma\,\Delta \ra
  \Ty\,\Gamma}$, such that $\bs{A[\id]} \equiv \bA$ and $\bs{A[\sigma\circ\delta]} \equiv
\bs{A[\sigma][\delta]}$. As before, the underlying sets are given by simple
composition:
\begin{alignat*}{3}
  & \Con_{\bs{A[\sigma]}}\,\ulGamma && \defn \Con_{\bA}\,(\bsigma\,\ulGamma)\\
  & \Sub_{\bs{A[\sigma]}}\,\Gamma\,\Delta\,\ulsigma && \defn
    \Sub_{\bA}\,\Gamma\,\Delta\,(\bsigma\,\ulsigma)\\
  & \Ty_{\bs{A[\sigma]}}\,\Gamma\,\ulA && \defn
      \Ty_{\bA}\,\Gamma\,(\bsigma\,\ulA)\\
  & \Tm_{\bs{A[\sigma]}}\,\Gamma\,A\,\ult && \defn
      \Tm_{\bA}\,\Gamma\,A\,(\bsigma\,\ult)
\end{alignat*}
The difference from the finitary case is that instead of preservation equations,
we have isomorphisms, coercions and coherence. However, we can recover
essentially the same reasoning as before, because all the previous transports
still work. Context and type formers are given by coercing $\bA$ structures
along preservation isomorphisms by $\bsigma$. For example:
\begin{alignat*}{3}
  &\emptycon_{\bs{A[\sigma]}} && \defn
    \coe\,\bsigma_{\emptycon}^{-1}\,\emptycon_{\bA}\\
  &\Gamma\ext_{\bs{A[\sigma]}}A && \defn
    \coe\,\bsigma_{\ext}^{-1}\,(\Gamma\ext_{\bA} A)\\
  &\Id_{\bs{A[\sigma]}}\,t\,u && \defn
    \coe\,\bsigma_{\Id}^{-1}\,(\Id_{\bA}\,t\,u)\\
  &\K_{\bs{A[\sigma]}}\,\Delta && \defn
    \coe\,\bsigma_{\K}^{-1}\,(\K_{\bA}\,\Delta)
\end{alignat*}
Term and substitution formers are given by composing $\coh$-lifted
isomorphisms with term and substitution formers from $\bA$. For example:
\begin{alignat*}{3}
  & \epsilon_{\bs{A[\sigma]}} && \defn
    \coh\,\bsigma_{\emptycon}^{-1}\,\emptycon_{\bA} \circ \epsilon_{\bA}\\
  & \p_{\bs{A[\sigma]}} && \defn
    \p_{\bA} \circ (\coh\,\bsigma_{\ext}^{-1}\,(\Gamma\ext A))^{-1}\\
  & (\sigma,_{\bs{A[\sigma]}}\,t) && \defn \coh\,\bsigma_{\ext}^{-1}\,(\Delta\ext A) \circ (\sigma,_{\bA}\,t)
\end{alignat*}
As we mentioned, only weak $\K$ is supported in $\bs{A[\sigma]}$. For strict $\K$
we would have to show:
\[
\Sub_{\bA}\,\Gamma\,\Delta\,(\bsigma\,\ulsigma)
\equiv \Tm_{\bA}\,\Gamma\,(\coe\,\bsigma_{\K}^{-1}\,(\K_{\bA}\,\Delta))\,(\bsigma\,\ulsigma)
\]
By strict $\K$ in $\bA$, it would be enough to show
\[
\Tm_{\bA}\,\Gamma\,(\K_{\bA}\,\Delta)\,(\bsigma\,\ulsigma)
\equiv \Tm_{\bA}\,\Gamma\,(\coe\,\bsigma_{\K}^{-1}\,(\K_{\bA}\,\Delta))\,(\bsigma\,\ulsigma)
\]
But there is no reason why these sets should be equal, so we instead produce an isomorphism.

Equations for term and type substitution follow from naturality of preservation
isomorphisms in $\bsigma$, $\coe[]$, $\coh[]$ and substitution equations in
$\bA$.

  %% & \appK_{\bs{A[\sigma]}}\,t && \defn
  %%   \appK_{\bA}\,((\coh\,\bsigma_{\K}\,(\K\,\Delta))^{-1}\circ t)

Iso-cleaving is given by iso-cleaving in $\bA$ and the action of $\bsigma$ on
isomorphisms, so that we have $\coe_{\bs{A[\sigma]}}\,\ulsigma\,\Gamma
\defn \coe_{\bA}\,(\bsigma\,\ulsigma)\,\Gamma$ and $\coh_{\bs{A[\sigma]}}\,\ulsigma\,\Gamma
\defn \coh_{\bA}\,(\bsigma\,\ulsigma)\,\Gamma$.

Functoriality of type substitution, i.e.\ $\bs{A[\id]} \equiv \bA$ and
$\bs{A[\sigma\circ\delta]} \equiv \bs{A[\sigma][\delta]}$, follows
from Lemma \ref{lem:idcomppres} and split cleaving given by $\coe^{\id}$,
$\coe^{\circ}$, $\coh^{\id}$ and $\coh^{\circ}$ laws in $\bA$.

\subsubsection{Terms}

$\bs{\Tm\,\Gamma\,A} : \Set$ is defined as the type of
\emph{weak flCwF sections} of $\bA$. The underlying functions of $\bt :
\bTm\,\bGamma\,\bA$ are as follows:
\begin{alignat*}{3}
  & \bt : (\ulGamma : \Con_{\bGamma}) \ra \Con_{\bA}\,\ulGamma\\
  & \bt : (\ulsigma : \Sub_{\bGamma}\,\ulGamma\,\ulDelta)
         \ra \Sub_{\bA}\,(\bt\,\ulGamma)\,(\bt\,\ulDelta)\,\ulsigma\\
  & \bt : (\ulA : \Ty_{\bGamma}) \ra \Ty_{\bA}\,(\bt\,\ulGamma)\,\ulA\\
  & \bt : (\ult : \Tm_{\bGamma}\,\ulGamma\,\ulA) \ra
          \Tm_{\bA}\,(\bt\,\ulGamma)\,(\bt\,\ulA)\,\ult
\end{alignat*}
Such that
\begin{enumerate}
  \item $\bt\,(\ulA[\ulsigma]) \equiv (\bt\,\ulA)\,[\bt\,\ulsigma]$
  \item $\bt\,(\ult[\ulsigma]) \equiv (\bt\,\ult)\,[\bt\,\ulsigma]$
  \item The unique $\epsilon_{\bA} : \Sub\,(\bt\,\emptycon)\,\emptycon\,\id$ has a vertical retraction.
  \item Each $(\bt\,\p,\,\bt\,\q) : \Sub\,(\bt\,(\ulGamma\,\ext\,\ulA))\,(\bt\,\ulGamma\,\ext\,\bt\,\ulA)\,\id$ has a vertical inverse.
\end{enumerate}

Similarly to what we had in $\bSub$, we denote the evident preservation
isomorphisms as $\bt_{\emptycon} : \bt\,\emptycon \simeq_{\id} \emptycon$ and
$\bt_{\ext} : \bt\,(\ulGamma\ext \ulA) \simeq_{\id} \bt\,\ulGamma \ext
\bt\,\ulA$. In short, weak sections are dependently typed analogues of weak
morphisms, with dependent underlying functions and displayed preservation
isomorphisms. We also have the derived fl-preservation isomorphisms.

\begin{theorem} A weak section $\bs{t : \Tm\,\Gamma\,A}$ preserves fl-structure up to vertical type isomorphisms, that is, the following are derivable:
\begin{alignat*}{3}
  & \bt_{\Sigma} : \bt\,(\Sigma\,\ulA\,\ulB) \simeq_{\id} \Sigma\,(\bt\,\ulA)\,((\bt\,\ulB)[\bt_{\ext}^{-1}]) \\
  & \bt_{\K} : \bt\,(\K\,\ulDelta) \simeq_{\id} \K\,(\bt\,\ulDelta) \\
  & \bt_{\Id} : \bt\,(\Id\,\ult\,\ulu) \simeq_{\id} \Id\,(\bt\,\ult)\,(\bt\,\ulu)
\end{alignat*}
Also, the above isomorphisms are natural in the sense of Theorem
\ref{thm:flpres}, and $\bt$ preserves term and substitution formers in the
fl-structure.
\end{theorem}
\begin{proof}
The construction of isomorphisms is the same as in Theorem
\ref{thm:flpres}. Indeed, every construction there has a displayed counterpart
which we can use here.
\end{proof}

We note though that the move from Theorem \ref{thm:flpres} to here is not simply a
logical predicate translation, because we are only lifting the codomain of a
weak morphism to a displayed version, and we leave the domain non-displayed. We
leave to future work the investigation of such asymmetrical (or
``modal'') logical predicate translations.



\subsubsection{Term substitution}

$\bs{\blank[\blank] : \Tm\,\Delta\,A \ra (\sigma : \Sub\,\Gamma\,\Delta)
  \ra \Tm\,\Gamma\,(A[\sigma])}$ is given similarly to
$\bs{\blank\!\circ\!\blank}$ in Section \ref{sec:idcomp}. Underlying functions
are given by function composition, and preservation morphisms are also similar:
\begin{alignat*}{3}
  & (\bs{t[\sigma]})_{\emptycon}^{-1} \defn
    \bt\,\bsigma_{\emptycon}^{-1} \circ \bt_{\emptycon}^{-1} \\
  & (\bs{t[\sigma]})_{\ext}^{-1} \defn
    \bt\,\bsigma_{\ext}^{-1} \circ \bt_{\ext}^{-1}
\end{alignat*}
We also have the same decomposition of derived isomorphisms as in Lemma
\ref{lem:idcomppres}. We do not have to show functoriality of term substitution
here, since that is derivable in any cwf, see e.g. \cite{kaposi2019constructing}.

\subsubsection{Comprehension}

$\bs{\Gamma\,\ext A : \Con}$ is defined as the total flcwf of $\bA$, in exactly
the same way as in the finitary case, since the additional iso-cleaving
structure plays no role in the result. $\bs{\p : \Sub\,(\Gamma\ext A)\,\Gamma}$
and $\bs{\q : \Tm\,(\Gamma\ext A)\,(A[\p])}$ are likewise unchanged; they are
strict morphisms, so also automatically weak morphisms. Substitution extension
$\bs{(\sigma,\,t)}$ is given by pointwise combining $\bsigma$ and $\bt$,
e.g.\ $\Con_{\bs{(\sigma,t)}}\,\ulGamma \defn (\bsigma\,\ulGamma,\,\bt\,\ulGamma)$.

\subsubsection{Strict constant families}
We have the same definition for $\bs{\K\,\Delta : \Ty\,\Gamma}$ as in the
finitary case, although we need to define iso-cleaving in addition. Fortunately,
coercions and coherences are all trivial, because $\bK\,\bDelta$ does not actually
depend on $\bGamma$.
\begin{alignat*}{3}
  &\coe_{\bs{\K\,\Delta}}\,\ulsigma\,\Gamma &&\defn \Gamma\\
  &\coe_{\bs{\K\,\Delta}}\,\ult\,A          &&\defn A
\end{alignat*}

\subsubsection{Universe}

$\bU : \bTy\,\bGamma$ is exactly the same as before. We define it as the type
which is constantly the flcwf of inner types, so it inherits the trivial
iso-cleaving from $\bK$.

$\bs{\El\,a : \Ty\,\Gamma}$ is again the displayed flcwf of
the elements of $\bs{a : \Tm\,\Gamma\,\U}$. The underlying sets are unchanged:
\begin{alignat*}{3}
  & \Con_{\bEl\,\ba}\,\ulGamma && \defn \Tm_0\,(\ba\,\ulGamma)\\
  & \Sub_{\bEl\,\ba}\,\Gamma\,\Delta\,\ulsigma && \defn \ba\,\ulsigma\,\Gamma \equiv \Delta\\
  & \Ty_{\bEl\,\ba}\,\Gamma\,\ulA && \defn \Tm_0\,(\ba\,\ulA\,\Gamma)\\
  & \Tm_{\bEl\,\ba}\,\Gamma\,A\,\ult && \defn \ba\,\ult\,\Gamma \equiv A
\end{alignat*}
We need to adjust definitions to show that $\bs{\El\,a}$ supports all required
structure. Previously, all context and type formers were inherited from $\bU$,
since $\ba$ strictly preserved them. Now, $\ba$ preserves structure up to
(definitional) isomorphism of inner types. Hence, the adjustments are quite
mechanical; they are like wrapping all definitions in ``unary record constructors''
given by preservation isomorphisms. For example:
\begin{alignat*}{3}
  & \emptycon_{\bEl\,\ba} && \defn \ba_{\emptycon}^{-1}\,\tt\\
  & (\Gamma\ext_{\bEl\,\ba} A) && \defn \ba_{\ext}^{-1}\,(\Gamma,\,A)
\end{alignat*}
We likewise use preservation isomorphisms to define $\K$, $\Id$ and $\Sigma$.
Context coercion is $\coe\,\ulsigma\,\Gamma \defn \ba\,\ulsigma\,\Gamma$. Type
coercion, for $A : \ba\,\ulA\,\Gamma$ is given as $\coe\,\ult\,A \defn
\ba\,\ult\,(\ba_{\ext}^{-1}\,(\Gamma,\,A))$.

\subsubsection{Unit type}

$\bs{\top : \Tm\,\Gamma\,\U}$ is the constantly $\top_0$ morphism, i.e.\ it maps
objects to $\top_0$ and types to $\lambda\,\_.\,\top_0$, and maps morphisms and
terms to the identity function. It clearly preserves $\emptycon$ and $\blank\!\ext\!\blank$
up to isomorphism.

\subsubsection{Sigma type}

For $\bs{a : \Tm\,\Gamma\,\U}$ and $\bs{b : \Tm\,(\Gamma\ext \El\,a)\,\U}$, we
define $\bs{\Sigma\,a\,b : \Tm\,\Gamma\,\U}$ as the component-wise $\Sigma$ of $\ba$
and $\bb$. For the action on $\ulGamma : \Con_{\bGamma}$, we have:
\begin{alignat*}{3}
  &(\bs{\Sigma\,a\,b})\,\ulGamma && : \Ty_0 \\
  &(\bs{\Sigma\,a\,b})\,\ulGamma &&\defn (\alpha : \ba\,\ulGamma) \times \bb\,(\ulGamma,\,\alpha)
\end{alignat*}
For the action on $\ulsigma : \Sub\,\ulGamma\,\ulDelta$, we have:
\begin{alignat*}{3}
  &(\bs{\Sigma\,a\,b})\,\ulsigma && : (\alpha : \ba\,\ulGamma) \times \bb\,(\ulGamma,\,\alpha)
    \to (\alpha : \ba\,\ulDelta) \times \bb\,(\ulDelta,\,\alpha)\\
  &(\bs{\Sigma\,a\,b})\,\ulsigma &&\defn \lambda\,(\alpha,\,\beta).\,(\ba\,\ulsigma\,\alpha,\,\bb\,(\ulsigma,\,\refl)\,\beta)
\end{alignat*}
Above, the second field should have type
$\bb\,(\ulDelta,\,\ba\,\ulsigma\,\alpha)$, while $\beta :
\bb\,(\ulGamma,\,\alpha)$. Therefore we need a morphism in $\bs{\Gamma \ext
  \El\,a}$ from $(\ulGamma,\,\alpha)$ to $(\ulDelta,\,\ba\,\ulsigma\,\alpha)$,
which is defined as $(\ulsigma,\,\refl)$, where $\refl : \ba\,\ulsigma\,\alpha
\equiv \ba\,\ulsigma\,\alpha$.
The action on $\ulA : \Ty\,\ulGamma$ is
\begin{alignat*}{3}
  &(\bs{\Sigma\,a\,b})\,\ulA &&: (\alpha : \ba\,\ulGamma) \times \bb\,(\ulGamma,\,\alpha)
    \to \Ty_0\\
  &(\bs{\Sigma\,a\,b})\,\ulA &&\defn \lambda\,(\alpha,\,\beta).\,(\alpha' : \ba\,\ulA\,\alpha) \times \bb\,(\ulA,\,\alpha')\,\beta
\end{alignat*}
Here we are somewhat running out of notation: we use $\alpha'$ to refer to a
\emph{type} over $\alpha : \ba\,\ulGamma$ in the displayed cwf of elements
$\bs{\El\,a}$. The action on terms is analogous:
\begin{alignat*}{3}
  &(\bs{\Sigma\,a\,b})\,\ult && : ((\alpha,\,\beta) : (\alpha : \ba\,\ulGamma) \times \bb\,(\ulGamma,\,\alpha))
    \to (\alpha' : \ba\,\ulA\,\alpha) \times \bb\,(\ulA,\,\alpha')\,\beta\\
  &(\bs{\Sigma\,a\,b})\,\ult &&\defn \lambda\,(\alpha,\,\beta).\,(\ba\,\ult\,\alpha,\,\bb\,(\ult,\,\refl)\,\beta)
\end{alignat*}
For the preservation of $\emptycon$, we need to show
$(\bs{\Sigma\,a\,b})\,\ulemptycon \simeq \top_0$. Unfolding the definition, we
get $((\alpha : \ba\,\ulemptycon) \times \bb\,(\ulemptycon,\,\alpha)) \simeq
\top_0$. This holds since $\ba\,\ulemptycon \simeq \top_0$, so
$\ba\,\ulemptycon$ is contractible, thus $(\ulemptycon,\,\alpha) \equiv
\ulemptycon_{\bs{\Gamma \ext \El\,a}}$, and we also know $\bb\,\ulemptycon
\simeq \top_0$. For the preservation $\blank\!\ext\!\blank$, we need
\[
(\bs{\Sigma\,a\,b})\,(\ulGamma \ext \ulA) \simeq (\gamma : (\bs{\Sigma\,a\,b})\,\ulGamma) \times
  (\bs{\Sigma\,a\,b})\,\ulA\,\gamma
\]
Unfolding definitions and reassociating $\Sigma$ on the right side:
\begin{alignat*}{3}
   &(\alpha : \ba\,(\ulGamma \ext \ulA)) \times \bb\,((\ulGamma \ext \ulA),\,\alpha) \\
   &\simeq \\
   &(\alpha : \ba\,\ulGamma)
           \times (\beta : \bb\,(\ulGamma,\,\alpha))
           \times (\alpha' : \ba\,\ulA\,\alpha)
           \times \bb\,(\ulA,\,\alpha')\,\beta
\end{alignat*}
Since $\ba_{\ext} : \ba\,(\ulGamma \ext \ulA)) \simeq (\alpha : \ba\,\ulGamma)
\times (\beta : \bb\,(\ulGamma,\,\alpha))$, we can rewrite the left side using
pattern matching notation as
\[
  (\ba_{\ext}^{-1}\,(\gamma,\,\alpha) : \ba\,(\ulGamma \ext \ulA))
     \times \bb\,((\ulGamma \ext \ulA),\,(\gamma,\,\alpha))
\]
Now, since $((\ulGamma \ext \ulA),\,(\gamma,\,\alpha)) \equiv (\ulGamma,\,\gamma)
\ext_{\bs{\Gamma\ext\El\,a}} (\ulA,\,\alpha)$, we know that $\bb\,((\ulGamma
\ext \ulA),\,(\gamma,\,\alpha))$ is also isomorphic to the evident $\Sigma$
type, and the preservation isomorphism follows.

Projections and pairing for $\bs{\Sigma\,a\,b}$ are defined in the obvious way by
component-wise projection and pairing.






%% It makes sense to call an element
%% of $\ba\,\ulGamma$ $\alpha$, but we also need to refer to displayed elements over $\alpha$




%%   &(\bs{\Sigma\,a\,b})\,\ulA &&\defn \lambda\,(\alpha,\,\beta).\,(\alpha' : \ba\,\ulA\,\alpha) \times \bb\,(\ulA,\,\alpha')\,\beta\\
%%   &(\bs{\Sigma\,a\,b})\,\ult &&\defn \lambda\,(\alpha,\,\beta).\,(\ba\,\ult\,\alpha,\,\bb\,(\ult,\,\refl)\,\beta)
%% \end{alignat*}
%% \todo{TODO}

\subsubsection{Identity}

For $\bt$ and $\bu$ in $\bTm\,\bGamma\,(\bEl\,\ba)$, we define $\bId\,\bt\,\bu
\boldsymbol{:} \bTm\,\bGamma\,\bU$ as expressing pointwise equality of weak
sections. We rely on the assumption that $\Ty_0$ has identity type.
\begin{alignat*}{3}
& (\bId\,\bt\,\bu)\,\ulGamma &&\defn (\bt\,\ulGamma = \bu\,\ulGamma)\\
& (\bId\,\bt\,\bu)\,\ulA     &&\defn \lambda\,e.\, (\bt\,\ulA = \bu\,\ulA)
\end{alignat*}
Above, $\bt\,\ulA = \bu\,\ulA$ is well-typed because of $e :
\bt\,\ulGamma = \bu\,\ulGamma$. For substitutions, we have to complete a square
of equalities:
\begin{alignat*}{3}
  (\bId\,\bt\,\bu)\,(\ulsigma : \Sub\,\ulGamma\,\ulDelta) : (\bt\,\ulGamma = \bu\,\ulGamma) \ra
       (\bt\,\ulDelta = \bu\,\ulDelta)
\end{alignat*}
This can be given by $\bt\,\ulsigma : \ba\,\ulsigma\,(\bt\,\ulGamma) =
\bt\,\ulDelta$ and $\bu\,\ulsigma : \ba\,\ulsigma\,(\bu\,\ulGamma) =
\bu\,\ulDelta$. The action on terms is analogous.

The $\emptycon$-preservation $(\bt\,\ulemptycon = \bu\,\ulemptycon) \simeq
\top_0$ follows from $\ba\,\ulemptycon \simeq \top_0$. For $\ext$-preservation,
we need to show
\[
 (\bt\,(\ulGamma \ext \ulA) = \bu\,(\ulGamma \ext \ulA)) \simeq
 ((e : \bt\,\ulGamma = \bu\,\ulGamma) \times (\bt\,\ulA = \bu\,\ulA))
\]
This follows from $\ext$-preservation by $\ba$. Equality reflection and
$\bs{\refl :} \bId\,\bt\,\bt$ are also evident.

\subsubsection{Infinitary function type}

For $\mi{Ix} : \Ty_0$ and $\bb : \mi{Ix} \ra \bTm\,\bGamma\,\bU$, we aim to define
$\bPiinf\,\mi{Ix}\,\bb \bs{:} \bTm\,\bGamma\,\bU$. The underlying functions
are:
\begin{alignat*}{3}
  & (\bPiinf\,\mi{Ix}\,\bb)\,\ulGamma    &&:= (i : \mi{Ix})\ra \bb\,i\,\ulGamma\\
  & (\bPiinf\,\mi{Ix}\,\bb)\,\ulsigma    &&:= \lambda\,i.\, \bb\,i\,\ulsigma\\
  & (\bPiinf\,\mi{Ix}\,\bb)\,\ulA\       &&:= \lambda\,\Gamma.\,(i : \mi{Ix})\ra \bb\,i\,\ulA\,(\Gamma\, a)\\
  & (\bPiinf\,\mi{Ix}\,\bb)\,\ult        &&:= \lambda\,i.\, \bb\,i\,\ult
\end{alignat*}
We rely on $\Pi$ in the inner theory. The preservation isomorphisms are
pointwise inherited from $\bb$. One direction of the isomorphisms is defined as
follows. Note that $\emptycon_{\bU} \equiv \top$ and $\ext_{\bU}$ is $\Sigma$.
\begin{alignat*}{3}
  &(\bPiinf\,\mi{Ix}\,\bb)_{\emptycon}^{-1} && : \top\ra (\bPiinf\,\mi{Ix}\,\bb)\,\emptycon\\
  &(\bPiinf\,\mi{Ix}\,\bb)_{\emptycon}^{-1} && \defn \lambda\,\_\,i.\,(\bb\,i)_{\emptycon}^{-1}\,\tt
\end{alignat*}
\begin{alignat*}{3}
  &(\bPiinf\,\mi{Ix}\,\bb)_{\ext}^{-1} && : (\Gamma : (\bPiinf\,\mi{Ix}\,\bb)\,\ulGamma)\times((\bPiinf\,\mi{Ix}\,\bb)\,\ulA\,\Gamma)\\
  & && \hspace{0.5em}\ra (\bPiinf\,\mi{Ix}\,\bb)\,(\ulGamma \ext \ulA)\\
  & (\bPiinf\,\mi{Ix}\,\bb)_{\ext}^{-1} && \defn \lambda\,(\Gamma,A)\,i.\,(\bb\,i)_{\ext}^{-1}(\Gamma\,i,\,A\,i)
\end{alignat*}

\subsubsection{Inductive function type}

For $\boldsymbol{a : \Tm\,\Gamma\,\U}$ and $\boldsymbol{B :
  \Ty\,(\Gamma\ext\El\,a)}$, we aim to define $\boldsymbol{\Pi\,a\,B}
\boldsymbol{:} \bTy\,\bGamma$. The underlying sets are unchanged.
\begin{alignat*}{3}
  & \Con_{\bs{\Pi\,a\,B}}\,\ulGamma &&\defn (\gamma : \ba\,\ulGamma) \to \Con_{\bB}\,(\ulGamma,\,\gamma)\\
  & \Sub_{\bs{\Pi\,a\,B}}\,\Gamma\,\Delta\,\ulsigma &&\defn
    (\gamma : \ba\,\ulGamma)\to \Sub_{\bB}\,(\Gamma\,\gamma)\,(\Delta\,(\ba\,\ulsigma\,\gamma))\,(\ulsigma,\,\refl)\\
  & \Ty_{\bs{\Pi\,a\,B}}\,\Gamma\,\ulA &&\defn
  \{\gamma : \ba\,\ulGamma\}(\alpha : \ba\,\ulA\,\gamma)
  \to \Ty_{\bB}\,(\Gamma\,\gamma)\,(\ulA,\,\alpha)\\
  & \Tm_{\bs{\Pi\,a\,B}}\,\Gamma\,A\,\ult &&\defn
    (\gamma : \ba\,\ulGamma) \to \Tm_{\bB}\,(\Gamma\,\gamma)\,(\A\,(\ba\,\ult\,\gamma))\,(\ult,\,\refl)
\end{alignat*}
Likewise, all structure is defined pointwise using $\bB$ structure. Similarly to
the $\bEl$ case, we have to sometimes fall through the defining isomorphisms for
$\ba$ structure. For comparison, in the finitary case we had the following definition:
\[
  (\Gamma \ext_{\bs{\Pi\,a\,B}} A)\,(\gamma,\,\alpha) \defn (\Gamma\,\gamma \ext_{\bB} A\,\alpha)
\]
Here, $(\gamma,\,\alpha) : \ba\,(\ulGamma \ext \ulA)$, so also
$(\gamma,\,\alpha) : (\gamma : \ba\,\ulGamma) \times \ba\,\ulA\,\gamma$, so the
$\Sigma$ pattern-matching notation is justified in the definition. In the
current infinitary case, we have $(\ba_{\ext},\,\ba_{\ext}^{-1}) :
\ba\,(\ulGamma \ext \ulA) \simeq ((\gamma : \ba\,\ulGamma) \times
\ba\,\ulA\,\gamma)$ instead. But we can use the intuition that set isomorphisms
are like unary record types, so we can still give a pattern-matching definition:
\[
  (\Gamma \ext_{\bs{\Pi\,a\,B}} A)\,(\ba_{\ext}^{-1}(\gamma,\,\alpha)) \defn
   (\Gamma\,\gamma \ext_{\bB} A\,\alpha)
\]
For the definitions of other type and term formers, we likewise insert the
isomorphisms appropriately. It remains to define iso-cleaving
$\bs{\Pi}$. Coercion is given by mapping indices backwards in $\bEl\,\ba$ and
coercing outputs forwards in $\bB$.
\begin{alignat*}{3}
  & \coe\,\ulsigma\,\Gamma &&\defn
    \lambda\,\gamma.\,\coe_{\bB}\,(\ulsigma,\refl)\,(\Gamma\,(\ba\,(\ulsigma^{-1})\,\gamma))\\
  & \coe\,\ult\,A &&\defn
    \lambda\,\gamma\,a.\,\coe_{\bB}\,(\ult,\refl)\,(A\,(\ba\,(\ult^{-1})\,(\ba_{\ext}^{-1}(\gamma,a))))
\end{alignat*}
Likewise, $\coh$-s are given by backwards-forwards $\coh$-s. As before,
$\bs{\appi}$ and $\bs{\lami}$ are defined as currying and uncurrying the
underlying functions.

\subsubsection{External function type}

For $\mi{Ix} : \Set_j$ and $\bB : \mi{Ix} \ra \bTy\,\bGamma$, we define $\bPie\,\mi{Ix}\,\bB
\bs{:} \bTy\,\bGamma$ as the $\mi{Ix}$-indexed direct product of $\bB$. Since the
indexing is given by a metatheoretic function, every component is given in the
evident pointwise way, including iso-cleaving.

\section{Discussion of Semantics}

\subsubsection{Iso-fibrancy as a structure identity principle}

The flcwfs of algebras that we get from the infinitary semantics are exactly the
same as in the finitary case. However, signature types are a bit more
interesting. The iso-fibrancy of types can be understood as a weaker version of
the \emph{structure identity principle} in homotopy type theory.

The structure identity principle says that isomorphism of algebras is equivalent
to equality of algebras. This is the same as saying that categories of algebras
are univalent \cite{univalent-categories}. Assuming a signature $\Gamma$ and
algebras $\gamma \simeq \gamma'$, we have $\gamma = \gamma'$. This equality is
respected by every construction in HoTT, which implies that for any HoTT type
family $F : \Gamma^A \to \ms{Type}$, we have a function $F\,\gamma \to
F\,\gamma'$.

We get a similar but weaker statement from the infinitary semantics: for $\sigma
: \gamma \simeq \gamma'$ and some ToS type $A : \Ty\,\Gamma$, we have a function
$\coe\,\sigma : A^A\,\gamma \to A^A\,\gamma'$. We also have
$\coh\,\sigma\,\alpha : \alpha \simeq_{\sigma} \coe\,\sigma\,\alpha$ for some
$\alpha : A^A\,\gamma$. So we can transport over isomorphisms, but not all
metatheoretic families can be transported, only those which arise as ToS types.

Of course, we can transport over multiple types, or telescopes of types too, by
iterated transport. For instance, given $A : \Ty\,\Gamma$, $B : \Ty\,(\Gamma
\ext A)$, $\alpha : A^A\,\gamma$ and $\beta : B^A\,(\gamma,\,\alpha)$, we can
transport $\alpha$ first, then transport $\beta$ by
$(\sigma,\,\coh\,\sigma\,\alpha)$.  Alternatively, we could add large $\Sigma$
types to ToS, as $\Sigma : (A : \Ty\,\Gamma) \to \Ty\,(\Gamma \ext A) \to \Ty
\Gamma$, thereby making iterated transport superfluous.

\subsubsection{Variations of semantics}

First, unlike in the finitary case, we have no opportunity to minimize
assumptions on the inner theory. Already when we compute algebras, we need inner
$\Pi$ for infinitary functions, inner $\top$ for $\top$, inner $\Sigma$ for
$\Sigma$ and inner $\blank\!=\!\blank$ for $\Id$.

Second: can we add the ``large'' equality type, which includes sort equations,
back to infinitary signatures? We dropped sort equations in this chapter because
they are clearly not isofibrant. We can add them back into the mix though, at
the price of dropping things from the semantics of signatures. The reason for
having isofibrant types is that type formers in $\U$ preserve $\emptycon$ and
$\blank\!\ext\!\blank$ only up to isomorphism. If we drop all semantic
components which depend on $\emptycon$ and $\blank\!\ext\!\blank$, we can drop
isofibrancy too from the model, and everything works. In this case, we still get
a category of algebras, plus a notion of induction, but we cannot show that
initiality is equivalent to induction, as the proof of Theorem
\ref{thm:initiality-induction} depends on $\blank\!\ext\!\blank$. We cannot do
term algebra constructions (see in Section \ref{sec:inf-term-algebras}) and
lambda-encodings (in Section \ref{sec:lambda-encodings}) either, since they rely
on isofibrancy.

\subsubsection{Substitutions}

\todo{Add section on signature semantics of signatures!!}

In this chapter we gain significant expressive power in defining model
constructions. Generally speaking, almost all constructions in the literature
which have been dubbed ``syntactic translations'' or ``syntactic models'' can be
now defined as ToS substitutions. Intuitively, this works because
\begin{itemize}
\item
  Syntactic translations usually do not rely on models being actually syntactic.
  They don't use induction on syntax in the \emph{target} theory. A rare and
  notable counterexample is our construction of recursors and eliminators for
  term models. These are perhaps ``syntactic'' in the sense that they
  prominently involve the syntax of some type theory. And they actually rely on
  syntax being syntax, because they construct recursor/eliminator functions by
  induction on terms.
\item
  Syntactic translations rarely if ever involve higher-order constructions.
  Such would be interpreting $\Con$ with $(\Con \to \Con) \to \Con$, for a
  contrived example.
\end{itemize}

\begin{myexample}
For a warmup example, now we can construct categories from monoids. Let us have
$\ms{MonoidSig}$ as the signature for monoids, with $\ms{M} : \U$ as the carrier
set, $\blank\!\cdot\!\blank : \ms{M} \to \ms{M} \to \El\,\ms{M}$ as
multiplication and $\epsilon : \El\,\ms{M}$ as identity the element. We define
$\sigma : \Sub\,\ms{MonoidSig}\,\ms{CatSig}$ to contain $\ms{Obj} \defn \top$,
$\ms{Hom} \defn \lambda\,\_\,\_.\,\ms{M}$, $\id \defn \epsilon$ and
$\blank\!\circ\!\blank \defn \blank\!\cdot\!\blank$.
\end{myexample}

\todo{Add section on signature semantics of signatures!!}


\section{Term Algebras}
\label{sec:inf-term-algebras}

We adapt now the previous term algebra construction to the infinitary
case. We again switch to the ETT setup with cumulative universes. We
assume Section \ref{sec:cumulative-ett} without any change. Also, we adapt
\ref{sec:ett-signatures} to infinitary signatures and semantics. All definitions
are the same, the only change is that the $\bM_{i,j}$ model is now the
isofibrant flcwf model, and we have the infinitary ToS.

\subsection{Term Algebra Construction}
\label{sec:iqii-term-algebra-construction}

The term algebra construction changes significantly. The reason is the
following. In the finitary case, the key property was that ``small types
evaluated in the term model are sets of terms''. Formally, we had for $a :
\Tm\,\Omega\,\U$ that $a^A\,(\Omega^T\,\id) \equiv \Tm\,\Omega\,(\El\,a)$.  This
is now weakened to an isomorphism, i.e.\ $a^A\,(\Omega^T\,\id) \simeq
\Tm\,\Omega\,(\El\,a)$.

This is again necessary because of the closure of $\U$ under type formers. For
example, $\top^A\,(\Omega^T\,\id) \equiv \top$, and $\Tm\,\Omega\,(\El\,\top)$
is merely isomorphic to $\top$. We assume $\Omega : \Sig_j$ for some $j$
level, and define $\blank^T$ by induction on $\syn_j$.
\begin{alignat*}{3}
  &\blank^T &&: (\Gamma : \Con)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^A\\
  &\blank^T &&: (\sigma : \Sub\,\Gamma\,\Delta)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Delta^T\,(\sigma \circ \nu) \simeq \sigma^A\,(\Gamma^T\,\nu)\\
  &\blank^T &&: (A : \Ty\,\Gamma)&&(\nu : \Sub\,\Omega\,\Gamma) \to \Tm\,\Omega\,(A[\nu])
  \to A^A\,(\Gamma^T\,\nu)\\
  &\blank^T &&: (t : \Tm\,\Gamma\,A)&&(\nu : \Sub\,\Omega\,\Gamma) \to A^T\,\nu\,(A[\nu]) \simeq_{\id} t^A\,(\Gamma^T\,\nu)
\end{alignat*}
In short, interpretations of substitutions and terms are weakened to
isomorphisms.  By $\simeq_{\id}$ we mean a displayed isomorphism of objects in
the semantic $A$ (which is an flcwf isofibration); recall Definition
\ref{def:displayed-iso}.  The isomorphism is ``vertical'' since it lies over
$\id$.

The interpretation of the cwf is the same as before, but like in the isofibrant
semantics, we have to use explicit $\coe$ instead of silently transporting over
equalities. In the interpretations of substitutions and terms, we have to
explicitly compose isomorphisms and sometimes lift them using $\coh$. We give
some examples. The interpretation of context formers is the same as before:
\begin{alignat*}{3}
  &\emptycon^T\,\nu           &&\defn \tt\\
  &(\Gamma \ext A)^T(\nu,\,t) &&\defn (\Gamma^T\,\nu,\,A^T\,\nu\,t)
\end{alignat*}
Type substitution with $\sigma : \Sub\,\Gamma\,\Delta$ is
interpreted as coercion:
\begin{alignat*}{3}
  &(A[\sigma])^T : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(A[\sigma][\nu]) \to A^A\,(\sigma^A\,(\Gamma^T\,\nu)) \\
  &(A[\sigma])^T\,\nu\,t \defn \coe\,(\sigma^T\,\nu)\,(A^T\,(\sigma\circ\nu)\,t)
\end{alignat*}
Composition of $\sigma : \Sub\,\Delta\,\Xi$ and $\delta : \Sub\,\Gamma\,\Delta$
is the following:
\begin{alignat*}{3}
  &(\sigma \circ \delta)^T : (\nu : \Sub\,\Omega\,\Gamma) \to \Delta^T\,(\sigma\circ\delta\circ\nu) \simeq \sigma^A\,(\delta^A\,(\Gamma^T\,\nu))\\
  &(\sigma \circ \delta)^T\,\nu \defn \sigma^M\,(\delta^T\,\nu) \circ \sigma^T\,(\delta\circ\nu)
\end{alignat*}
Above, we have
\begin{alignat*}{3}
& \delta^T\,\nu &&: \Xi^T\,(\delta\circ\nu) \simeq \delta^A\,(\Gamma^T\,\nu)\\
& \sigma^M\,(\delta^T\,\nu) &&: \sigma^A\,(\Xi^T\,(\delta\circ\nu)) \simeq \sigma^A\,(\delta^A\,(\Gamma^T\,\nu))\\
& \sigma^T\,(\delta\circ\nu) &&: \Delta^T\,(\sigma\circ\delta\circ\nu) \simeq \sigma^A\,(\Xi^T\,(\delta\circ \nu))
\end{alignat*}
Hence, the type of the composition in the definition checks out. We make use of
the fact that $\sigma^M$ sends an isomorphism in $\Gamma$ to an isomorphism in
$\Delta$.

Substitution extension is a somewhat more complicated case. We want to interpret
the extension of $\sigma : \Sub\,\Gamma\,\Delta$ with $t :
\Tm\,\Gamma\,(A[\sigma])$:
\[
      (\sigma,\,t)^T : (\nu : \Sub\,\Omega\,\Gamma)
  \to (\Delta \ext A)^T\,((\sigma,\,t)\circ\nu)\simeq(\sigma,\,t)^A\,(\Gamma^T\,\nu)
\]
The goal is an isomorphism in the semantic $\Gamma \ext A$ category, i.e.\ the
total category of $A$. Every isomorphism in $\Gamma \ext A$ arises as packing
together a $\Gamma$ isomorphism and a displayed $A$ isomorphism over it. We can compute
the type further:
\[
      (\sigma,\,t)^T : (\nu : \Sub\,\Omega\,\Gamma)
  \to (\Delta^T\,(\sigma \circ \nu),\,A^T\,(\sigma\circ\nu)\,(t[\nu])) \simeq (\sigma^A\,(\Gamma^T\,\nu),\,t^A\,(\Gamma^T\,\nu))
\]
We can exhibit $\sigma^T\,\nu : \Delta^T\,(\sigma \circ \nu) \simeq
\sigma^A\,(\Gamma^T\,\nu)$ as the base component of the goal isomorphism. Now we
need a displayed isomorphism over it. Following the pattern, we may try
$t^T\,\nu$:
\[
  t^T\,\nu : (A[\sigma])^T\,\nu\,(t[\nu]) \simeq_{\id} t^A\,(\Gamma^T\,\nu)
\]
Computing the type:
\[
  t^T\,\nu : \coe\,(\sigma^T\,\nu)\,(A^T\,(\sigma\circ\nu)\,(t[\nu])) \simeq_{\id} t^A\,(\Gamma^T\,\nu)
\]
So this is not quite what is needed; we want a displayed iso over $\sigma^T\,\nu$, but we have
something over $\id$. We can fix this using $\coh$:
\[
\coh\,(\sigma^T\,\nu)\,(A^T\,(\sigma\circ\nu)\,(t[\nu])) :
A^T\,(\sigma\circ\nu)\,(t[\nu]) \simeq_{\sigma^T\,\nu} \coe\,(\sigma^T\,\nu)\,(A^T\,(\sigma\circ\nu)\,(t[\nu]))
\]
The composition of $t^T\,\nu$ and the above now checks out:
\[
  (\sigma,\,t)^T\,\nu \defn (\sigma^T\,\nu,\,t^T\,\nu\circ \coh\,(\sigma^T\,\nu)\,(A^T\,(\sigma\circ\nu)\,(t[\nu])))
\]
We omit the rest of the cwf interpretation. It should be apparent that explicit
$\coe$ and $\coh$-handling is fairly technical. It should be noted though that
in a proof assistant, the finitary and infinitary constructions would be of
similar difficulty, because there we cannot rely on equality reflection and
implicit transports to magically tidy up the formalization. In fact, even in the
finitary case it would be a good idea to structure the formalization around coercions
and coherences.

The high-level explanation for why the weakened constructions continue to work,
is the same as what we gave in the section on iso-fibrant semantics: we do
nothing which would violate stability under isomorphisms; additionally, because
our isofibrations are \emph{split}, coercion and coherence compute strictly on
identities and compositions, which ensures that conversion equations in the syntax
are respected. For example, functoriality of the type substitution defined above
relies on $\coe$ computation on identity and composition.

The universe is interpreted as follows.
\begin{alignat*}{3}
  &\U^T : (\nu : \Sub\,\Omega\,\Gamma) \to \Tm\,\Omega\,\U \to \Set_{j + 1} \\
  &\U^T\,\nu\,a \defn \Tm\,\Omega\,(\El\,a) \\
  &\\
  &(\El\,a)^T : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\El\,(a[\nu]))) \to a^A\,(\Gamma^T\,\nu)\\
  &(\El\,a)^T\,\nu\,t \defn (a^T\,\nu)\,t
\end{alignat*}
In the interpretation of $\El$, note that
\[
a^T\,\nu : \Tm\,\Omega\,(\El\,(a[\nu])) \simeq_{\id} a^A\,(\Gamma\,\nu)
\]
But this is an isomorphism in the semantic $\U$, which is the category of sets
in $\Set_{j + 1}$. So coercion along $a^T\,\nu$ is simply function application,
and we are justified in writing $(a^T\,\nu)\,t$.

For each type former in $\U$, we have to exhibit an isomorphism of sets in the
interpretation. For $\top$, we need
\[
  \top^T : (\nu : \Sub\,\Omega\,\Gamma) \to \U^T\,\nu\,(\top[\nu]) \simeq_{\id} \top^A\,(\Gamma^T\,\nu)
\]
The result type computes to $\Tm\,\Omega\,(\El\,\top) \simeq \top$, which is evident. For $\Sigma$, we
have to show
\[
   \Tm\,\Omega\,(\El\,(\Sigma\,(a[\nu])\,(b[\nu\circ\p,\,\q]))) \simeq ((\alpha : a^A\,(\Gamma^T\,\nu)) \times b^A\,(\Gamma^T\,\nu,\,\alpha))
\]
This follows from the induction hypotheses $a^T$ and $b^T$, which establish the
first and second components of the desired isomorphism.

For the identity type, we need
\[
  \Tm\,\Omega\,(\El\,(\Id\,(t[\nu])\,(u[\nu])) \simeq (t^A\,(\Gamma^T\,\nu) \equiv u^A\,(\Gamma^T\,\nu))
\]
This follows from $t^T\,\nu$, $u^T\,\nu$ and the specifying isomorphism of
$\Id$.

The infinitary function type follows the same pattern. We define the isomorphism
below using induction hypotheses and the specifying isomorphism of $\Piinf$.
\[
\Tm\,\Omega\,(\El\,(\Piinf\,\mi{Ix}\,(\lambda\,i.\,(b\,i)[\nu])))
\simeq
((i : \mi{Ix}) \to (b\,i)^A\,(\Gamma\,\nu))
\]

Inductive functions are interpreted by transport along the $a^T\,\nu$
isomorphism from the domain type:
\begin{alignat*}{3}
  &(\Pii\,a\,B)^T : (\nu : \Sub\,\Omega\,\Gamma)(t : \Tm\,\Omega\,(\Pii\,(a[\nu])\,(B[\nu\circ\p,\,\q])))\\
  & \hspace{3.5em}\to (\alpha : a^A\,(\Gamma^T\,\nu)) \to B^A\,(\Gamma^T\,\nu,\,\alpha)\\
  &(\Pii\,a\,B)^T\,\nu\,t \defn \lambda\,\alpha.\,
         B\,(\nu,\,(a^T\,\nu)^{-1}\,\alpha)\,(t\,((a^T\,\nu)^{-1}\,\alpha))
\end{alignat*}
External functions are interpreted the same way as in the finitary case.


\subsection{Recursor and Eliminator Construction}

\todo{todo}

\section{Levitation and Bootstrapping}
\label{sec:iqii-levitation}

\section{Lambda-Encodings}
\label{sec:lambda-encodings}

In \emph{lambda-encodings} of a signature, inductive data is represented as
functions. The core trade-off is that we get inductive types from few
assumptions (basic type formers and universes), but the constructed types only
support weakened elimination principles. In this section we generalize the
following two lambda-encodings to infinitary QII signatures.
\begin{itemize}
  \item The Böhm-Berarducci encodings \cite{boehm-berarducci}, or BB-encodings
    henceforth, require an impredicative base universe. We have non-dependent
    elimination (recursion) from BB-encoded types to the base universe, but not
    to any other universe.
  \item Impredicative encodings as given by Awodey, Frey and Speight
    \cite{afs-encoding}, or AFS-encodings in short, additionally assume that the
    base universe is closed under an intensional identity type which supports
    function extensionality. These encodings allow dependent elimination, but
    also only targeting the impredicative universe.
\end{itemize}
It turns out that lambda-encodings are obtained as modest variations of the term
algebra construction in Section \ref{sec:inf-term-algebras}. Additionally, we
shall see that lambda-encodings also rely on isofibrancy, so it makes sense to
present them for the infinitary ToS.

\subsubsection{Metatheory}

The main benefit of lambda-encodings is that we do not have to assume that ToS
syntaxes exist. However, we do need to make use of most basic type formers in
the construction, so there is not much benefit to working in 2LTT. Hence, we use
the ETT setting with cumulative $\Set_i$ universes. We use the bootstrapping
definition of signatures from Section \ref{sec:iqii-levitation}, i.e.\ a
signature is a context in an arbitrary model of ToS.

\subsection{Böhm-Berarducci Encoding}

\textbf{Assumption.} We assume that $\Set_0$ is impredicative. This means that
for $A : \Set_i$ and $B : A \to Set_0$, we have that $(a : A) \to B\,a :
\Set_0$. In short, $\Set_0$ is closed under arbitrarily indexed dependent
products. This assumption is necessary to generalize the classic impredicative
encodings of Böhm and Berarducci. Impredicativity should be handled with care,
if we are to retain consistency:
\begin{itemize}
\item Only the base universe can be impredicative; if $\Set_1$ or any larger universe
      is impredicative too, the system is inconsistent \cite{TODO}.
\item Only function types are special in a impredicative universe. Impredicative
      $\Sigma$-types are inconsistent in our setting. They are consistent only in
      rather restricted settings, for instance System F is consistent with
      impredicative \emph{existential} types, which are like $\Sigma$-types but with
      a positive recursion principle instead of negative projections \cite{TODO}.
\item Impredicative $\Set_0$ is inconsistent with the law of excluded middle
      (LEM). This is not really a concern for us, as we will not use LEM in the following,
      and actually we don't use LEM anywhere in this thesis.
\end{itemize}

\begin{mydefinition} We define the \textbf{impredicative $\Set_0$ models} of ToS in the following.
These are the same as the standard models which can be used to compute $\blank^A$, i.e.\ the notion
of algebras for each signature. However, the inductive sorts are fixed to be in $\Set_0$.

For an assumed $j$ level, we define a model in $\ToS_{j+1,j}$, where we have

\end{mydefinition}







\subsection{Awodey-Frey-Speight Encoding}















\section{Left Adjoints of Substitutions}



%% \chapter{Levitation, Bootstrapping and Universe Levels}
%% \label{chap:levitation}

%% \section{Levitation for Closed QIITs}
%% \section{Levitation for Infinitary QIITs}

\chapter{Higher Inductive-Inductive Signatures}
\label{chap:hiit}

\section{Theory of Signatures}
\section{Semantics}

\chapter{Conclusion}

\bibliography{references}
\backmatter
\end{document}
