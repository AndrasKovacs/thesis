\documentclass[12pt,a4paper,twoside,openany]{book}

%% build: latexmk -pdf -pvc thesis.tex


%% Packages
%% --------------------------------------------------------------------------------

\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathpartir}
\usepackage{scalerel}
\usepackage{stmaryrd}
\usepackage{authblk}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\usepackage{bm}
\usepackage{titlesec}

%% \bibliographystyle{IEEEtran}
\bibliographystyle{alpha}

%% Environments
%% --------------------------------------------------------------------------------

\theoremstyle{remark}
\newtheorem{notation}{Notation}

\theoremstyle{definition}
\newtheorem{mydefinition}{Definition}
\newtheorem{myexample}{Example}
\newtheorem{mylemma}{Lemma}

\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newtheorem{corollary}{Corollary}

%% Fonts and spacing
%% --------------------------------------------------------------------------------

%% \geometry{left=3cm,right=2cm,top=2.5cm,bottom=2.5cm,includehead,includefoot}

\linespread{1.25}
\geometry{left=4cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includehead,includefoot}


%% Chapter style
%% --------------------------------------------------------------------------------

\titleformat{\chapter}[display]
  {\bfseries\Large}
  {\filright\MakeUppercase{\chaptertitlename} \Huge\thechapter}
  {1ex}
  {\titlerule\vspace{1ex}\filleft}
  [\vspace{1ex}\titlerule]


%% Abbrevs
%% --------------------------------------------------------------------------------

\newcommand{\mi}[1]{\mathit{#1}}
\newcommand{\ms}[1]{\mathsf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}


\newcommand{\zero}{\ms{zero}}
\newcommand{\suc}{\ms{suc}}

\newcommand{\refl}{\mathsf{refl}}
\newcommand{\reflect}{\mathsf{reflect}}
\newcommand{\Reflect}{\mathsf{Reflect}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\Con}{\mathsf{Con}}
\newcommand{\Sub}{\mathsf{Sub}}
\newcommand{\Tm}{\mathsf{Tm}}
\newcommand{\Ty}{\mathsf{Ty}}
\newcommand{\U}{\mathsf{U}}
\newcommand{\El}{\mathsf{El}}
\newcommand{\Id}{\mathsf{Id}}
\newcommand{\proj}{\mathsf{proj}}
\renewcommand{\tt}{\mathsf{tt}}
\newcommand{\blank}{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}
\newcommand{\ra}{\rightarrow}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\Lift}{\Uparrow}
\newcommand{\ToS}{\mathsf{ToS}}
\newcommand{\ext}{\triangleright}
\newcommand{\emptycon}{\scaleobj{.75}\bullet}
\newcommand{\Pii}{\Pi}
\newcommand{\funi}{\Rightarrow}
\newcommand{\fune}{\Rightarrow^{ext}}
\newcommand{\appi}{\mathsf{app}}
\newcommand{\lami}{\mathsf{lam}}
\newcommand{\Pie}{\Pi^{\mathsf{ext}}}
\newcommand{\appe}{\mathsf{app^{ext}}}
\newcommand{\lame}{\mathsf{lam^{ext}}}
\newcommand{\toe}{\to^{ext}}
\newcommand{\Piinf}{\Pi^{\mathsf{inf}}}
\newcommand{\appinf}{\mathsf{app^{inf}}}
\newcommand{\laminf}{\mathsf{lam^{inf}}}
\newcommand{\appitt}{\mathop{{\scriptstyle @}}}
\newcommand{\Refl}{\mathsf{Refl}}
\newcommand{\IdU}{\mathsf{IdU}}
\newcommand{\ReflU}{\mathsf{ReflU}}
\newcommand{\Sig}{\mathsf{Sig}}
\newcommand{\ToSSig}{\mathsf{ToSSig}}
\newcommand{\Subtype}{\mathsf{Subtype}}
\newcommand{\subtype}{\mathsf{subtype}}
\newcommand{\NatSig}{\mathsf{NatSig}}
\newcommand{\Sg}{\Sigma}
\newcommand{\flcwf}{\mathsf{flcwf}}
\newcommand{\SigTy}{\mathsf{SigTy}}
\newcommand{\SigTm}{\mathsf{SigTm}}

\newcommand{\Kfam}{\mathsf{K}}
\newcommand{\lamK}{\mathsf{lam}_{\K}}
\newcommand{\appK}{\mathsf{app}_{\K}}

\newcommand{\p}{\mathsf{p}}
\newcommand{\q}{\mathsf{q}}
\newcommand{\K}{\mathsf{K}}
\newcommand{\A}{\mathsf{A}}
\newcommand{\D}{\mathsf{D}}
\renewcommand{\S}{\mathsf{S}}
\newcommand{\arri}{\Rightarrow}
\newcommand{\arre}{\Rightarrow^{\mathsf{ext}}}
\newcommand{\arrinf}{\Rightarrow^{\mathsf{inf}}}
\newcommand{\syn}{\mathsf{syn}}
\newcommand{\SynSig}{\mathsf{SynSig}}
\newcommand{\bCon}{\boldsymbol{\Con}}
\newcommand{\bTy}{\boldsymbol{\Ty}}
\newcommand{\bSub}{\boldsymbol{\Sub}}
\newcommand{\bTm}{\boldsymbol{\Tm}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\bt}{\boldsymbol{t}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\bA}{\boldsymbol{A}}
\newcommand{\ba}{\boldsymbol{a}}
\newcommand{\bb}{\boldsymbol{b}}
\newcommand{\bB}{\boldsymbol{B}}
\newcommand{\bid}{\boldsymbol{\id}}
\newcommand{\bemptycon}{\boldsymbol{\emptycon}}
\newcommand{\bSet}{\boldsymbol{\Set}}
\newcommand{\bU}{\boldsymbol{\U}}
\newcommand{\bEl}{\boldsymbol{\El}}
\newcommand{\bPii}{\boldsymbol{\Pi}}
\newcommand{\bPie}{\boldsymbol{\Pie}}
\newcommand{\bPiinf}{\boldsymbol{\Piinf}}
\newcommand{\bappi}{\boldsymbol{\mathsf{app}}}
\newcommand{\blami}{\boldsymbol{\mathsf{lam}}}
\newcommand{\bId}{\boldsymbol{\Id}}
\newcommand{\bM}{\boldsymbol{\mathsf{M}}}
\newcommand{\bT}{\boldsymbol{\mathsf{T}}}
\newcommand{\bS}{\boldsymbol{\mathsf{S}}}
\newcommand{\bP}{\boldsymbol{\mathsf{P}}}
\newcommand{\bD}{\boldsymbol{\mathsf{D}}}
\newcommand{\bI}{\boldsymbol{\mathsf{I}}}
\newcommand{\ul}[1]{\underline{#1}}
\newcommand{\ulGamma}{\ul{\Gamma}}
\newcommand{\ulDelta}{\ul{\Delta}}
\newcommand{\ulgamma}{\ul{\gamma}}
\newcommand{\ulOmega}{\ul{\Omega}}
\newcommand{\uldelta}{\ul{\delta}}
\newcommand{\ulsigma}{\ul{\sigma}}
\newcommand{\ulnu}{\ul{\nu}}
\newcommand{\ulepsilon}{\ul{\epsilon}}
\newcommand{\ult}{\ul{t}}
\newcommand{\ulu}{\ul{u}}
\newcommand{\ulA}{\ul{A}}
\newcommand{\ula}{\ul{a}}
\newcommand{\ulB}{\ul{B}}
\newcommand{\tos}{\mathsf{tos}}
\newcommand{\coe}{\mathsf{coe}}
\newcommand{\coh}{\mathsf{coh}}
\newcommand{\llb}{\llbracket}
\newcommand{\rrb}{\rrbracket}

\newcommand{\Var}{\ms{Var}}
\newcommand{\var}{\ms{var}}
\newcommand{\app}{\ms{app}}
\newcommand{\vz}{\ms{vz}}
\newcommand{\vs}{\ms{vs}}
\newcommand{\Alg}{\ms{Alg}}
\newcommand{\Mor}{\ms{Mor}}
\newcommand{\DispAlg}{\ms{DispAlg}}
\newcommand{\Section}{\ms{Section}}
\newcommand{\Initial}{\ms{Initial}}
\newcommand{\Inductive}{\ms{Inductive}}
\newcommand{\TmAlg}{\ms{TmAlg}}
\newcommand{\Rec}{\ms{Rec}}
\newcommand{\Ind}{\ms{Ind}}
\newcommand{\Obj}{\ms{Obj}}
\newcommand{\Nat}{\ms{Nat}}
\newcommand{\Bool}{\ms{Bool}}
\newcommand{\mbbC}{\mbb{C}}
\newcommand{\hmbbC}{\hat{\mbb{C}}}
\newcommand{\mbbD}{\mbb{D}}
\newcommand{\lam}{\ms{lam}}

\newcommand{\true}{\ms{true}}
\newcommand{\false}{\ms{false}}
\newcommand{\up}{\uparrow}
\newcommand{\down}{\downarrow}

\newcommand{\lab}{\langle}
\newcommand{\rab}{\rangle}
\newcommand{\defn}{:\equiv}

\newcommand{\yon}{\ms{y}}


%% --------------------------------------------------------------------------------

\title{Type-Theoretic Signatures for Algebraic Theories and Inductive Types}
\date{2021 September}
\author{András Kovács}

%% --------------------------------------------------------------------------------

\begin{document}
\maketitle

\frontmatter
\tableofcontents{}


\mainmatter

\chapter{Introduction}

\section{Specification and Semantics for Inductive Types}
\section{Overview of the Thesis and Contributions}
\section{Notation and Conventions}
\subsection{Metatheory}
\subsection{Universes}
\label{sec:universes}
\label{sec:notation}

\chapter{Simple Inductive Signatures}
\label{chap:simple-inductive-signatures}

In this chapter, we take a look at a very simple notion of inductive
signature. The motivation for doing so is to present the basic ideas of this
thesis in the easiest possible setting, with explicit definitions. The later
chapters are greatly generalized and expanded compared to the current one, and
are not feasible (and probably not that useful) to present in full formal
detail. We also include a complete Agda formalization of the contents of this
chapter, in less than 200 lines.

\todo{potentially in intro}

The mantra throughout this dissertation is the following: inductive types are
specified by typing contexts in certain \emph{theories of signatures}. For each
class of inductive types, there is a corresponding theory of signatures, which
is viewed as a proper type theory and comes equipped with an algebraic model
theory. \emph{Semantics} of signatures is given by interpreting them in certain
models of the theory of signatures. Semantics should at least provide a notion
of induction principle for each signature; in this chapter we provide a bit more
than that, and substantially more in Chapters \ref{chap:fqiit} and \ref{chap:iqiit}.

\section{Theory of Signatures}
\label{sec:simple-signatures}

Generally, more expressive theories of signatures can describe a larger classes
of inductive types. As we are aiming at minimalism right now, the current theory
of signatures is as follows:

\begin{mydefinition}
The \textbf{theory of signatures}, or ToS for short, is a simple type theory
equipped with the following features:
  \begin{itemize}
    \item An empty base type $\iota$.
    \item A \emph{first-order function type} $\iota\!\to\!\blank$; this is a
      function whose domain is fixed to be $\iota$. Moreover, first-order functions only
      have neutral terms: there is application, but no $\lambda$-abstraction.
  \end{itemize}
\end{mydefinition}

We can specify the full syntax using the following Agda-like inductive definitions.
\begin{alignat*}{4}
  & \Ty              &&: \Set           && \Var &&: \Con \to \Ty \to \Set \\
  & \iota            &&: \Ty            && \vz  &&: \Var\,(\Gamma \ext A)\,A \\
  & \iota\!\to\blank &&: \Ty \to \Ty    && \vs  &&: \Var\,\Gamma\,A \to \Var\,(\Gamma \ext B)\,A\\
  & && && &&\\
  & \Con             &&: \Set           && \Tm  &&: \Con \to \Ty \to \Set \\
  & \emptycon        &&: \Con           && \var &&: \Var\,\Gamma\,A \to \Tm\,\Gamma\,A \\
  & \blank\ext\blank &&: \Con \to \Ty \to \Con \hspace{2em} && \app &&: \Tm\,\Gamma\,(\iota\to A) \to \Tm\,\Gamma\,\iota
                                                           \to \Tm\,\Gamma\,A
\end{alignat*}
Here, $\Con$ contexts are lists of types, and $\Var$ specifies well-typed De Bruijn indices, where
$\vz$ represents the zero index, and $\vs$ takes the successor of an index.

\begin{notation} We use capital Greek letters starting from $\Gamma$ to refer to contexts, $A$, $B$, $C$ to
refer to types, and $t$, $u$, $v$ to refer to terms. In examples, we may use a
nameful notation instead of De Bruijn indices. For example, we may write $x :
\Tm\,(\emptycon \ext (x : \iota) \ext (y : \iota))\,\iota$ instead of $\var\,(\vs\,\vz)
: \Tm\,(\emptycon \ext \iota \ext \iota)\,\iota$. Additionally, we may write
$t\,u$ instead of $\app\,t\,u$ for $t$ and $u$ terms.
\end{notation}

\begin{mydefinition} \textbf{Parallel substitutions} map variables to terms.
\begin{alignat*}{3}
&\Sub : \Con \to \Con \to \Set\\
&\Sub\,\Gamma\,\Delta \equiv \{A\} \to \Var\,\Delta\,A \to \Tm\,\Gamma\,A
\end{alignat*}
We use $\sigma$ and $\delta$ to refer to substitutions. We also recursively
define the action of substitution on terms:
\begin{alignat*}{3}
  &\rlap{$\blank[\blank] : \Tm\,\Delta\,A \to \Sub\,\Gamma\,\Delta \to \Tm\,\Gamma\,A$}\\
  &(\var\, x)   &&[ \sigma ] \defn \sigma\,x\\
  &(\app\,t\,u) &&[ \sigma ] \defn \app\,(t[\sigma])\,(u[\sigma])
\end{alignat*}
The identity substitution $\id$ is defined simply as $\var$. It is easy to see that
$t[\id] = t$ for all $t$. Substitution composition is as follows.
\begin{alignat*}{3}
  &\blank\!\circ\!\blank : \Sub\,\Delta\,\Xi \to \Sub\,\Gamma\,\Delta \to \Sub\,\Gamma\,\Xi\\
  &(\sigma \circ \delta)\,x \defn (\sigma\,x)[\delta]
\end{alignat*}
\end{mydefinition}

\begin{myexample} We may write signatures for natural numbers and binary trees respectively as follows.
\begin{alignat*}{3}
  & \ms{NatSig}  &&\defn \emptycon \ext (\mi{zero} : \iota) \ext (\mi{suc} : \iota \to \iota)\\
  & \ms{TreeSig} &&\defn \emptycon \ext (\mi{leaf} : \iota) \ext (\mi{node} : \iota \to \iota \to \iota)
\end{alignat*}
\end{myexample}

In short, the current ToS allows inductive types which are
\begin{itemize}
\item \emph{Single-sorted}: this means that we have a single type constructior, corresponding to $\iota$.
\item \emph{Closed}: signatures cannot refer to any externally existing type. For example, we cannot write a signature for ``lists of natural number'' in a direct fashion, since there is no way to refer to the type of natural numbers.
\item \emph{Finitary}: inductive types corresponding to signatures are always
  finitely branching trees. Being closed implies being finitary, since an
  infinitely branching node would require some external type to index subtrees
  with. For example, $\mi{node} : (\mathbb{N} \to \iota) \to \iota$ would
  specify an infinite branching (if such type was allowed in ToS).
\end{itemize}

\emph{Remark.} We omit $\lambda$-expressions from ToS for the sake of
simplicity: this causes terms to be always in normal form (neutral, to be
precise), and thus we can skip talking about conversion rules. Later, starting
from Chapter \ref{chap:fqiit} we include proper $\beta\eta$-rules in signature
theories.

\section{Semantics}
\label{sec:simple-semantics}

For each signature, we need to know what it means for a type theory to support
the corresponding inductive type. For this, we need at least a notion of
\emph{algebras}, which can be viewed as a bundle of all type and
value constructors, and what it means for an algebra to support an
\emph{induction principle}.  Additionally, we may want to know what it means to
support a \emph{recursion principle}, which can be viewed as a non-dependent
variant of induction. In the following, we define these notions by induction on
ToS syntax.

\emph{Remark.} We use ``algebra'' and ``model'' synonymously throughout
this thesis.

\subsection{Algebras}

First, we calculate types of algebras. This is simply a standard interpretation
into the $\Set$ universe. We define the following operations by induction; the
$\blank^A$ name is overloaded for $\Con$, $\Ty$ and $\Tm$.
\begin{alignat*}{3}
& \hspace{-4em} \rlap{$\blank^A : \Ty \to \Set \to \Set$} \\
& \hspace{-4em} \iota^A\,&&X \defn X \\
& \hspace{-4em} (\iota\to A)^A\,&&X \defn X \to A^A\,X\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Con \to \Set \to \Set$}\\
& \hspace{-4em} \rlap{$\Gamma^A\,X \defn \{A : \Ty\} \to \Var\,\Gamma\,A \to A^A\,X$}\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Tm\,\Gamma\,A \to \{X : \Set\} \to \Gamma^A\,X \to A^A\,X$}\\
& \hspace{-4em} (\var\,x)^A\,&&\gamma \defn \gamma\,x\\
& \hspace{-4em} (\app\,t\,u)^A\,&&\gamma \defn t^A\,\gamma\,(u^A\,\gamma)\\
& \hspace{-4em} && \\
& \hspace{-4em} \rlap{$\blank^A : \Sub\,\Gamma\,\Delta \to \{X : \Set\} \to \Gamma^A\,X \to \Delta^A\,X$}\\
& \hspace{-4em} \rlap{$\sigma^A\,\gamma\,x \defn (\sigma\,x)^A\,\gamma$}
\end{alignat*}
Here, types and contexts depend on some $X : \Set$, which serves as the
interpretation of $\iota$. We define $\Gamma^A$ as a product: for each variable
in the context, we get a semantic type. This trick, along with the definition of
$\Sub$, makes formalization a bit more compact. Terms and substitutions are
interpreted as natural maps. Substitutions are interpreted by pointwise interpreting
the contained terms.

\begin{notation}
We may write values of $\Gamma^A$ using notation for $\Sigma$-types. For
example, we may write $(\mi{zero} : X) \times (\mi{suc} : X \to X)$ for the
result of computing $\ms{NatSig}^A\,X$.
\end{notation}

\begin{mydefinition} We define \textbf{algebras} as follows.
\begin{alignat*}{3}
  & \Alg : \Con \to \Set_1 \\
  & \Alg\,\Gamma \defn (X : \Set) \times \Gamma^A\,X
\end{alignat*}
\end{mydefinition}

\begin{myexample} $\Alg\,\ms{NatSig}$ is computed to $(X : \Set)\times(\mi{zero} :
X)\times(\mi{suc} : X \to X)$.
\end{myexample}

\subsection{Morphisms}

Now, we compute notions of morphisms of algebras. In this case, morphisms are
functions between underlying sets which preserve all specified structure. The
interpretation for calculating morphisms is a \emph{logical relation
interpretation} \cite{udayReynolds} over the $\blank^A$ interpretation. The key
part is the interpretation of types:
\begin{alignat*}{3}
  & \hspace{-4em}\rlap{$\blank^M : (A : \Ty)\{X_0\,X_1 : \Set\}(X^M : X_0 \to X_1) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-4em}\iota^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn X^M\,\alpha_0 = \alpha_1 \\
  & \hspace{-4em}(\iota\to A)^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn
       (x : X_0) \to A^M\,X^M\,(\alpha_0\,x)\,(\alpha_1\,(X^M\,x))
\end{alignat*}
We again assume an interpretation for the base type $\iota$, as $X_0$, $X_1$ and
$X^M : X_0 \to X_1$. $X^M$ is function between underlying sets of algebras, and
$A^M$ computes what it means that $X^M$ preserves an operation with type $A$. At
the base type, preservation is simply equality. At the first-order function
type, preservation is a quantified statement over $X_0$. We define morphisms for
$\Con$ pointwise:
\begin{alignat*}{3}
  &\blank^M : (\Gamma : \Con)\{X_0\,X_1 : \Set\} \to (X_0 \to X_1) \to \Gamma^A\,X_0 \to \Gamma^A\,X_1 \to \Set\\
  &\Gamma^M\,X^M\,\gamma_0\,\gamma_1 \defn
    \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^M\,X^M\,(\gamma_0\,x)\,(\gamma_1\,x)
\end{alignat*}
For terms and substitutions, we get preservation statements, which are sometimes
called \emph{fundamental lemmas} in discussions of logical relations \cite{udayReynolds}.
\begin{alignat*}{3}
  & \hspace{-10em}\rlap{$\blank^M : (t : \Tm\,\Gamma\,A) \to \Gamma^M\,X^M\,\gamma_0\,\gamma_1 \to A^M\,X^M\,(t^A\,\gamma_0)\,(t^A\,\gamma_1)$}\\
  & \hspace{-10em}(\var\,x)^M    &&\gamma^M \defn \gamma^M\,x \\
  & \hspace{-10em}(\app\,t\,u)^M &&\gamma^M \defn t^M\,\gamma^M\,(u^A\,\gamma_0)\\
  & \hspace{-10em}&& \\
  & \hspace{-10em}\rlap{$\blank^M : (\sigma : \Sub\,\Gamma\,\Delta) \to \Gamma^M\,X^M\,\gamma_0\,\gamma_1 \to \Delta^M\,X^M\,(\sigma^A\,\gamma_0)\,(\sigma^A\,\gamma_1)$}\\
  & \hspace{-10em} \rlap{$\sigma^M\, \gamma^M\,x \defn (\sigma\,x)^M\,\gamma^M$}
\end{alignat*}
The definition of $(\app\,t\,u)^M$ is well-typed by the induction hypothesis
$u^M\,\gamma^M : X^M\,(u^A\,\gamma_0) = u^A\,\gamma_1$.

\begin{mydefinition}
To get notions of \textbf{algebra morphisms}, we again pack up $\Gamma^M$ with
the interpretation of $\iota$.
\begin{alignat*}{3}
  & \Mor : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Alg\,\Gamma \to \Set \\
  & \Mor\,\{\Gamma\}\,(X_0,\,\gamma_0)\,(X_1,\,\gamma_1) \defn (X^M : X_0 \to X_1) \times \Gamma^M\,X^M\,\gamma_0\,\gamma_1
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation:
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\Mor\,\{\NatSig\}\,(X_0,\,\mi{zero_0},\,\mi{suc_0})\,(X_0,\,\mi{zero_1},\,\mi{suc_1}) \defn$} \\
           &(X^M : X_0 \to X_1) \\
   \times\,&(X^M\,\mi{zero_0} = \mi{zero_1}) \\
   \times\,&((x : X_0) \to X^M\,(\mi{suc_0}\,x) = \mi{suc_1}\,(X^M\,x))
\end{alignat*}
\end{myexample}

\begin{mydefinition} We state \textbf{initiality} as a predicate on algebras:
\begin{alignat*}{3}
  & \Initial : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set\\
  & \Initial\,\{\Gamma\}\,\gamma \defn
    (\gamma' : \Alg\,\Gamma) \to \ms{isContr}\,(\Mor\,\gamma\,\gamma')
\end{alignat*}
Here $\ms{isContr}$ refers to unique existence \cite[Section 3.11]{hottbook}. If we drop
$\ms{isContr}$ from the definition, we get the notion of weak initiality, which
corresponds to the recursion principle for $\Gamma$. Although we call this
predicate $\Initial$, in this chapter we do not yet show that algebras form a
category. We provide the extended semantics in Chapter \ref{chap:fqiit}. The
computed algebras and morphism there remain the same as in the current chapter.
\end{mydefinition}

\paragraph{Morphisms vs.\ logical relations.}
The $\blank^M$ interpretation can be viewed as a special case of logical
relations over the $\blank^A$ model: every morphism is a \emph{functional}
logical relation, where the chosen relation between the underlying sets happens
to be a function. Consider now a more general relational interpretation for
types:
\begin{alignat*}{3}
  & \hspace{-0.5em}\rlap{$\blank^R : (A : \Ty)\{X_0\,X_1 : \Set\}(X^R : X_0 \to X_1 \to \Set) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-0.5em}\iota^R\,&&X^R\,\alpha_0\,\,\alpha_1 \defn X^R\,\alpha_0\,\alpha_1 \\
  & \hspace{-0.5em}(\iota\to A)^R\,&&X^R\,\alpha_0\,\,\alpha_1 \defn
       (x_0 : X_0)(x_1 : X_1) \to X^R\,x_0\,x_1 \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,x_1)
\end{alignat*}
Here, functions are related if they map related inputs to related outputs. If we
know that $X^M\,\alpha_0\,\alpha_1 \equiv (f\,\alpha_0 = \alpha_1)$ for some $f$
function, we get
\[
  (x_0 : X_0)(x_1 : X_1) \to f\,x_0 = x_1 \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,x_1)
\]
Now, we can simply substitute along the input equality proof in the above type,
to get the previous definition for $(\iota \to A)^M$:
\[
  (x_0 : X_0) \to A^R\,X^R\,(\alpha_0\,x_0)\,(\alpha_1\,(f\,x_0))
\]
This substitution along the equation is called ``singleton contraction'' in the
jargon of homotopy type theory \cite{hottbook}. The ability to perform contraction
here is at the heart of the \emph{strict positivity restriction} for inductive
signatures. Strict positivity in our setting corresponds to only having
first-order function types in signatures. If we allowed function domains to be
arbitrary types, in the definition of $(A \to B)^M$ we would only have a
black-box $A^M\,X^M : A^A\,X_0 \to A^A\,X_1 \to \Set$ relation, which is not
known to be given as an equality.

In Chapter \ref{chap:fqiit} we expand on this. As a preliminary summary:
although higher-order functions have relational interpretation, such relations
do not generally compose. What we eventually aim to have is a \emph{category} of
algebras and algebra morphisms, where morphisms do compose. We need a
\emph{directed} model of the theory of signatures, where every signature becomes
a category of algebras. The way to achieve this, is to prohibit higher-order
functions, thereby avoiding the polarity issues that prevent a directed
interpretation for general function types.

\subsection{Displayed Algebras}

At this point we do not yet have specification for induction principles. We use
the term \emph{displayed algebra} to refer to ``dependent'' algebras, where
every displayed algebra component lies over corresponding components in the base
algebra. For the purpose of specifying induction, displayed algebras can be
viewed as bundles of induction motives and methods.

Displayed algebras over some $\gamma : \Alg\,\Gamma$ are equivalent to slices
over $\gamma$ in the category of $\Gamma$-algebras; we show this in Chapter
\ref{chap:fqiit}. A slice $f : \Sub\,\Gamma\,\gamma'\,\gamma$ maps elements of
$\gamma$'s underlying set to elements in the base algebra. Why do we need
displayed algebras, then? The main reason is that if we are to eventually
implement inductive types in a dependently typed language, we need to compute
induction principles exactly, not merely up to isomorphisms.

For more illustration of using some displayed algebras in a type-theoretic
setting, see \cite{displayedcats}. We adapt the term ``displayed algebra'' from
ibid.\ as a generalization of displayed categories (and functors, natural
transformations) to other algebraic structures.

The displayed algebra interpretation is a \emph{logical predicate}
interpretation, defined as follows.
\begin{alignat*}{3}
  & \rlap{$\blank^D : (A : \Ty)\{X\} \to (X \to \Set) \to A^A\,X \to \Set$}\\
  & \iota^D\,       && X^D\,\alpha \defn X^D\,\alpha \\
  & (\iota\to A)^D\,&& X^D\,\alpha \defn (x : X)(x^D : X^D\,x) \to A^D\,X^D\,(\alpha\,x)\\
  & &&\\
  & \rlap{$\blank^D : (\Gamma : \Con)\{X\} \to (X \to \Set) \to \Gamma^A\,X \to \Set$}\\
  & \rlap{$\Gamma^D\,X^D\,\gamma \defn
       \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^D\,X^D\,(\gamma\,x)$}\\
  & &&\\
  & \rlap{$\blank^D : (t : \Tm\,\Gamma\,A)
      \to \Gamma^D\,X^D\,\gamma \to A^D\,X^D\,(t^A\,\gamma)$}\\
  & (\var\,x)^D\,&&\gamma^D \defn \gamma^D\,x\\
  & (\app\,t\,u)^D\,&&\gamma^D \defn t^D\,\gamma^D\,(u^A\,\gamma)\,(u^D\,\gamma^D)\\
  & &&\\
  & \rlap{$\blank^D : (\sigma : \Sub\,\Gamma\,\Delta)
      \to \Gamma^D\,X^D\,\gamma \to \Delta^D\,X^D\,(\sigma^A\,\gamma)$}\\
  & \rlap{$\sigma^D\,\gamma^D\,x \defn (\sigma\,x)^D\,\gamma^D$}
\end{alignat*}
Analogously to before, everything depends on a predicate interpretation $X^D : X
\to \Set$ for $\iota$. For types, a predicate holds for a function if the
function preserves predicates. The interpretation of terms is again a
fundamental lemma, and we again have pointwise definitions for contexts and
substitutions.
\begin{mydefinition}[\textbf{displayed algebras}]
\begin{alignat*}{3}
  & \DispAlg : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set_1\\
  & \DispAlg\,\{\Gamma\}\,(X,\,\gamma) \defn (X^D : X \to \Set) \times \Gamma^D\,X^D\,\gamma
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc}) \equiv$}\\
              & (X^D &&: X \to \Set)\\
      \times\,& (\mi{zero^D} &&: X^D\,\mi{zero})\\
      \times\,& (\mi{suc^D} &&: (n : X) \to X^D\,n \to X^D\,(\mi{suc}\,n))
\end{alignat*}
\end{myexample}

\subsection{Sections}

Sections of displayed algebras are ``dependent'' analogues of algebra morphisms,
where the codomain is displayed over the domain.

\begin{alignat*}{3}
  & \hspace{-6em}\rlap{$\blank^S : (A : \Ty)\{X\,X^D\}(X^S : (x : X) \to X^D\,x) \to (\alpha : A^A\,X) \to A^D\,X^D\,\alpha \to \Set$}\\
  & \hspace{-6em}\iota^S\,&&X^S\,\alpha\,\,\alpha^D \defn X^S\,\alpha = \alpha^D \\
  & \hspace{-6em}(\iota\to A)^S\,&&X^S\,\alpha\,\,\alpha^D \defn
  (x : X) \to A^S\,X^S\,(\alpha\,x)\,(\alpha^D\,(X^S\,x))\\
  & \hspace{-6em}&&\\
  &\hspace{-6em}\rlap{$\Con^S : (\Gamma : \Con)\{X\,X^D\}(X^S : (x : X) \to X^D\,x) \to (\gamma : \Gamma^A\,X) \to \Gamma^D\,X^D\,\gamma \to \Set$}\\
  &\hspace{-6em}\rlap{$\Gamma^S\,X^S\,\gamma_0\,\gamma_1 \defn
    \{A : \Ty\}(x : \Var\,\Gamma\,A) \to A^S\,X^S\,(\gamma_0\,x)\,(\gamma_1\,x)$}\\
  & \hspace{-6em} && \\
  & \hspace{-6em}\rlap{$\blank^S : (t : \Tm\,\Gamma\,A) \to \Gamma^S\,X^S\,\gamma\,\gamma^D \to A^S\,X^S\,(t^A\,\gamma)\,(t^D\,\gamma^D)$}\\
  & \hspace{-6em}(\var\,x)^S    &&\gamma^S \defn \gamma^S\,x \\
  & \hspace{-6em}(\app\,t\,u)^S &&\gamma^S \defn t^S\,\gamma^S\,(u^A\,\gamma)\\
  & \hspace{-6em}&& \\
  & \hspace{-6em}\rlap{$\blank^S : (\sigma : \Sub\,\Gamma\,\Delta) \to \Gamma^S\,X^S\,\gamma\,\gamma^D \to \Delta^S\,X^S\,(\sigma^A\,\gamma)\,(\sigma^A\,\gamma^D)$}\\
  & \hspace{-6em} \rlap{$\sigma^S\, \gamma^S\,x = (\sigma\,x)^S\,\gamma^S$}
\end{alignat*}

\begin{mydefinition}[\textbf{Displayed algebra sections} (``sections'' in short)]
\begin{alignat*}{3}
  & \Section : \{\Gamma : \Con\} \to (\gamma : \Alg\,\Gamma) \to \DispAlg\,\gamma \to \Set\\
  & \Section\,(X,\,\gamma)\,(X^D\,\gamma^D) \defn (X^S : (x : X) \to X^D\,x) \times \Gamma^S\,X^S\,\gamma\,\gamma^D
\end{alignat*}
\end{mydefinition}
\begin{myexample} We have the following computation.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\Section\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})\,(X^D,\,\mi{zero^D},\,\mi{suc^D}) \equiv$}\\
              & (X^S &&: (x : X) \to X^D\,x)\\
      \times\,& (\mi{zero^S} &&: X^S\,\mi{zero} = \mi{zero^D})\\
      \times\,& (\mi{suc^S} &&: (n : X) \to X^S\,(\mi{suc\,n}) = \mi{suc^D}\,n\,(X^S\,n))
\end{alignat*}
\end{myexample}

\begin{mydefinition}[\textbf{Induction}]
We define a predicate which holds if an algebra supports induction.
\begin{alignat*}{3}
  & \Inductive : \{\Gamma : \Con\} \to \Alg\,\Gamma \to \Set_1\\
  & \Inductive\,\{\Gamma\}\,\gamma \defn
     (\gamma^D : \DispAlg\,\gamma) \to \Section\,\gamma\,\gamma^D
\end{alignat*}
\end{mydefinition}

We can observe that $\Inductive\,\{\ms{NatSig}\}\,(X,\,\ms{zero},\,\ms{suc})$
computes exactly to the usual induction principle for natural numbers. The input
$\DispAlg$ is a bundle of the induction motive and the methods, and the output
$\Section$ contains the $X^S$ eliminator function together with its $\beta$
computation rules.

\section{Term Algebras}

In this section we show that if a type theory supports the inductive types comprising
the theory of signatures, it also supports every inductive type which is described
by the signatures.

Note that we specified $\Tm$ and $\Sub$, but did not need either of them when
specifying signatures, or when computing induction principles. That signatures
do not depend on terms, is a property specific to simple signatures; this will
not be the case in Chapter \ref{chap:fqiit} when we move to more general
signatures. However, terms and substitutions are already useful here in the
construction of term algebras.

The idea is that terms in contexts comprise initial algebras. For example,
$\Tm\,\ms{NatSig}\,\iota$ is the set of natural numbers (up to
isomorphism). Informally, this is because the only way to construct terms is by
applying the $\ms{suc}$ variable (given by $\var\,\vz$) finitely many times to
the $\ms{zero}$ variable (given by $\var\,(\vs\,\vz)$).

\begingroup
\allowdisplaybreaks
\begin{mydefinition}[\textbf{Term algebras}]
Fix an $\Omega : \Con$. We abbreviate $\Tm\,\Omega\,\iota$ as $\ms{T}$; this will serve
as the carrier set of the term algebra. We additionally define the following.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^T : (A : \Ty) \to \Tm\,\Omega\,A \to A^A\,\ms{T}$} \\
  & \hspace{-5em}\iota^T\,&&t \defn t \\
  & \hspace{-5em}(\iota\to A)^T\,&&t \defn \lambda\,u.\,A^T\,(\app\,t\,u)\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (\Gamma : \Con) \to \Sub\,\Omega\,\Gamma \to \Gamma^A\,\ms{T}$}\\
  & \hspace{-5em}\rlap{$\Gamma^T\,\nu\,\{A\}\,x \defn A^T\,(\nu\,x)$}\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (t : \Tm\,\Gamma\,A)(\nu : \Sub\,\Omega\,\Gamma) \to A^T\,(t[\nu]) = t^A\,(\Gamma^T\,\nu)$}\\
  & \hspace{-5em}(\var\,x)^T\,   &&\nu    \text{   holds by   } \refl\\
  & \hspace{-5em}(\app\,t\,u)^T\,&&\nu \text {   holds by   } t^T\,\nu \text{   and   } u^T\,\nu\\
  & \hspace{-5em}&& \\
  & \hspace{-5em}\rlap{$\blank^T : (\sigma : \Sub\,\Gamma\,\Delta)(\nu : \Sub\,\Omega\,\Gamma)\{A\}(x : \Var\,\Delta\,A)$}\\
  & \hspace{-3em}\rlap{$\to \Delta^T\,(\sigma \circ \nu)\,x = \sigma^A\,(\Gamma^T\,\nu)\,x$}\\
  & \hspace{-5em}\rlap{$ \sigma^T\,\nu\,x \defn (\sigma\,x)^T\,\nu$}
\end{alignat*}
Now we can define the term algebra for $\Omega$ itself:
\begin{alignat*}{3}
  & \TmAlg_{\Omega} : \Alg\,\Omega \\
  & \TmAlg_{\Omega} \defn \Omega^T\,\Omega\,\id
\end{alignat*}
\end{mydefinition}
\endgroup

In the interpretation for contexts, it is important that $\Omega$ is
fixed, and we do induction on all $\Gamma$ contexts such that there is a
$\Sub\,\Omega\,\Gamma$. It would not work to try to compute term algebras by
direct induction on contexts, because we need to refer to the same $\ms{T}$ set
in the interpretation of every type in a signature.

The interpretation of types embeds terms as $A$-algebras. At the base type
$\iota$, this embedding is simply the identity function, since $\iota^A\,\ms{T}
\equiv \ms{T} \equiv \Tm\,\Omega\,\iota$. At function types we recursively proceed
under a semantic $\lambda$. The interpretation of contexts is pointwise.

The interpretations of terms and substitutions are coherence properties, which
relate the term algebra construction to term evaluation in the $\blank^A$ model.
For terms, if we pick $\nu \equiv \id$, we get $A^T\,t =
t^A\,\TmAlg_{\Omega}$. The left side embeds $t$ in the term model via
$\blank^T$, while the right hand side evaluates $t$ in the term model.

A way to view the term algebra construction, is that we are working in a
\emph{slice model} over the fixed $\Omega$, and every $\nu :
\Sub\,\Omega\,\Gamma$ can be viewed as an internal $\Gamma$-algebra in this
model. The term algebra construction demonstrates that
every such internal algebra yields an external element of $\Gamma^A$. We will
see in Section \ref{sec:fqiit-term-algebras} that we can construct term algebras
from \emph{any} model of a ToS, not just the ToS syntax; but while term algebras
constructed from ToS syntax are themselves initial algebras, in other cases they
may not be initial.

\subsection{Weak Initiality}
\label{sec:simple-weak-initiality}
We show that $\TmAlg_{\Omega}$ supports a recursion principle, i.e.\ it is weakly
initial.

\begin{mydefinition}[\textbf{Recursor construction}]\label{def:simple-recursor} We assume $(X,\,\omega) : \Alg\,\Omega$;
recall that $X : \Set$ and $\omega : \Omega^A\,X$. We define $\ms{R} : \ms{T} \to X$
as $\ms{R}\,t \equiv t^A\,\omega$. We additionally define the following.
\begin{alignat*}{3}
& \hspace{-6em}\rlap{$\blank^R : (A : \Ty)(t : \Tm\,\Omega\,A) \to A^M\,\ms{R}\,(A^T\,t)\,(t^A\,\omega)$}\\
& \hspace{-6em}\iota^R\,&&t \defn (\refl : t^A\,\omega = t^A\,\omega)\\
& \hspace{-6em}(\iota\to A)^R\,&&t \defn \lambda\,u.\,A^R\,(\app\,t\,u)\\
& \hspace{-6em}&& \\
& \hspace{-6em}\rlap{$\blank^R : (\Gamma : \Con)(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)$}\\
& \hspace{-6em}\rlap{$\Gamma^R\,\nu\,x \defn A^R\,(\nu\,x)$}
\end{alignat*}
We define the recursor for $\Omega$ as
\begin{alignat*}{3}
  & \Rec_{\Omega} : (\mi{alg} : \Alg\,\Omega) \to \Mor\,\TmAlg_{\Omega}\,\mi{alg}\\
  & \Rec_{\Omega}\,(X,\,\omega) \defn (\ms{R},\,\Omega^R\,\Omega\,\id)
\end{alignat*}
\end{mydefinition}

In short, the way we get recursion is by evaluating terms in arbitrary
$(X,\,\omega)$ algebras using $\blank^A$. The $\blank^R$ operation for types and
contexts confirms that $\ms{R}$ preserves structure appropriately, so that
$\ms{R}$ indeed yields algebra morphisms.

We skip interpreting terms and substitutions by $\blank^R$. It is necessary to
do so with more general signatures, but not in the current chapter.

\subsection{Induction}

We take the idea of the previous section a bit further. We have seen that
recursion for term algebras is given by evaluation in the ``standard'' model
$\blank^A$. Now, we show that induction for term algebras corresponds to
evaluation in the logical predicate model $\blank^D$.

\begin{mydefinition}[\textbf{Eliminator construction}]\label{def:simple-eliminator-construction}
We assume $(X^D,\,\omega^D) : \DispAlg\,\TmAlg_\Omega$. Recall that $X^D :
\ms{T} \to \Set$ and $\omega^D : \Omega^D\,X^D\,(\Omega^T\,\Omega\,\id)$. Like
before, we first interpret the underlying set:
\begin{alignat*}{3}
  & \ms{E} : (t : \ms{T}) \to X^D\,t \\
  & \ms{E}\,t \defn t^D\,\omega^D
\end{alignat*}
However, this definition is not immediately well-typed, since $t^D\,\omega^D$
has type $X^D\,(t^A\,(\Omega^T\,\Omega\,\id))$, so we have to show that
$t^A\,(\Omega^T\,\Omega\,\id) = t$. This equation says that nothing happens if
we evaluate a term with type $\iota$ in the term model. We get it from the
$\blank^T$ interpretation of terms: $t^T\,\id : t[\id] =
t^A\,(\Omega^T\,\Omega\,\id)$, and we also know that $t[\id] = t$. We interpret types
and contexts as well:
\begin{alignat*}{3}
  & \hspace{-8em}\rlap{$\blank^E : (A : \Ty)(t : \Tm\,\Omega\,A) \to A^S\,\ms{E}\,(t^A\,(\Omega^T\,\Omega\,\id))\,(t^D\,\omega^D)$}\\
  & \hspace{-8em}\iota^E\,&&t : (t^A\,(\Omega^T\,\Omega\,\id))^D\,\omega^D = t^D\,\omega^D\\
  & \hspace{-8em}(\iota\to A)^E\,&&t \defn \lambda\,u.\, A^E\,(\app\,t\,u)\\
  & \hspace{-8em}&& \\
  & \hspace{-8em}\rlap{$\blank^E : (\Gamma : \Con)(\nu : \Sub\,\Omega\,\Gamma) \to \Gamma^S\,\ms{E}\,(\nu^A\,(\Omega^T\,\Omega\,\id))\, (\nu^D\,\omega^D)$}\\
  & \hspace{-8em}\rlap{$\Gamma^E\,\nu\,x \defn A^E\,(\nu\,x)$}
\end{alignat*}
In $\iota^E$ we use the same equation as in the definition of $\ms{E}$. In
$(\iota\to A)^E$ the definition is well-typed because of the same equation, but
instantiated for the abstracted $u$ term this time. All of this amounts to some
additional path induction and transport fiddling in the (intensional) Agda
formalization. We get induction for $\Omega$ as below.
\begin{alignat*}{3}
  &\Ind_{\Omega} : (\mi{alg} : \DispAlg\,\TmAlg_\Omega) \to \Section\,\TmAlg_\Omega\,\mi{alg}\\
  &\Ind_{\Omega}\,(X^D,\,\omega^D) \defn (E,\, \Omega^E\,\Omega\,\id)
\end{alignat*}
\end{mydefinition}

\section{Discussion}

\subsection{Comparison to F-algebras}

A well-known alternative way for treating inductive types is to use certain
cocontinuous endofunctors as a more semantic notion of signatures.

For example, single-sorted inductive types can be presented as endofunctors
which preserve colimits of some ordinal-indexed chains. For instance, if we have
an $\kappa$-cocontinuous $F : \mbb{C} \to \mbb{C}$, then algebras are given as
$(X : |\mbb{C}|) \times (\mbb{C}(F\,X,\,X))$, morphisms as commuting squares,
and Adámek's theorem \cite{adamek} establishes the existence of initial
algebras.

An advantage of this approach is that we can describe different classes of
signatures by choosing different $\mbb{C}$ categories:
\begin{itemize}
  \item If $\mbb{C}$ is $\mbf{Set}$, we get simple inductive types.
  \item If $\mbb{C}$ is $\mbf{Set}^I$ for some set $I$, we get indexed inductive types.
  \item If $\mbb{C}$ is $\mbf{Set}/I$, we get inductive-recursive types.
\end{itemize}

Another advantage of $F$-algebras is that signatures are a fairly semantic
notion: they make sense even if we have no syntactic presentation at hand. That
said, often we do need syntactic signatures, for use in proof assistants, or
just to have a convenient notation for a class of cocontinuous functors.

An elegant way of carving out a large class of such functors is to
consider polynomials as signatures. For example, when working in \textbf{Set}, a
signature is an element of $(S : \Set) \times (P : S \to \Set)$, and $(S,\,P)$
is interpreted as a functor as $X \mapsto (s : S) \times (P\,s \to X)$. The
initial algebra is the W-type specified by $S$ shapes and $P$ positions. This
yields infinitary inductive types as well.

However, it is not known how to get \emph{inductive-inductive} signatures by
picking the right $\mbb{C}$ category and a functor. In an inductive-inductive
signature, there may be multiple sorts, which can be indexed over previously
declared sorts. For example, in the signature for categories we have $\Obj :
\Set$ and $\Mor : \Obj \to \Obj \to \Set$, indexed twice over $\Obj$. Some
extensions are required to the idea of $F$-algebras:
\begin{itemize}
\item
  For inductive-inductive definitions with two sorts, Forsberg gives a
  specification with two functors, and a considerably more complex notion of
  algebras, involving dialgebras \cite{forsberg-phd}.
\item
  For an arbitrary number of sorts, Altenkirch et
  al.\ \cite{altenkirch18qiit} use a ``list'' of functors, specified mutually
  with categories of algebras: each functor has as domain the semantic category
  of all previous sorts.
\end{itemize}

The functors-as-signatures approach gets significantly less convenient as we
consider more general specifications. The approach of this thesis is the skip the
middle ground between syntactic signatures and semantic categories of algebras:
we treat syntactic signatures as a key component, and give direct semantic
interpretation for them. Although we lose the semantic nature of $F$-algebras,
our approach scales extremely well, all the way up to infinitary
quotient-inductive-inductive types in Chapter \ref{chap:iqiit}, and to some
extent to higher inductive-inductive types as well in Chapter \ref{chap:hiit}.

If we look back at $\blank^A : \Con \to \Set \to \Set$, we may note that
$\Gamma^A$ yields a functor, in fact the same functor (up to isomorphism) that
we would get from an $F$-algebra presentation. However, this is a coincidence in
the single-sorted case. With the $F$-algebra presentation, we can view $(X :
|\mbb{C}|) \times (\mbb{C}(F\,X,\,X))$ as specifying the category of algebras as
the total category of a displayed category (by viewing the $\Sigma$-type here as
taking total categories; a $\Sigma$ in $\mbf{Cat}$). In our approach, we aim to
get the displayed categories directly, without talking about functors.

\subsection{Generic Programming}
\label{sec:generic-programming}

Let's consider now our signatures and term algebras in the context of generic
programming. This is largely future work, and we don't elaborate it much. But we
can draw some preliminary conclusions and make some comparisons.

If a language can formalize inductive signatures and their semantics, that can
be viewed as an implementation of generic programming over the described types.
Compared to a purely mathematical motivation for this formalization, the
requirements for practical generic programming are a bit more stringent.
\begin{itemize}
  \item \emph{Encoding overhead}: there should be an acceptable overhead in
    program size and performance when using generic representations.  Size
    blowup can be an issue when writing proofs as well, when types and
    expressions become too large to mentally parse.
  \item \emph{Strictness properties}: generic representations should compute as
    much as possible, ideally in exactly the same way as their non-generic
    counterparts.
\end{itemize}

\paragraph{Fixpoints of functors.}There is a sizable literature
of using fixpoints of functors in generic programming, mainly in Haskell
\cite{alacarte,compdata,multirec} and Agda \cite{loh11generic,allais20type}. We
give a minimal example below for an Agda-like implementation.

We have an inductive syntax for some strictly positive functors, covering essentially the
same signatures as $\Con$.
\begin{alignat*}{3}
  & \ms{Sig}                &&: \Set \\
  & \ms{Id}                 &&: \ms{Sig} \\
  & \ms{K\top}              &&: \ms{Sig} \\
  & \blank\!\otimes\!\blank &&: \ms{Sig} \to \ms{Sig} \to \ms{Sig} \\
  & \blank\!\oplus\!\blank  &&: \ms{Sig} \to \ms{Sig} \to \ms{Sig}
\end{alignat*}

$\ms{Id}$ codes the identity functor, and $\ms{K\top}$ codes the functor which
is constantly $\top$. $\blank\!\otimes\!\blank$ and $\blank\!\oplus\!\blank$ are
pointwise products and coproducts respectively. So we have the evident
interpretation functions:
\begin{alignat*}{3}
  & \llbracket\blank\rrbracket &&: \ms{Sig} \to \Set \to \Set\\
  & \ms{map} &&: (F : \ms{Sig}) \to (X_0 \to X_1) \to \llbracket F \rrbracket\,X_0 \to \llbracket F \rrbracket\,X_1
\end{alignat*}
In Haskell and Agda, the easiest way to get initial algebras is to directly define
the inductive fixpoint for each assumed $F : \ms{Sig}$:
\begin{alignat*}{3}
  & \ms{Fix_F} &&: \Set \\
  & \ms{con_F} &&: \llbracket F \rrbracket\,\ms{Fix_F} \to \ms{Fix_F}
\end{alignat*}
In Haskell, this definition is valid for arbitrary \emph{semantic} $F$ functor,
because there is no termination checking or positivity checking. In Agda, the
above definition is valid because the positivity checker is willing to look
inside the definition of $\llbracket\blank\rrbracket$. However, Coq and Lean
reject this definition. Next we establish weak initiality, by defining the
recursor:
\begin{alignat*}{3}
  & \ms{rec} : (\llbracket F \rrbracket\,X \to X) \to \ms{Fix_F} \to X \\
  & \ms{rec}\,f\,(\ms{con}\,x) \defn f\,(\ms{map}\,(\ms{rec}\,f)\,x)
\end{alignat*}
This is again fine in Haskell, but it unfortunately does not pass Agda's
termination checker. The most conservative solution is to inline the recursive
call into $\ms{map}$, so that the definition becomes transparent to termination
checking.
\begin{alignat*}{3}
  &\ms{rec} : (\llbracket F \rrbracket\,X \to X) \to \ms{Fix_F} \to X\\
  &\ms{rec}\,f\,(\ms{con}\,x) \defn f\,(\ms{maprec}\,f\,x)
\end{alignat*}
\begin{alignat*}{3}
  & \rlap{$\ms{maprec} : \{G\} \to (\llbracket F \rrbracket\,X \to X) \to \llbracket G \rrbracket\,\ms{Fix_F} \to \llbracket G \rrbracket\,X$}\\
  & \ms{maprec}\,\{\Id\}\,&&f\,x &&\defn \ms{rec}\,f\,x\\
  & \ms{maprec}\,\{\ms{K\top}\}\,&&f\,x &&\defn x\\
  & \ms{maprec}\,\{G \otimes H\}\,&&f\,(x,\,y) &&\defn  (\ms{maprec}\,f\,x,\,\ms{maprec}\,f\,y)\\
  & \ms{maprec}\,\{G \oplus H\}\,&&f\,(\ms{inj_1}\,x) &&\defn \ms{maprec}\,f\,x\\
  & \ms{maprec}\,\{G \oplus H\}\,&&f\,(\ms{inj_2}\,x) &&\defn \ms{maprec}\,f\,x
\end{alignat*}

Alternatively, we might use \emph{sized types} \cite{abel17normalization}, as
in \cite{allais20type}. The drawback is dependence on an additional
language feature which is only supported in Agda, and which has had several
soundness issues since its introduction \cite{TODO}.

There is yet another possible approach: defining initial algebras as sequential
colimits, using Adámek's theorem. This approach was taken by Ahrens, Matthes and
Mörtberg in \cite{ahrens19from}. However, the encoding overhead is excessive,
and it is practically unusable for generic programming. Another drawback is that
defining colimits requires quotient types, which are often not available
natively.

\paragraph{W-types.} Given a polynomial $(S,\,P) : (S : \Set) \times (S \to \Set)$,
the corresponding W-type is inductively specified as below:
\begin{alignat*}{3}
  & \ms{W}_{S,\,P} &&: \Set \\
  & \ms{sup} &&: (s : S) \to (P\,s \to \ms{W}_{S,\,P}) \to \ms{W}_{S,\,P}
\end{alignat*}
If we assume $\top$, $\bot$, $\Bool$, $\Pi$, $\Sigma$, $\ms{W}$-types, universes
and an intensional identity type, a large class of inductive types can be
derived, including infinitary and finitary indexed inductive families; this
was shown by Hugunin \cite{whynotw}. The encoding also yields definitional
$\beta$-rules for recursion and elimination. However, there is also significant
encoding overhead here.
\begin{itemize}
  \item
    First, there is a translation from more convenient signatures to $(S,\,P)$ polynomials.
  \item Then, we take the $\ms{W}_{S\,P}$ type, but we need to additionally
    restrict it to the \emph{canonical} elements by a predicate, as in $(x :
    \ms{W}_{S\,P}) \times \ms{canonical}\,x$. This is required because the only
    way to represent inductive branching is by functions, but functions
    sometimes contain too many elements up to definitional equality. For
    example, $\bot \to A$ has infinitely many definitonally distinct
    inhabitants.
\end{itemize}
There is also a performance overhead imposed by the mandatory higher-order
constructors. W-types are a great way to have a small basis in a formal setting,
both in intensional and extensional type theories, but they are a bit too heavy
for practical purposes.

\paragraph{Term algebras.}
The main advantage of the term algebras described in this chapter is that they
can be defined using plain inductive families, which are available in every
major dependently typed language. Even in GHC Haskell, the support for
generalized ADTs is sufficient for implementing term algebras. In contrast, as
we have seen, the direct inductive definition of fixpoints is only possible in
Agda, while the colimit definition requires quotients and is rather
heavyweight. Even in Agda, the drawback of the direct fixpoint definition is
that many generic operations only pass termination checking after manual
inlining. With term algebras, generic operations can be defined by induction on
$\Tm\,\Gamma\,A$ in an obviously terminating way.

For practical usage it makes sense to slightly modify terms. We switch to a
\emph{spine neutral} definition. We mutually inductively define $\ms{Spine}$ and
$\Tm$:
\begin{alignat*}{3}
  & \ms{Spine} &&: (\Gamma : \Con) \to \Ty \to \Ty \to \Set \\
  & \epsilon &&: \{A\} \to \ms{Spine}\,\Gamma\,A\,A\\
  & \blank\!,\!\blank &&: \{B\,C\} \to \Tm\,\Gamma\,\iota \to \ms{Spine}\,\Gamma\,B\,C \to \ms{Spine}\,\Gamma\,(\iota\to B)\,C\\
  & \Tm  &&: \Con \to \Ty \to \Set \\
  & \blank\$\blank &&: \{A\,B\} \to \Var\,\Gamma\,A \to \ms{Spine}\,\Gamma\,A\,B \to \Tm\,\Gamma\,B
\end{alignat*}
With this representation, a term is always a variable applied to a list of
arguments. This can be useful, because pattern matching implementations in
metalanguages (e.g.\ Agda or Idris) are more likely to know about which
constructors are possible in patterns. Using this, we give here an ad-hoc
definition of natural numbers in pseudo-Agda.
\begin{alignat*}{3}
  &\Nat : \Set && \ms{zero} &&\defn \vz\,\$\,\epsilon\\
  &\Nat \defn \Tm\,(\emptycon\ext \iota\to \iota \ext \iota)\,\iota\hspace{2em} && \ms{suc}\,n &&\defn \vs\,\vz\,\$\,(n,\,\epsilon)
\end{alignat*}
\begin{alignat*}{3}
  &\hspace{-6.5em}\rlap{$\ms{NatElim} : (P : \Nat \to \Set) \to P\,\ms{zero}\to ((n : \Nat) \to P\,n \to P\,(\ms{suc}\,n))$}\\
  &\hspace{-6.5em}\rlap{$\hspace{4em}\to (n : \Nat) \to P\,n$}\\
  &\hspace{-6.5em}\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,(\vz\,\$\,\epsilon) &&\defn \ms{pz}\\
  &\hspace{-6.5em}\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,(\vs\,\vz\,\$\,(n,\,\epsilon)) &&\defn
    \ms{ps}\,n\,(\ms{NatElim}\,P\,\ms{pz}\,\ms{ps}\,n)
\end{alignat*}
The actual Agda definition can be found in the supplementary formalization, and
it is pretty much the same as above. We recover the exact same behavior with
respect to pattern matching as with native inductive definitions.

$\Rec_\Omega$ and $\Ind_\Omega$ can be adapted to spine neutral terms with minor
adjustments. But what about the $\beta$-rules which they produce as part of
their output, are they definitional (i.e.\ proven by $\refl$)? In this chapter
we do not have a rigorous way of reasoning about definitional equalities; in the
next chapter we develop such reasoning and show that $\Rec_\Omega$ enjoys
definitional $\beta$-rules (with or without the spine neutral
definition).

However, $\Ind_\Omega$ only supports propositional $\beta$-rules. The issue is
the extra transporting in the definition of $\ms{E} : (t : \Tm\,\Omega\,\iota)
\to X^D\,t$: transports don't strictly commute with constructors. This appears
to be a point of advantage for the direct fixpoint definition in Agda, as it
allows generic elimination with strict computation rules \cite{TODO}.

The term algebra presentation can be easily extended to indexed families. In
that case, signatures and terms are still definable with basic inductive
families, without requiring quotients or complicated encodings; see Kaposi and
von Raumer \cite{mutualinductive}.

A related existing work is \emph{sum-of-products} generics by De Vries and Löh
\cite{sop}. There, signatures for functors are in a normal form: we cannot
freely take products and coproducts, instead a signature looks very much like a
$\Con$ in this chapter (except in an indexed form). The authors observe that
several generic programming patterns are easier to express with normalized
signatures. However, they still use explicit fixpoints as the way to get initial
algebras.

\chapter{Semantics in Two-Level Type Theory}
\label{chap:2ltt}

In this chapter we describe how two-level type theory is used as a metatheoretic
setting in the rest of this thesis. First, we provide motivation and
overview. Second, we describe models of type theories in general, and models of
two-level type theories as extensions. Third, we describe presheaf models of
two-level type theories. Finally, we generalize the semantics and the term
algebra construction from Chapter \ref{chap:simple-inductive-signatures} in
two-level type theory, as a way to illustrate the applications.

\section{Motivation}
\label{sec:2ltt-motivation}
We note two shortcomings of the semantics presented in the
previous chapter.

First, the semantics that we provided was not as general as it could be. We
used the internal $\Set$ universe to specify algebras, but algebras make sense
in many different categories. A crude way to generalize semantics is to simply
say that our formalization, which was carried out in the syntax (i.e.\ initial
model) of some intensional type theory, can be interpreted in any model of the
type theory. However, this is wasteful: for simple inductive signatures, it is
enough to assume a category with finite products as semantic setting. We don't
need all the extra baggage that comes with a model of a type theory.

Second, we were not able to reason about definitional equalities, only
propositional ones. We have a formalization of signatures and semantics in
intensional Agda, where the two notions differ\footnote{As opposed to in
extensional type theory, where they're the same.}, but only propositional
equality is subject to internal reasoning. For instance, we would like to show
that term algebras support recursion with strict $\beta$-rules, and for this we
need to reason about strict equality.

\begin{notation}
We use $\emptycon$ for the terminal object in a $\mbb{C}$ category, with
$\epsilon : \mbb{C}(A,\,\emptycon)$ for the unique morphism. For products, we
use $\blank\!\otimes\!\blank$ with $(\blank\!,\!\blank) : \mbb{C}(A,\,B) \to
\mbb{C}(A,\,C) \to \mbb{C}(A,\,B\otimes C)$ and $\p$ and $\q$ for
first and second projections respectively.
\end{notation}

\begin{myexample}
Assuming $\mbbC$ has finite products, natural number algebras and binary tree
algebras are specified as follows.
\begin{alignat*}{3}
  &\Alg_{\ms{NatSig}} &&\defn (X : |\mbbC|) \times \mbbC(\emptycon,\,X) \times \mbbC(X,\,X)\\
  &\Alg_{\ms{TreeSig}}&& \defn (X : |\mbbC|) \times \mbbC(\emptycon,\,X) \times \mbbC(X \otimes X,\,X)
\end{alignat*}
\end{myexample}
Here, $\Alg_{\ms{NatSig}}$ and $\Alg_{\ms{TreeSig}}$ are both sets in some
metatheory, and the $\times$ in the definitions refer to the metatheoretic
$\Sigma$. Algebras can be viewed as diagrams which preserve finite products, and
algebra morphisms are natural transformations.

How should we adjust $\Alg$ to compute algebras in $\mbbC$, and $\Mor$ to
compute their morphisms? While it is possible to do this in a direct fashion,
working directly with objects and morphisms of $\mbbC$ is rather unwieldy. $\mbbC$ is
missing many convenience features of type theories.
\begin{itemize}
\item There are no variables or binders. We are forced to work in a point-free
  style or chase diagrams; both become difficult to write and read after a
  certain point of complexity.
\item
  There no functions, universes or inductive types.
\item
  Substitution (with weakening as a special case) has to be handled explicitly
  and manually. Substitutions are certain morphisms, while ``terms'' are also
  morphisms, and we have to use composition to substitute terms. In contrast, if
  we are working internally in a type theory, terms and substitutions are
  distinct, and we only have to explicitly deal with terms, and substitutions
  are automated and implicit.
\end{itemize}

The above overlaps with motivations for working in \emph{internal languages}
\cite{internallogic} of structured categories: they aid calculation and compact
formalization by hiding bureaucratic structural details.

A finite product category $\mbbC$ does not have much of an internal language, it
is too bare-bones. But we can work instead in the internal language of
$\hat\mbbC$, the category of presheaves over $\mbbC$. This allows faithful
reasoning about $\mbbC$, while also including all convenience features of
extensional type theory.

\emph{Two-level type theories} \cite{twolevel}, or 2LTT in short, are type
theories such that they have ``standard'' interpretations in presheaf
categories. A 2LTT has an inner layer, where types and terms arise by embedding
$\mbbC$ in $\hat{\mbbC}$, and an outer layer, where constructions are inherited
from $\hat{\mbbC}$. The exact details of the syntax may vary depending on what
structures $\mbbC$ supports, and which type formers we assume in the outer
layer. Although it is possible to add assumptions to a 2LTT which preclude
standard presheaf semantics \cite[Section 2.4.]{twolevel}, we stick to basic
2LTT in this thesis. By using 2LTT, we are able to use a type-theoretic syntax
in the rest of the thesis which differs only modestly from the style of
definitions that we have seen so far.

From a programming perspective, basic 2LTT provides a convenient syntax for
writing metaprograms. This can be viewed as \emph{two-stage compilation}: if we
have a 2LTT program with an inner type, we can run it, and it returns another
program, which lives purely in the inner theory.

\section{Models of Type Theories}
\label{sec:models-of-tts}

Before elaborating on 2LTT-specific features, we review models of type theories
in general. Variants of 2LTT will be obtained by adding extra features on the
top of more conventional TTs.

It is also worth to take a more general look at models at this point, because
the notions presented in this subsection (categories with families, type
formers) will be reused several times in this thesis, when specifying theories
of signatures.

\subsection{The Algebraic View}

We take an algebraic view \cite{TODO} of models and syntaxes of type theories throughout
this thesis. Models of type theories are algebraic structures: they are
categories with certain extra structure. The syntax of a type theory is
understood to be its initial model. In initial models, the underlying category
is the category of typing contexts and parallel substitutions, while the extra
structure corresponds to type and term formers, and equations quotient the
syntax by definitional equality.

Type theories can be described with quotient inductive-inductive (QII)
signatures, and their initial models are quotient inductive-inductive types
(QIITs). Hence, 2LTT is also a QII theory. We will first talk about QIITs in
Chapter \ref{chap:fqiit}. Until then, we shall make do with an informal
understanding of categorical semantics for type theories, without using anything
in particular from the metatheory of QIITs. There is some annoying circularity
here, that we talk about QIITs in this thesis, but we employ QIITs when talking
about them. However, this is only an annoyance in exposition and not a
fundamental issue: Chapter \ref{chap:levitation} describes how to eliminate
circularity by a form of bootstrapping.

The algebraic view lets us dispense with all kinds of ``raw'' syntactic objects.
We only ever talk about well-typed and well-formed objects, moreover, every
construction must respect definitional equalities. For terms in the algebraic
syntax, definitional equality coincides with metatheoretic equality. This
mirrors equality of morphisms in 1-category theory, where we usually reuse
metatheoretic equality.

In the following we specify notions of models for type theories. We split this
in two parts: categories with families and type formers.

\subsection{Categories With Families}

\begin{mydefinition}
A \textbf{category with family} (cwf) \cite{Dybjer96internaltype} is a way to
specify the basic structural rules for contexts, substitutions, types and
terms. It yields a dependently typed explicit substitution calculus \cite{TODO}.
A cwf consists of the following.
\begin{itemize}
\item
  A category with a terminal object. We denote the set of objects as $\Con :
  \Set$ and use capital Greek letters starting from $\Gamma$ to refer to
  objects. The set of morphisms is $\Sub : \Con \to \Con \to \Set$, and we use
  $\sigma$, $\delta$ and so on to refer to morphisms. We write $\id$ for the
  identity morphism and $\blank\circ\blank$ for composition. The terminal
  object is $\emptycon$ with unique morphism $\epsilon :
  \Sub\,\Gamma\,\emptycon$. In initial models (that is, syntaxes) of type
  theories, objects correspond to typing contexts, morphisms to parallel
  substitutions and the terminal object to the empty context; this informs the
  naming scheme.
\item A \emph{family structure}, containing $\Ty : \Con \to \Set$ and $\Tm :
  (\Gamma : \Con) \to \Ty\,\Gamma \to \Set$. We use $A$, $B$, $C$ to refer to
  types and $t$, $u$, $v$ to refer to terms. $\Ty$ is a presheaf over the
  category of contexts and $\Tm$ is a displayed presheaf over $\Ty$. This means
  that types and terms can be substituted:
  \begin{alignat*}{3}
    &\blank[\blank] : \Ty\,\Delta \to \Sub\,\Gamma\,\Delta \to \Ty\,\Gamma\\
    &\blank[\blank] : \Tm\,\Delta\,A \to (\sigma : \Sub\,\Gamma\,\Delta) \to \Tm\,\Gamma\,(A[\sigma])
  \end{alignat*}
  Substitution is functorial: we have $A[\id] = A$ and
  $A[\sigma\circ\delta] = A[\sigma][\delta]$, and likewise for terms.

  A family structure is additionally equipped with \emph{context comprehension}
  which consists of a context extension operation $\blank\ext\blank : (\Gamma :
  \Con) \to \Ty\,\Gamma \to \Con$ together with an isomorphism
  $\Sub\,\Gamma\,(\Delta\ext A) \simeq ((\sigma : \Sub\,\Gamma\,\Delta) \times
  \Tm\,\Gamma\,(A[\sigma]))$ which is natural in $\Gamma$.
\end{itemize}
\end{mydefinition}

The following notions are derivable from the comprehension structure:
\begin{itemize}
\item
  By going right-to-left along the isomorphism, we recover \emph{substitution
  extension} $\blank,\blank : (\sigma : \Sub\,\Gamma\,\Delta) \to
  \Tm\,\Gamma\,(A[\sigma]) \to \Sub\,\Gamma\,(\Delta\ext A)$. This means that
  starting from $\epsilon$ or the identity substitution $\id$, we can iterate
  $\blank,\blank$ to build substitutions as lists of terms.
\item
  By going left-to-right, and starting from $\id : \Sub\,(\Gamma\ext
  A)\,(\Gamma\ext A)$, we recover the \emph{weakening substitution} $\p :
  \Sub\,(\Gamma\ext A)\,\Gamma$ and the \emph{zero variable} $\q :
  \Tm\,(\Gamma\ext A)\,(A[\p])$.
\item
  By weakening $\q$, we recover a notion of variables as De Bruijn indices. In
  general, the $n$-th De Bruijn index is defined as $\q[\p^{n}]$, where $\p^{n}$
  denotes $n$-fold composition.
\end{itemize}

Comprehension can be characterized either by taking $\blank,\blank$, $\p$ and
$\q$ as primitive, or the natural isomorphism. The two are equivalent, and we
may switch between them, depending on which is more convenient.

There are other ways for presenting the basic categorical structure of models,
which are nonetheless equivalent to cwfs, including natural models
\cite{awodey18natural} and categories with attributes \cite{cartmellthesis}. We
use the cwf presentation for its immediately algebraic character and closeness
to conventional explicit substitution syntax.

\begin{notation}As De Bruijn indices are hard to read, we will mostly use
nameful notation for binders. For example, assuming $\Nat : \{\Gamma : \Con\}
\to \Ty\,\Gamma$ and $\Id : \{\Gamma : \Con\}(A : \Ty\,\Gamma) \to
\Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma$, we may write $\emptycon \ext
n : \Nat \ext p : \Id\,\Nat\,n\,n$ for a typing context, instead of using
numbered variables or cwf combinators as in $\emptycon \ext \Nat \ext
\Id\,\Nat\,\q\,\q$.
\end{notation}

\begin{notation}
In the following, we will denote family structures by ($\Ty$,$\Tm$) pairs and overload context
extension $\blank\ext\blank$ for different families.
\end{notation}

\begin{mydefinition} The following derivable operations are commonly used.
\label{def:cwfops}
  \begin{itemize}
    \item \emph{Single substitution} can be derived from parallel substitution
      as follows. Assume $t : \Tm\,(\Gamma\ext A)\,B$, and $u :
      \Tm\,\Gamma\,A$. $t$ is a term which may depend on the last variable in
      the context, which has $A$ type. We can substitute that variable with the
      $u$ term as $t[\id,\,u] : \Tm\,\Gamma\,(\A[\id,\,u])$. Note that term
      substitution causes the type to be substituted as well. $(\id,\,u) :
      \Sub\,\Gamma\,(\Gamma\ext A)$ is well-typed because $u : \Tm\,\Gamma\,A$
      hence also $u : \Tm\,\Gamma\,(A[\id])$.

    \item We can \emph{lift substitutions} over binders as follows. Assuming
      $\sigma : \Sub\,\Gamma\,\Delta$ and $A : \Ty\,\Delta$, we construct a
      lifting of $\sigma$ which maps an additional $A$-variable to itself:
      $(\sigma\circ\p,\,\q) : \Sub\,(\Gamma\ext A[\sigma])\,(\Delta \ext A)$.
      Let us see why this is well-typed. We have $\p : \Sub\,(\Gamma\ext
      A[\sigma])\,\Gamma$ and $\sigma : \Sub\,\Gamma\,\Delta$, so $\sigma \circ
      \p : \Sub\,(\Gamma\ext A[\sigma])\,\Delta$. Also, $\q : \Tm\,(\Gamma\ext
      A[\sigma])\,(A[\sigma][\p])$, hence $\q : \Tm\,(\Gamma\ext
      A[\sigma])\,(A[\sigma \circ \p])$, thus $(\sigma\circ \p,\,\q)$
      typechecks.
  \end{itemize}
\end{mydefinition}

\begin{notation}

As a nameful notation for substitutions, we may write $t[x \mapsto u]$, for
a single substitution, or $t[x \mapsto u_1, y \mapsto u_2]$ and so on.

In nameful notation we leave all weakening implicit, including substitution
lifting. Formally, if we have $t : \Tm\,\Gamma\,A$, we can only mention $t$ in
$\Gamma$. If we need to mention it in $\Gamma \ext B$, we need to use $t[\p]$
instead. In the nameful notation, $t : \Tm\,(\Gamma\ext x : B)\,A$ may be
used.\footnote{Moreover, when working in the internal syntax of a theory, we
just write Agda-like type-theoretic notation, without noting contexts and
substitutions in any way.}
\end{notation}

\subsection{Type formers}
A family structure in a cwf may be closed under certain type formers, such as
functions, $\Sigma$-types, universes or inductive types. We give some examples
here for their specification. First, we look at common negative type formers,
which can be specified using isomorphisms. Then, we consider positive type
formers, and finally universes.

\subsubsection{Negative types}

\begin{mydefinition}
A $(\Ty,\,\Tm)$ family supports \textbf{$\Pi$-types} if it supports the following.
\begin{alignat*}{3}
  &\Pi           &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  &\ms{\Pi[]}    &&: (\Pi\,A\,B)[\sigma] = \Pi\,(A[\sigma])\,(B[\sigma\circ\p,\,\q])\\
  &\app          &&: \Tm\,\Gamma\,(\Pi\,A\,B) \to \Tm\,(\Gamma \ext A)\,B\\
  &\lam          &&: \Tm\,(\Gamma \ext A)\,B \to \Tm\,\Gamma\,(\Pi\,A\,B)\\
  &\Pi\beta      &&: \app\,(\lam\,t) = t\\
  &\Pi\eta       &&: \lam\,(\app\,t) = t\\
  &\lam[]        &&: (\lam\,t)[\sigma] = \lam\,(t[\sigma\circ\p,\,\q])
\end{alignat*}
Here, $\Pi$ is the type formation rule. $\ms{\Pi[]}$ is the type substitution
rule, expressing that substituting $\Pi$ proceeds structurally on constituent
types.  Note $B[\sigma\circ\p,\,\q]$, where we lift $\sigma$ over the additional
binder.

The rest of the rules specify a natural isomorphism $\Tm\,\Gamma\,(\Pi\,A\,B)
\simeq \Tm\,(\Gamma \ext A)\,B$. We only need a substitution rule (i.e.\ a
naturality rule) for one direction of the isomorphism, since the naturality of
the other map is derivable.

This way of specifying $\Pi$-types is very convenient if we have explicit
substitutions. The usual ``pointful'' specification is equivalent to this. For
example, we have the following derivation of pointful application:
\begin{alignat*}{3}
  &\app' : \Tm\,\Gamma\,(\Pi\,A\,B) \to (u : \Tm\,\Gamma\,A) \to \Tm\,\Gamma\,(B[\id,\,u])\\
  &\app'\,t\,u \defn (\app\,t)[\id,\,u]
\end{alignat*}

\end{mydefinition}

\textbf{Remark on naturality.} The above specification for $\Pi$ can be written
more compactly if we assume that everything is natural with respect to
substitution.
\begin{alignat*}{3}
  &\Pi            &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  & (\app,\,\lam) &&: \Tm\,\Gamma\,(\Pi\,A\,B) \simeq \Tm\,(\Gamma \ext A)\,B
\end{alignat*}
This is a reasonable assumption; in the rest of the thesis we only ever define
structures on cwfs which are natural in this way.

\begin{notation} From now on, when specifying type formers in family structures,
we assume that everything is natural, and thus omit substitution equations.
\end{notation}

There are ways to make this idea more precise, and take it a step further by
working in languages where only natural constructions are possible. The term
\emph{higher-order abstract syntax} (HOAS) is sometimes used for this style. It lets us
also omit contexts, so we would only need to write
\begin{alignat*}{3}
  &\Pi            &&: (A : \Ty) \to (\Tm\,A \to \Ty) \to \Ty\\
  & (\app,\,\lam) &&: \Tm\,(\Pi\,A\,B) \simeq ((a : \Tm\,A) \to \Tm\,(B\,a))
\end{alignat*}
Recently several promising works emerged in this area \cite{TODO}. Although this
technology is likely to be the preferred future direction in the metatheory of
type theories, this thesis does not make use of it. The field is rather fresh,
with several different approaches and limited amount of pedagogical exposition,
and the new techniques would also raise the level of abstraction in this thesis,
all contributing to making it less accessible. One more reason, and perhaps the
most important one, for skipping higher-order abstract syntax, is that this
author has not yet acquired the proficiency to comfortably use the new
techniques.

\begin{mydefinition}
\label{def:constant-families}
A family structure supports \textbf{constant families} if we have the following.
\begin{alignat*}{3}
  & \K &&: \Con \to \{\Gamma : \Con \} \to \Ty\,\Gamma \\
  & (\appK,\,\lamK) &&: \Tm\,\Gamma\,(\K\,\Delta) \simeq \Sub\,\Gamma\,\Delta
\end{alignat*}
Constant families express that every context can be viewed as a non-dependent
type in any context. Having constant families is equivalent to the
\emph{democracy} property for a cwf
\cite{clairambault2014biequivalence,forsberg-phd}.  Constant families are
convenient when building models, because they let us model non-dependent types
as semantic contexts, which are often simpler structures than semantic types.
From a programming perspective, constant families specify closed record types,
where $\K\,\Delta$ has $\Delta$-many fields.

If we have equalities of sets for the specification,
i.e.\ $\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$, we have \textbf{strict
  constant families}.

\end{mydefinition}

\begin{mydefinition}
A family structure supports \textbf{$\Sigma$-types} if we have
\begin{alignat*}{3}
  & \Sigma  &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\
  & (\proj,\,(\blank,\blank)) &&: \Tm\,\Gamma\,(\Sigma\,A\,B) \simeq ((t : \Tm\,\Gamma\,A) \times \Tm\,\Gamma\,(B[\id,\,t]))
\end{alignat*}
We use the shorter specification above, where everything is assumed to be
natural. We may write $\proj_1$ and $\proj_2$ for composing the metatheoretic
first and second projections with $\proj$.
\end{mydefinition}

\begin{mydefinition}
A family structure supports the \textbf{unit type} if we have $\top : \Ty\,\Gamma$ such
that $\Tm\,\Gamma\,\top \simeq \top$, where the $\top$ on the right is the
metatheoretic unit type, and we overload $\top$ for the internal unit type.
From this, we get the internal $\tt : \Tm\,\Gamma\,\top$, which is
definitionally unique.
\end{mydefinition}

\begin{mydefinition}
A family structure supports \textbf{extensional identity} types if there is $\Id
: \Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma$ such that
$(\reflect,\,\refl) : \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t = u)$.
\end{mydefinition}

It is also possible to give a positive definition for identity types, in which
case we get intensional identity. Extensional identity corresponds to a
categorical equalizer of terms (a limit), while the Martin-Löf-style intensional
identity is characterized as the initial reflexive relation on a type (a
colimit).

This choice between negative and positive specification generally exists for
type formers with a single term construction rule. For example, $\Sigma$ can be
defined as a positive type, with an elimination rule that behaves like pattern
matching. Positive $\Sigma$ is equivalent to negative $\Sigma$, although it only
supports propositional $\eta$-rules. In contrast, positive identity is usually
\emph{not} equivalent to negative identity.

$\refl : t = u \to \Tm\,\Gamma\,(\Id\,t\,u)$ expresses reflexivity of identity:
definitionally equal terms are provably equal. $\reflect$, which goes the other
way around, is called \emph{equality reflection} \cite{TODO}: provably equal
terms are identified in the metatheory.

Uniqueness of identity proofs (UIP) is often ascribed to the extensional
identity type \cite{TODO}. UIP means that $\Tm\,\Gamma\,(\Id\,t\,u)$ has at most
a single inhabitant up to $\Id$. However, UIP is not something which is inherent
in the negative specification, instead it's inherited from the metatheory. If
$\Tm$ forms a homotopy set in the metatheory, then internal equality proofs
inherit uniqueness through the defining isomorphism.

\subsubsection{Positive types}

We do not dwell much on positive types here, as elsewhere in this thesis we talk
a lot about specifying such types anyway. We provide here some background and
a small example.

The motivation is to specify initial internal algebras in a cwf. However,
specifying the uniqueness of recursors using definitional equality is
problematic, if we are to have decidable and efficient conversion checking for a
type theory. Consider the specification of $\Bool$ together with its recursor.
\begin{alignat*}{3}
  & \Bool  &&: \Ty\,\Gamma \\
  & \true  &&: \Tm\,\Gamma\,\Bool \\
  & \false &&: \Tm\,\Gamma\,\Bool \\
  & \ms{BoolRec} &&: (B : \Ty\,\Gamma)\to \Tm\,\Gamma\,B \to \Tm\,\Gamma\,B \to \Tm\,\Gamma\,\Bool \to \Tm\,\Gamma\,B\\
  & \true\beta &&: \ms{BoolRec}\,B\,t\,f\,\true = t\\
  & \false\beta &&: \ms{BoolRec}\,B\,t\,f\,\false = f
\end{alignat*}
$\ms{BoolRec}$ together with the $\beta$-rules specifies an internal
$\Bool$-algebra morphism. A possible way to specify definitional uniqueness is
as follows. Assuming $B : \Ty\,\Gamma$, $t : \Tm\,\Gamma\,B$, $f :
\Tm\,\Gamma\,B$ and $m : \Tm\,(\Gamma\ext b : \Bool)\,B$, such that $m[b \mapsto
  \true] = t$ and $m[b \mapsto \false] = f$, it follows that
$\ms{BoolRec}\,B\,t\,f\,b : \Tm\,(\Gamma\ext b : \Bool)\,B$ is equal to $m$.

Unfortunately, deciding conversion with this rule entails deciding pointwise
equality of arbitrary $\Bool$ functions, which can be done in exponential time
in the number of $\Bool$ arguments. More generally, Scherer presented a decision
algorithm for conversion checking with strong finite sums and products in simple
type theory \cite{scherer17deciding}, which also takes exponential time. If we
move to natural numbers with definitionally unique recursion, conversion
checking becomes undecidable.

One solution is to have propositionally unique recursion instead. However, if
such equations are postulated, that would break the canonicity property in
intensional type theories, since now we would have equality proofs other than
$\refl$ in the empty context.

The standard solution is to have dependent elimination principles instead: this
allows inductive reasoning, canonicity and effectively decidable definitional
equality at the same time. For $\Bool$, we would have
\begin{alignat*}{3}
  & \ms{BoolInd} &&: (B : \Ty\,(\Gamma\ext b : \Bool)) \to \Tm\,\Gamma\,(B[b \mapsto \true])\\
  & &&\to \Tm\,\Gamma\,(B[b \mapsto \false]) \to (t : \Tm\,\Gamma\,\Bool) \to \Tm\,\Gamma\,(B[b \mapsto t])
\end{alignat*}
together with $\ms{BoolInd}\,B\,t\,f\,\true = t$ and $\ms{BoolInd}\,B\,t\,f\,\false = f$.

Of course, if we assume extensional identity types, we have undecidable
conversion anyway, and definitionally unique recursion is equivalent to
induction. But decidable conversion is an essential part of type theory, perhaps
its main selling point as a foundation for mechanized mathematics, which makes
it possible to relegate a deluge of boilerplate to computers. Hence, decidable
conversion should be kept in mind.

\subsubsection{Universes}

Universes are types which classify types. There are several different flavors of
universes.

\begin{mydefinition} A \textbf{Tarski-style} universe consists of
the following data:
\begin{alignat*}{3}
  & \U : \Ty\,\Gamma\hspace{2em}\El : \Tm\,\Gamma\,\U \to \Ty\,\Gamma
\end{alignat*}
\end{mydefinition}
This is a weak classifier, since not all $\Ty\,\Gamma$ are necessarily
represented as terms of the universe. Rather, this kind of universe can be
viewed as an internal sub-family of $(\Ty,\,\Tm)$. Like families, Tarski
universes can be closed under type formers. For instance, if $\U$ has $\Nat$,
we have the following:
\begin{alignat*}{3}
  &\Nat : \Tm\,\Gamma\,\U
    \hspace{1em}\mi{zero} : \Tm\,\Gamma\,(\El\,\Nat)
    \hspace{1em}\mi{suc} : \Tm\,\Gamma\,(\El\,\Nat) \to \Tm\,\Gamma\,(\El\,\Nat)
\end{alignat*}
\vspace{-2em}
\begin{alignat*}{3}
  \ms{NatElim} &:\,\,\,(P : \Ty\,(\Gamma\ext n : \El\,\Nat))\\
  &\to \Tm\,\Gamma\,(P[n \mapsto \mi{zero}])\\
  &\to \Tm\,(\Gamma\ext n : \El\,\Nat \ext \mi{np} : P[n \mapsto n])\,(P[n \mapsto \mi{suc}\,n]) \\
  &\to (n : \Tm\,\Gamma\,(\El\,\Nat)) \to \Tm\,\Gamma\,(P[n \mapsto n])
\end{alignat*}
If all type formers in $\U$ follow this scheme, $\U$ may be called a
\textbf{weakly Tarski} universe. If we assume that every type former in $\U$ is
also duplicated in $(\Ty,\,\Tm)$, moreover $\El$ preserves all type formers, so
that e.g.\ $\El\,\Nat$ is definitionally equal to the natural number type in
$\Ty$, then $\U$ is \textbf{strongly Tarski}.

It is often more convenient to have stronger classifiers as universes, so that
\emph{all} types in a given family structure are represented.

\begin{mydefinition}
Ignoring size issues for now, \textbf{Coquand universes} \cite{TODO} are
specified as follows:
\[
  \U : \Ty\,\Gamma\hspace{1em} (\El,\,\ms{c}) : \Tm\,\Gamma\,\U \simeq \Ty\,\Gamma
\]
$\ms{c}$ maps every type in $\Ty$ to a code in $\U$. Now we can ignore $\El$
when specifying type formers, as $\ms{c}$ can be always used to get a code in
$\U$ for a type.
\end{mydefinition}

Unfortunately, the exact specification above yields an inconsistent
``type-in-type'' system, because $\U$ itself has a code in $\U$. The standard
solution is to have multiple family structures $(\Ty_i,\,\Tm_i)$, indexed by
universe levels, and have $\U_i : \Ty_{i + 1}\,\Gamma$ and
$\Tm_{i+1}\,\Gamma\,\U_i \simeq \Ty_i\,\Gamma$. For a general specification of
consistent universe hierarchies , see \cite{kovacs2021generalized}. As mentioned in Section
\ref{sec:universes}, we omit universe indices in the following, and implicitly
assume ``just enough'' universes for particular purposes.

\begin{mydefinition}
\textbf{Russell universes} are Coquand universes additionally satisfying
$\Tm\,\Gamma\,\U = \Ty\,\Gamma$ as an equality of sets, and also $\ms{El}\,t =
t$. This justifies omitting $\El$ and $\ms{c}$ from informal notation,
implicitly casting between $\Tm\,\Gamma\,\U$ and $\Ty\,\Gamma$.
\end{mydefinition}
Russell-style universes are commonly supported in set-theoretic models. They are
also often inherited from meta-type-theories which themselves have
Russell-universes. Major implementations of type theories (Coq, Lean, Agda,
Idris) are all such.


\section{Two-Level Type Theory}

\subsection{Models}

We describe models of 2LTT in the following. This is not the only possible way
to present 2LTT; our approach differs from \cite{twolevel} in some ways. We will summarize
the differences at the end of this section.

\begin{mydefinition}
A model of a \textbf{two-level type theory} is a model of type theory such that
\begin{itemize}
  \item It supports a Tarski-style universe $\Ty_0 : \Ty\,\Gamma$ with decoding $\Tm_0 :
    \Tm\,\Gamma\,\Ty_0 \to \Ty\,\Gamma$.
  \item $\Ty_0$ may be closed under arbitrary type formers, however, it is only possible
    to eliminate from $\Ty_0$ type formers to types in $\Ty_0$.
\end{itemize}
Types in $\Ty_0$ are called \emph{inner} types, while other types are \emph{outer}. Alternatively,
we may talk about \emph{object-level} and \emph{meta-level} types.
\end{mydefinition}

For example, if we have inner functions, we have the following:
\begin{alignat*}{3}
  &\Pi_0 &&: (A : \Tm\,\Gamma\,\Ty_0) \to \Tm\,(\Gamma \ext \Tm_0\,A) \to \Tm\,\Gamma\,\Ty_0\\
  &(\app_0,\,\lam_0) &&: \Tm\,\Gamma\,(\Tm_0\,(\Pi_0\,A\,B)) \simeq \Tm\,(\Gamma \ext \Tm_0\,A)\,(\Tm_0\,B)
\end{alignat*}
If we have inner Booleans, we have the following (with $\beta$-rules omitted):
\begin{alignat*}{3}
  &\Bool_0 &&: \Tm\,\Gamma\,\Ty_0\\
  &\true_0 &&: \Tm\,\Gamma\,(\Tm_0\,\Bool_0)\\
  &\false_0 &&: \Tm\,\Gamma\,(\Tm_0\,\Bool_0)\\
  & \ms{BoolInd_0} &&: (B : \Tm\,(\Gamma\ext b : \Tm_0\,\Bool_0)\,\Ty_0)\\
  & && \to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto \true_0]))\\
  & &&\to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto \false_0]))\\
  & && \to (t : \Tm\,\Gamma\,(\Tm_0\,\Bool_0)) \to \Tm\,\Gamma\,(\Tm_0\,(B[b \mapsto t]))
\end{alignat*}

Intuitively, we can view outer types and terms as metatheoretical, while $\Ty_0$
represents the set of types in the object theory, and $\Tm_0$ witnesses that any
object type can be mapped to a metatheoretical set of object terms. The
restriction on elimination is crucial. If we have a Boolean term in the object
language, we can use the object-level elimination principle to construct new
object terms. But it makes no sense to eliminate into the metatheory. In fact,
an object-level Boolean term is not necessarily $\true$ or $\false$, it can also
be just a variable or neutral term in some context, or it can be an arbitrary
non-canonical value in a given model.

We review some properties of 2LTT. An important point is the action of $\Tm_0$
on type formers. In general, $\Tm_0$ preserves the negative type formers but not
others.

For example, we have the isomorphism $\Tm_0\,(\Pi_0\,A\,B) \simeq
\Pi_1\,(\Tm_0\,A)\,(\Tm_0\,B)$, where $\Pi_1$ denotes outer functions.  We move
left-to-right by mapping $t$ to $\lam_1\,(\app_1\,t)$, and the other way by
mapping $t$ to $\lam_0\,(\app_0\,t)$. The preservation of $\Sigma$, $\top$, $\K$
and extensional identity is analogous.

In contrast, we can map from outer positive types to inner ones, but not the
other way around. From $b : \Tm\,\Gamma\,\Bool_1$, we can use the outer
$\Bool_1$ recursor to return in $\Tm_0\,\Bool_0$. In the other direction, we
only have constant functions since the $\Bool_0$ recursor only targets types in
$\Ty_0$.

It may be the case that there are universes in the inner layer. For example,
disregarding size issues (or just accepting an inconsistent inner theory), there
may be an $\U_0$ in $\Ty_0$ such that we have $\Tm\,\Gamma\,(\Tm_0\,\U_0) =
\Tm\,\Gamma\,\Ty_0$. This amounts to having a Russell-style inner universe with
type-in-type. Assume that we have $\U_1$ as well, as a meta-level Russell
universe. Then we can map from $\Tm_0\,\U_0$ to $\U_1$, by taking $A$ to
$\Tm_0\,A$, but we cannot map in the other direction.

\subsection{Internal Syntax and Notation}
\label{sec:2ltt-internal-syntax}

In the rest of this thesis we will mostly work internally to a 2LTT, i.e.\ we
use 2LTT as metatheory. We adapt the metatheoretical notations used up until
now. We list used features and conventions below.

\begin{itemize}
  \item
    We keep previous notation for type formers. For instance, $\Pi$-types are
    written as $(x : A) \to B$ or as $A \to B$.
  \item
    We assume a Coquand-style universe in the outer layer, named $\Set$. As
    before, we leave the sizing levels implicit; if we were fully precise, we
    would write $\Set_i$ for a hierarchy of outer universes. Despite having a
    Coquand universe, we shall omit encoding and decoding in the internal
    syntax, and instead work in Russell-style. In practical implementations,
    elaborating Russell-style notation to Coquand-style is straightforward to
    do.
  \item
    If the same type formers are supported both in the inner and outer layers, we
    may distinguish them by $_0$ and $_1$ subscripts, e.g.\ by having $\Bool_0$ and
    $\Bool_1$. We omit some inferable subscripts, e.g.\ for $\Pi$ and
    $\Sigma$-types. In these cases, we usually know from the type parameters which
    type former is meant. For example, $\Tm_0\,\Bool_0 \to \Bool_1$ can only refer
    to outer functions.
  \item
    We have the convention that $\blank\!=\!\blank$ refers to the inner equality
    type, while $\blank\!\equiv\!\blank$ refers to the outer equality type. In
    the semantics of 2LTT that we use, outer equality of inner values is
    interpreted as definitional equality of inner terms, hence the naming
    scheme.
  \item
    By having $\Set$, we are able to have $\Ty_0 : \Set$ and $\Tm_0 : \Ty_0 \to
    \Set$. So we don't have to deal with proper meta-level types, and have a
    more uniform notation. Notation and specification for inner type formers changes
    accordingly. For example, for inner $\Pi$-types we may write $(x : A) \to B$
    if $A : \Ty_0$ and $B$ depends on $x : \Tm_0\,A$. This also enables a
    higher-order specification: if $B : \Tm_0\,A \to \Ty_0$, then $(x : A) \to
    B\,x : \Ty_0$, and the specifying isomorphism for $\Pi$ can be written as
    $\Tm_0\,((x : A) \to B\,x) \simeq ((x : \Tm_0\,A) \to \Tm_0\,(B\,x))$.
  \item
    We may omit inferable $\Tm_0$ applications. For instance, $\Bool_1 \to
    \Bool_0$ can be ``elaborated'' to $\Bool_1 \to \Tm_0\,\Bool_0$ without
    ambiguity, since the function codomain must be on the same level as the
    domain, and the only thing we can do to make sense of this is to lift the
    codomain by $\Tm_0$. Sometimes there is some ambiguity: $(\Bool_0 \to
    \Bool_0) \to \Bool_1$ can be elaborated both to $\Tm_0\,(\Bool_0 \to
    \Bool_0) \to \Bool_1$ and to $(\Tm_0\,\Bool_0 \to \Tm_0\,\Bool_0) \to
    \Bool_1$. However, in this case the two output types are definitionally
    isomorphic, because of the $\Pi$-preservation by $\Tm_0$. Hence, the
    elaboration choice does not make much difference, so we may still omit
    $\Tm_0$-s in situations like this.
\end{itemize}

\begin{myexample} Working in the internal syntax of 2LTT, the specification of $\Bool_0$
looks like the following (omitting $\beta$ again):
\begin{alignat*}{3}
  &\Bool_0  &&: \Ty_0\\
  &\true_0  &&: \Bool_0\\
  &\false_0 &&: \Bool_0\\
  & \ms{BoolInd_0} &&: (B : \Bool_0 \to \Ty_0) \to B\,\true_0 \to B\,\false_0 \to (t : \Bool_0) \to B\,t
\end{alignat*}
If we elaborate the type of $\ms{BoolInd_0}$, we get the following:
\begin{alignat*}{3}
  & \ms{BoolInd_0} &&: (B : \Tm_0\,\Bool_0 \to \Ty_0) \to \Tm_0\,(B\,\true_0) \to \Tm_0\,(B\,\false_0)\\
  & && \to (t : \Tm_0\,\Bool_0) \to \Tm_0\,(B\,t)
\end{alignat*}
Here, the type is forced to live in the outer level because of the dependency on
$\Ty_0$. Since $\Ty_0$ is an outer type, $\Bool_0 \to \Ty_0$ must be lifted, which
in turn requires all other types to be lifted as well.
\end{myexample}

\section{Standard Semantics of 2LTT}

We review the standard semantics of 2LTT which we use in the rest of the
thesis. This justifies the metaprogramming view, that 2LTT allows meta-level
reasoning about an inner theory.

We present it two steps, by assuming progressively more structure in the inner
theory. First, we only assume a category. This already lets us present a
presheaf semantics for the outer layer. Then, we assume a cwf as the inner
theory, which lets us interpret $\Ty_0$ and $\Tm_0$ and also consider inner type
formers.

\subsection{Presheaf Model of the Outer Layer}

In this subsection we present a presheaf model for the outer layer of 2LTT, that
is, the base category together with the terminal object, the $(\Ty,\,\Tm)$
family and some type formers. This presheaf semantics is well-known in the
literature \cite{TODO}. We give a specification which follows \cite{TODO} and
\cite{TODO} most closely.

In the following, we work outside 2LTT (since we are defining a model of 2LTT),
in a suitable metatheory; an extensional type theory with enough $\Set$
universes suffices.

We assume a $\mbbC$ category. We write $i,\,j,\,k : |\mbbC|$ for objects and
$f,\,g,\,h\,: \mbbC(i,\,j)$ for morphisms. We use a different notation than for
cwfs before, in order to disambiguate components in $\mbbC$ from components in
the presheaf model of 2LTT. We use $\hmbbC$ to refer to the model which is being
defined. We use the same component names for $\hmbbC$ as in Section
\ref{sec:models-of-tts}.

\subsubsection{Model of Cwf}

\begin{mydefinition}
$\Gamma : \Con$ is a presheaf over $\mbbC$. Its components
are as follows.
\begin{alignat*}{3}
  & |\Gamma|             &&: |\mbbC| \to \Set \\
  & \blank\lab\blank\rab &&: |\Gamma|\,j \to \mbbC(i,\,j) \to |\Gamma|\,i\\
  & \gamma\lab\id\rab &&= \gamma \\
  & \gamma\lab f\circ g\rab &&= \gamma \lab f \rab \lab g \rab
\end{alignat*}
We flip around the order of arguments in the action of $\Gamma$ on
morphisms. This is more convenient because of the contravariance; we can observe
this in the statement of preservation laws already. The action on morphisms is
sometimes called \emph{restriction}.
\end{mydefinition}

\begin{mydefinition}
$\sigma : \Sub\,\Gamma\,\Delta$ is a natural transformation from $\Gamma$ to
$\Delta$. It has action $|\sigma| : |\Gamma|\,i \to |\Delta|\,i$, such that
$|\sigma|(\gamma\lab f \rab) = (|\sigma|\gamma)$.
\end{mydefinition}

\begin{mydefinition}
\label{def:presheaf-type}
$A : \Ty\,\Gamma$ is a displayed presheaf over $\Gamma$. The
``displayed'' here is used in exactly the same sense as in ``displayed
algebra'' before. As we will see in Chapter \ref{chap:fqiit}, presheaves can be
specified with a signature, in which case a presheaf is an algebra, and a
displayed presheaf is a displayed algebra. The definition here is equivalent
to saying that $A$ is a presheaf over the category of elements of $\Gamma$,
but it is more convenient to use in concrete definitions and calculations. The
components of $A$ are as follows.
\begin{alignat*}{3}
  &|A| &&: |\Gamma|\,i \to \Set\\
  &\blank\lab\blank\rab &&: |A|\,\gamma \to (f : \mbbC(i,\,j)) \to |A|\,(\gamma\lab f \rab)\\
  & \alpha\lab\id\rab &&= \alpha \\
  & \alpha\lab f\circ g\rab &&= \alpha \lab f \rab \lab g \rab
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
$t : \Tm\,\Gamma\,A$ is a section of the displayed presheaf $A$. This is
again the same notion of section that we have seen before, instantiated for
presheaves.
\begin{alignat*}{3}
  & |t| : (\gamma : |\Gamma|)\,i \to |A|\,\gamma \\
  & |t|(\gamma\lab f \rab) = (|t|\gamma)\lab f \rab
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
$\Gamma \ext A : \Con$ is the total presheaf of the displayed presheaf $A$. Its action on objects and morphisms is the following.
\begin{alignat*}{3}
  &|\Gamma \ext A| &&\defn (\gamma : |\Gamma|) \times |A\,\gamma|\\
  &(\gamma,\,\alpha)\lab f \rab &&\defn (\gamma\lab f \rab,\, \alpha\lab f \rab)
\end{alignat*}
The $\id$ and $\blank\!\circ\!\blank$ preservation laws follow immediately.
\end{mydefinition}

\begin{mydefinition}
$A[\sigma] : \Ty\,\Gamma$ is defined as follows, assuming
$A : \Ty\,\Delta$ and $\sigma : \Sub\,\Gamma\,\Delta$.
\begin{alignat*}{3}
  & |A[\sigma]|\,\gamma &&\defn |A|\,(|\sigma|\,\gamma) \\
  & \alpha \lab f \rab &&\defn \alpha \lab f \rab
\end{alignat*}
In the second component, we use $\blank\!\lab\!\blank\!\rab$ for $A$ on the right hand
side.  The definition is well-typed since $|A|\,(|\sigma|\,(\gamma\lab f \rab))
= |A|\,((|\sigma|\,\gamma)\lab f \rab)$ by the naturality of
$\sigma$. Functoriality follows from functoriality of $A$.
\end{mydefinition}

It's easy to check that the above definitions can be extended to a cwf.
\begin{itemize}
  \item For the base category, we take the category of presheaves.
  \item The empty context $\emptycon$ is the terminal presheaf, i.e.\ the
        constantly $\top$ functor.
  \item Type substitution is functorial, as it is defined as simple function
    composition of actions on objects.
  \item Term substitution is defined as composition of a section and
    a natural transformation; and also functorial for the same reason.
  \item Context comprehension structure follows from the $\Sigma$-based definition for
    context extension.
\end{itemize}

\subsubsection{Yoneda Embedding}

Before continuing with interpreting type formers in $\hmbbC$, we review the
Yoneda embedding, as it is useful in subsequent definitions.

\begin{mydefinition}
The \textbf{Yoneda embedding}, denoted $\ms{y}$, is a functor from $\mbbC$ to
the underlying category of $\hmbbC$, defined as follows.
\begin{alignat*}{3}
  & \yon : |\mbbC| \to \Con \hspace{3em}&& \yon : \mbbC(i,\,j) \to \Sub\,(\yon\,i)\,(\yon\,j)\\
  & \yon\,i \defn \mbbC(\blank,\,i) && |\yon\,f|\,g \defn f \circ g
\end{alignat*}
\end{mydefinition}

\begin{mylemma}[\textbf{Yoneda lemma}] We have $\Sub\,(\yon\,i)\,\Gamma \simeq |\Gamma|\,i$ as an isomorphism of sets, natural in $i$ \cite{TODO}.
\end{mylemma}

\noindent\emph{Corollary.} If we choose $\Gamma$ to be $\yon j$, it follows that
$\Sub\,(\yon\,i)\,(\yon\,j) \simeq \mbbC(i,\,j)$, i.e.\ that $\yon$ is
bijective on morphisms; hence it is an embedding.

\begin{notation}
\label{not:yoneda}
For $\gamma : |\Gamma|\,i$, we use $\gamma\lab \blank \rab :
\Sub\,(\yon\,i)\,\Gamma $ to denote transporting right-to-left along the Yoneda
lemma. In the other direction we don't really need a notation, since from
$\sigma : \Sub\,(\yon\,i)\,\Gamma$ we get $\sigma\,\id : |\Gamma|\,i$.
\end{notation}

\subsubsection{Type Formers}

\begin{mydefinition}
\label{def:k-psh}
\textbf{Constant families} are displayed presheaves which do not depend on their context.
\begin{alignat*}{3}
  & \K &&: \Con \to \{\Gamma : \Con \} \to \Ty\,\Gamma\\
  & |\K\,\Delta|\,\{i\}\,\gamma\,&&\defn |\Delta|\,i \\
  & \delta\lab f \rab &&\defn \delta \lab f \rab
\end{alignat*}
With this definition, we have $\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$
so we have strict constant families.
\end{mydefinition}

\begin{notation}
It is useful to consider any set as a constant presheaf, so
given $A : \Set$ we may write $A : \Con$ for the constant presheaf
as well.
\end{notation}

\begin{mydefinition}
From any $A : \Set$, we get $\K\,A : \Ty\,\Gamma$. This can be used to
model negative or positive \textbf{closed type formers}. For example, natural
numbers are modeled as $\K\,\mbb{N}$, Booleans as $\K\,\Bool$, the unit type as
$\K\,\top$, and so on.
\end{mydefinition}

\begin{mydefinition}
\textbf{Coquand universes} can be defined as follows. We write $\Set_{\hmbbC}$
for the outer universe in the model, to distinguish it from the external
$\Set$. Since the $\Set_{\hmbbC}$ is a non-dependent type, it is helpful to
define it as a $\Set_{\hmbbC} : \Con$ such that $\Sub\,\Gamma\,\Set_{\hmbbC}
\simeq \Ty\,\Gamma$.  The usual universe can be derived from this as
$\K\,\Set_{\hmbbC}$. Again, we ignore size issues; the fully formal definition
would involve indexing constructions in $\hmbbC$ by universe levels.

We can take a hint from the Yoneda lemma. We aim to define $|\Set_{\hmbbC}|\,i$,
but by the Yoneda lemma it is isomorphic to $\Sub\,(\yon
i)\,\Set_{\hmbbC}$. However, by specification this should be isomorphic to
$\Ty\,(\yon\,i)$, so we take this as definition:
\begin{alignat*}{3}
  & \Set_{\hmbbC} &&: \Con\\
  &|\Set_{\hmbbC}|\,i &&\defn \Ty\,(\yon\,i)\\
  &A \lab f \rab &&\defn A[\yon f]
\end{alignat*}
\end{mydefinition}
In the $A \lab f \rab$ definition, we substitute $A : \Ty\,(\yon\,i)$ with $\yon
f : \Sub\,(\yon j)\,(\yon i)$ to get an element of $\Ty\,(\yon j)$.  The
required $\Sub\,\Gamma\,\Set_{\hmbbC} \simeq \Ty\,\Gamma$ is straightforward, so
we omit the definition.

We note that \emph{Russell} universes are not supported in the outer layer, as
$\Sub\,\Gamma\,\Set_{\hmbbC}$ and $\Ty\,\Gamma$ are not strictly the same, in
particular they have a different number of components as iterated
$\Sigma$-types. Nevertheless, as we mentioned in Section \ref{sec:2ltt-internal-syntax}, we
use Russell-style notation in the internal 2LTT syntax, and assume that encoding/decoding
is inserted by elaboration.

\begin{mydefinition}
\textbf{$\Sigma$-types} are defined pointwise. The definitions for pairing and
projections follow straightforwardly.
\begin{alignat*}{3}
  & \Sigma  &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma\ext A) \to \Ty\,\Gamma\\    & |\Sigma\,A\,B|\,\gamma && \defn (\alpha : |A|\,\gamma) \times |B|\,(\gamma,\,\alpha)\\
  & (\alpha,\,\beta) \lab f \rab && \defn (\alpha \lab f \rab,\, \beta \lab f \rab)
\end{alignat*}
\end{mydefinition}

\begin{mydefinition}
We define \textbf{$\Pi$-types} in the following. This is a bit more complicated,
so first we look at the simpler case of presheaf exponentials.

The exponential $\Delta^\Gamma : \Con$ is characterized by the isomorphism
$\Sub\,(\Gamma \otimes \Delta)\,\Xi\,\simeq\,\Sub\,\Gamma\,(\Xi^\Delta)$, where
we write $\otimes$ for the pointwise product of two presheaves. We can again use
the Yoneda lemma. We want to define $|\Delta^\Gamma|\,i$, but this is isomorphic
to $\Sub\,(\yon i)\,(\Delta^\Gamma)$, which should be isomorphic to $\Sub\,(\yon
i \otimes \Gamma)\,\Delta$ by the specification of exponentials. Hence:
\begin{alignat*}{3}
  &|\Delta^\Gamma|\,i &&\defn \Sub\,(\yon i \otimes \Gamma)\,\Delta \\
  & \sigma \lab f \rab &&\defn \sigma \circ (\yon f \circ \p,\,\q)
\end{alignat*}
In the definition of presheaf restriction, we use $\p$, $\q$ as projections and
$\blank\!,\!\blank$ as pairing for $\otimes$. In short, $(\yon f \circ \p,\,\q)$
is the same as the morphism lifting from Definition \ref{def:cwfops}: it weakens
$\yon f : \Sub\,(\yon j)\,(\yon i)$ to $\Sub\,(\yon j \otimes \Gamma)\,(\yon i
\otimes \Gamma)$.

The dependently typed case follows the same pattern, except that we use $\Tm$
and $\blank\!\ext\!\blank$ instead of $\Sub$ and
$\blank\!\otimes\!\blank$. Additionally, the action on objects depends on
$\gamma : |\Gamma|\,i$, and we make use of $\gamma \lab \blank \rab\,\,:
\Sub\,(\yon i)\,\Gamma$ (introduced in Notation \ref{not:yoneda}).
\begin{alignat*}{3}
  & \Pi &&: (A : \Ty\,\Gamma) \to \Ty\,(\Gamma \ext A) \to \Ty\,\Gamma\\
  & |\Pi\,A\,B|\,\{i\}\,\gamma &&\defn \Tm\,(\yon i \ext A[\gamma \lab \blank \rab])\,(B[\gamma\lab\blank\rab \circ\,\p,\,\q])\\
  & t\lab f \rab &&\defn t[\yon f \circ \p,\, \q]
\end{alignat*}
Let's unfold the above definition a bit. Assuming $t : |\Pi\,A\,B|\,\{i\}\,\gamma$, we have
\[
|t| : \{j : |\mbbC|\}\to((f,\,\alpha) : (f : \mbbC(j,\,i)) \times |A|\,(\gamma\lab f \rab)) \to
       |B|\,(\gamma\lab f\rab,\,\alpha)
\]
This is a bit clearer if we remove the $\Sigma$-type by currying.
\[
|t| : \{j : |\mbbC|\}(f : \mbbC(j,\,i))(\alpha : |A|\,(\gamma \lab f \rab)) \to
       |B|\,(\gamma\lab f \rab,\,\alpha)
\]

Restriction is functorial since it is defined as $\Tm$ substitution. The definitions
for $\lam$ and $\app$ are left to the reader.
\end{mydefinition}

\begin{mydefinition}
\textbf{Extensional identity} is defined as pointwise equality of sections:
\begin{alignat*}{3}
  & \Id : \Tm\,\Gamma\,A \to \Tm\,\Gamma\,A \to \Ty\,\Gamma\\
  & |\Id\,t\,u|\,\gamma \defn |t|\,\gamma = |u|\,\gamma
\end{alignat*}
For the restriction operation, we have to show that $|t|\,\gamma = |u|\,\gamma$
implies $|t|\,(\gamma\lab f \rab) = |u|\,(\gamma \lab f \rab)$. This
follows from congruence by $\blank \lab f \rab$ and naturality of $t$ and
$u$.  The defining $(\reflect,\,\refl) : \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t =
u)$ isomorphism is evident, assuming UIP and function extensionality for the
metatheoretic $\blank\!=\!\blank$ relation (which we do assume).
\end{mydefinition}

\subsection{Modeling The Inner Layer}

We assume now that $\mbbC$ is a cwf. We write types as $a,\,b,\,c :
\Ty_\mbbC\,i$ and terms as $t,\,u,\,v : \Tm_\mbbC\,i\,a$. We reuse $\emptycon$
for the terminal object and $\blank\ext\blank$ for context extension, and
likewise reuse notation for substitutions.

\begin{mydefinition}[\textbf{$\Ty_{0}$, $\Tm_{0}$}]
First, note that $\Ty_{\mbbC}$ is a presheaf over $\mbbC$, and $\Tm_{\mbbC}$ is
a displayed presheaf over $\Ty_{\mbbC}$; this follows from the requirement that
they form a family structure over $\mbbC$. Hence, in the presheaf model
$\Ty_{\mbbC}$ is an element of $\Con$ and $\Tm_{\mbbC}$ is an element of
$\Ty\,\Ty_{\mbbC}$. Also recall from Definition \ref{def:k-psh} that
$\Tm\,\Gamma\,(\K\,\Delta) = \Sub\,\Gamma\,\Delta$. With this is mind, we
give the following definitions:
\begin{alignat*}{3}
  & \Ty_0 : \Ty\,\Gamma                   && \Tm_0 : \Tm\,\Gamma\,\Ty_0 \to \Ty\,\Gamma\\
  & \Ty_0 \defn \K\,\Ty_{\mbbC}\hspace{2em} && \Tm_0\,A \defn \Tm_{\mbbC}[A]
\end{alignat*}
$\Tm_{\mbbC}[A]$ is well-typed since $A : \Tm\,\Gamma\,(\K\,\Ty_{\mbbC})$, thus
$A : \Sub\,\Gamma\,\Ty_{\mbbC}$. In other words, $A$ is a natural transformation
from $\Gamma$ to the presheaf of inner types.
\end{mydefinition}

\subsubsection{Inner Type Formers}

Can type formers in $(\Ty_{\mbbC},\,\Tm_{\mbbC})$ be transferred to
$(\Ty_0,\,\Tm_0)$ in the presheaf model of 2LTT? For example, if $\mbbC$
supports $\Bool$, we would like to model $\Bool_0$ in $\Ty_0$ as well. The
following explanation is adapted from Capriotti \cite[Section
  2.3]{capriotti2017models}.

Generally, a type former in $\mbbC$ transfers to $\hmbbC$ if it can be specified
in the internal language of $\hmbbC$; if the type former ``always has been'' in
$\hmbbC$ to begin with. To be describable in $\hmbbC$, a type former needs to be
natural with respect to $\mbbC$ morphisms. This is also a core idea of HOAS:
when working in $\hmbbC$, everything is natural, and we can omit boilerplate
related to contexts and substitutions. For example, consider the specification
of inner $\Pi$-types in the internal syntax of 2LTT:
\begin{alignat*}{3}
  &\Pi_0             &&: (A : \Ty_0) \to (\Tm_0\,A \to \Ty_0) \to \Ty_0\\
  &(\app_0,\,\lam_0) &&: \Pi_0\,A\,B \simeq ((a :\,\Tm_0\,A) \to \,\Tm_0\,(B\,a))
\end{alignat*}
We can say that this \emph{defines} what it means for $\mbbC$ to support
$\Pi$. We recover the usual non-higher-order specification of $\Pi$ in the
following way, up to isomorphism:
\begin{itemize}
\item First, we interpret the higher-order specification as a context or closed $\Sigma$-type
      in the standard presheaf model of 2LTT. This yields a presheaf over $\mbbC$.
\item Then, we evaluate the resulting presheaf at the terminal object
      $\emptycon$. This yields a set which is isomorphic to the conventional
      specification of $\Pi$.
\end{itemize}

In summary, if by ``type formers'' we mean extra structure on $(\Ty_0,\,\Tm_0)$
which is definable in 2LTT, then \emph{by definition} all such type formers
transfer from $\mbbC$ to $(\Ty_0,\,\Tm_0)$. This holds for every type former
mentioned in this thesis.

\subsection{Functions with Inner Domains}

There is a useful semantic simplification in the standard presheaf model, in
cases where we have functions of the form $\Pi\,(\Tm_0\,A)\,B$. This greatly
reduces encoding overhead when interpreting inductive signatures in 2LTT; we
look at examples in Section \ref{sec:2ltt-simple-signatures}. First we look at
the simply-typed case with presheaf exponentials.
\begin{mylemma}
$\yon$ preserves finite products up to isomorphism, i.e.\ $\yon \emptycon \simeq
  \emptycon$ and $\yon (i \otimes j) \simeq (\yon i \otimes \yon j)$.
\end{mylemma}
\begin{proof}
$\yon \emptycon$ is $\mbbC(\blank,\,\emptycon)$ by definition, which is
pointwise isomorphic to $\top$, hence isomorphic to $\emptycon \equiv
\K\,\top$. $\yon (i \otimes j)$ is $\mbbC(\blank,\,i \otimes j)$, which is
isomorphic to $\yon i \otimes \yon j$ by the specification of products.
\end{proof}
\begin{mylemma} We have the following isomorphism.
\begin{alignat*}{3}
  & |\Gamma^{\yon i}|\,j \equiv \hspace{3em}&&\\
  & \Sub\,(\yon j \otimes \yon i)\,\Gamma \simeq \hspace{3em} &&\text{by product preservation}\\
  & \Sub\,(\yon (j \otimes i))\,\Gamma \simeq \hspace{3em} &&\text {by Yoneda lemma}\\
  & |\Gamma|\,(j \otimes i)&&
\end{alignat*}
\end{mylemma}

It is possible to rephrase the above derivation for $\Pi$-types. For that, we
would need to define the action of $\yon$ on types and terms, consider the
preservation of $\blank\ext\blank$ by $\yon$, and also specify a ``dependent''
Yoneda lemma for $\Tm$. For the sake of brevity, we omit this, and present the
result directly:
\begin{alignat*}{3}
  & |\Pi\,(\Tm_0\,A)\,B|\,\{i\}\,\gamma \simeq |B|\,\{i \ext |A|\,\gamma\}\,(\gamma \lab \p \rab,\,\q)
\end{alignat*}
In short, depending on an inner domain is the same as depending on an extended
context in $\mbbC$.  We expand a bit on the typing of the right hand side. We
have $\gamma : |\Gamma|\,i$, moreover
\begingroup
\allowdisplaybreaks
\begin{alignat*}{3}
  & |B| &&: \{j : \mbbC\} \to |\Gamma\,\,\ext \Tm_0\,A|\,j \to \Set\\
  & |B| &&: \{j : \mbbC\} \to ((\gamma' : |\Gamma|\,j)\times \Tm_{\mbbC}\,j\,(|A|\,\gamma')) \to \Set\\
  & |B|\,\{i \ext |A|\,\gamma\} &&: ((\gamma' : |\Gamma|\,(i \ext |A|\,\gamma))\times \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,(|A|\,\gamma')) \to \Set\\
  & \gamma \lab \p \rab &&: |\Gamma|\,(i \ext |A|\,\gamma)\\
  & \q &&: \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,((|A|\,\gamma)[\p])\\
  & \q &&: \Tm_{\mbbC}\,(i \ext |A|\,\gamma)\,(|A|\,(\gamma \lab \p \rab))\\
\end{alignat*}
\endgroup

\section{Simple Inductive Signatures in 2LTT}
\label{sec:2ltt-simple-signatures}

We revisit simple inductive signatures in this section, working internally to
2LTT. We review the concepts introduced in Chapter
\ref{chap:simple-inductive-signatures} in the same order.

\begin{notation}
In this section we shall be fairly explicit about writing $\Tm_0$-s and
transporting along definitional isomorphisms. The simple setting makes it
feasible to be explicit; in later chapters we are more terse, as signatures and
semantics get more complicated.
\end{notation}

\subsection{Theory of Signatures}
Signatures are defined exactly in the same way as before: we have $\Con : \Set$,
$\Ty : \Set$, $\Sub : \Con \to \Con \to \Set$, $\Var : \Con \to \Ty \to \Set$ and
$\Tm : \Con \to \Ty \to \Set$. However, now by $\Set$ we mean the outer universe
of 2LTT. Thus signatures are inductively defined in the outer layer.

\subsection{Algebras}

Again we compute algebras by induction on signatures, but now we use inner
types for carriers of algebras. We interpret types as follows:
\begin{alignat*}{3}
& \hspace{-4em} \rlap{$\blank^A : \Ty \to \Ty_0 \to \Set$} \\
& \hspace{-4em} \iota^A\,&&X \defn \Tm_0\,X \\
& \hspace{-4em} (\iota\to A)^A\,&&X \defn \Tm_0\,X \to A^A\,X
\end{alignat*}
Elsewhere, we change the type of the $X$ parameters accordingly:
\begin{alignat*}{3}
& \blank^A &&: \Con \to \Ty_0 \to \Set\\
& \blank^A &&: \Var\,\Gamma\,A \to \{X : \Ty_0\} \to \Gamma^A\,X \to A^A\,X\\
& \blank^A &&: \Tm\,\Gamma\,A \to \{X : \Ty_0\} \to \Gamma^A\,X \to A^A\,X\\
& \blank^A &&: \Sub\,\Gamma\,\Delta \to \{X : \Ty_0\} \to \Gamma^A\,X \to \Delta^A\,X
\end{alignat*}
We also define $\ms{Alg}\,\Gamma$ as $(X : \Ty_0) \times \Gamma^A\,X$.

\begin{myexample}
Inside 2LTT we have the following:\footnote{Up to isomorphism, since we previously defined $\Gamma^A$ as a function type instead of an iterated product type.}
\[ \Alg\,\ms{NatSig} \equiv (X : \Ty_0)\times(\mi{zero} : \Tm_0\,X)\times(\mi{suc} : \Tm_0\,X \to \Tm_0\,X) \]
Then, we may assume any cwf $\mbbC$, and interpret the above closed type in the
presheaf model $\hmbbC$, and evaluate the result at $\emptycon$ and
the unique element of the terminal presheaf $\K\,\top$:
\[
  |\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt : \Set
\]
We only need to compute definitions now. We use the simplified semantics for
$\mi{suc} : \Tm_0\,X \to \Tm_0\,X$, since the function domain is an inner
type. We get the following:
\[
|\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt \equiv
(X : \Ty_{\mbbC}\,\emptycon) \times (\mi{zero} : \Tm_{\mbbC}\,\emptycon\,X) \times (\mi{suc} : \Tm_{\mbbC}\,(\emptycon \ext X)\,X)
\]
Using the same computation, we get the following for binary trees:
\[
|\Alg\,\ms{TreeSig}|\,\{\emptycon\}\,\tt \equiv
(X : \Ty_{\mbbC}\,\emptycon) \times (\mi{leaf} : \Tm_{\mbbC}\,\emptycon\,X) \times (\mi{node} : \Tm_{\mbbC}\,(\emptycon \ext X \ext X)\,X)
\]
\end{myexample}

We can also get internal algebras in any $\mbbC$ category with finite products,
because we can build cwfs from all such $\mbbC$.

\begin{mydefinition} Assuming $\mbbC$ with finite products, we build a cwf by setting
$\Con \defn |\mbbC|$, $\Ty\,\Gamma \defn |\mbbC|$, $\Sub\,\Gamma\,\Delta \defn \mbbC(\Gamma,\,\Delta)$, $\Tm\,\Gamma\,A \defn \mbbC(\Gamma,\,A)$, $\Gamma \ext A \defn \Gamma \otimes A$ and $\emptycon \defn \emptycon_{\mbbC}$. In short, we build a non-dependent (simply-typed) cwf.
\end{mydefinition}

Now we can effectively interpret signatures in finite product categories. For
example:
\[
|\Alg\,\ms{NatSig}|\,\{\emptycon\}\,\tt \equiv
(X : |\mbbC|) \times (\mi{zero} : \mbbC(\emptycon,\,X)) \times (\mi{suc} : \mbbC(\emptycon \otimes X,\,X))
\]
This is almost the same as what we would write by hand for the specification of
natural number objects; the only difference is the extra $\emptycon
\otimes\blank$ in $\mi{suc}$.

\subsection{Morphisms}

We get an additional degree of freedom in the computation of morphisms:
preservation equations can be inner or outer. The former option is \emph{weak}
or \emph{propositional} preservation, while the latter is \emph{strict}
preservation. In the presheaf model of 2LTT, outer equality is definitional
equality of inner terms, while inner equality is propositional equality in the
inner theory. Of course, if the inner theory has extensional identity types,
weak and strict equations in 2LTT coincide for inner types. We compute weak
preservation for types as follows.
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^M : (A : \Ty)\{X_0\,X_1 : \Ty_0\}(X^M : \Tm_0\,X_0 \to \Tm_0\,X_1) \to A^A\,X_0 \to A^A\,X_1 \to \Set$}\\
  & \hspace{-5em}\iota^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn \Tm_0\,(X^M\,\alpha_0 = \alpha_1) \\
  & \hspace{-5em}(\iota\to A)^M\,&&X^M\,\alpha_0\,\,\alpha_1 \defn
       (x : \Tm_0\,X_0) \to A^M\,X^M\,(\alpha_0\,x)\,(\alpha_1\,(X^M\,x))
\end{alignat*}
For strict preservation, we simply change $\Tm_0\,(X^M\,\alpha_0 = \alpha_1)$ to
$X^M\,\alpha_0 \equiv \alpha_1$. The definition of morphisms is the same as
before:
\begin{alignat*}{3}
  &\blank^M : (\Gamma : \Con_1)\{X_0\,X_1 : \Ty_0\} \to (\Tm_0\,X_0 \to \Tm_0\,X_1) \to \Gamma^A\,X_0 \to \Gamma^A\,X_1 \to \Set\\
  &\Gamma^M\,X^M\,\gamma_0\,\gamma_1 \defn
  \{A\}(x : \Var_1\,\Gamma\,A) \to A^M\,X^M\,(\gamma_0\,x)\,(\gamma_1\,x)\\
  & \\
  &\Mor : \{\Gamma : \Con_1\} \to \Alg\,\Gamma \to \Alg\,\Gamma \to \Set \\
  &\Mor\,\{\Gamma\}\,(X_0,\,\gamma_0)\,(X_1,\,\gamma_1) \defn (X^M : \Tm_0\,X_0 \to \Tm_0\,X_1) \times \Gamma^M\,X^M\,\gamma_0\,\gamma_1
\end{alignat*}
We omit here the $\blank^M$ definitions for terms and substitutions.

\subsection{Displayed Algebras}

We present $\blank^D$ only for types below.
\begin{alignat*}{3}
  & \rlap{$\blank^D : (A : \Ty)\{X\} \to (\Tm_0\,X \to \Ty_0) \to A^A\,X \to \Set$}\\
  & \iota^D\,       && X^D\,\alpha \defn \Tm_0\,(X^D\,\alpha) \\
  & (\iota\to A)^D\,&& X^D\,\alpha \defn (x : \Tm_0\,X)(x^D : \Tm_0\,(X^D\,x)) \to A^D\,X^D\,(\alpha\,x)
\end{alignat*}
We use type dependency in the inner layer. In the presheaf model, this is
interpreted as inner types depending on certain contexts.
\begin{myexample} Assume a closed $(X,\,\mi{zero},\,\mi{suc})$ $\Nat$-algebra in 2LTT. We have the following computation:
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc}) \equiv$}\\
              & (X^D &&: \Tm_0\,X \to \Ty_0)\\
      \times\,& (\mi{zero^D} &&: \Tm_0\,(X^D\,\mi{zero}))\\
      \times\,& (\mi{suc^D} &&: (n : \Tm_0\,X) \to \Tm_0\,(X^D\,n) \to \Tm_0\,(X^D\,(\mi{suc}\,n)))
\end{alignat*}
Let's look at the presheaf interpretation now. We simplify functions with inner
domains everywhere. Also note that for $\ms{suc} : \Tm_0\,X \to \Tm_0\,X$, we
get $|\ms{suc}|\,\tt : \Tm_{\mbbC}\,(\emptycon\ext n : |X|\,\tt)\,(|X|\,\tt)$ in
the semantics, so a $\ms{suc}\,t$ application is translated as a substitution
$(|\ms{suc}|\,\tt)[n \mapsto |t|\,\tt]$.
\begin{alignat*}{3}
  & \rlap{$|\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})|\,\{\emptycon\}\,\tt \equiv$}\\
              & (X^D &&: \Ty_{\mbbC}\,(\emptycon\ext n : |X|\,\tt))\\
      \times\,& (\mi{zero^D} &&: \Tm_{\mbbC}\,\emptycon\,(X^D[n \mapsto |\mi{zero}|\,\tt]))\\
      \times\,& (\mi{suc^D} &&: \Tm_{\mbbC}\,(\emptycon\ext n : |X|\,\tt \ext n^D : X^D[n \mapsto |\mi{zero}|\,\tt])\,(X^D[n \mapsto (|\mi{suc}|\,\tt)[n \mapsto n]))
\end{alignat*}
\end{myexample}
To explain $(|\ms{suc}|\,\tt)[n \mapsto n])$: we have $\ms{suc}\,n$ in 2LTT,
where $n$ is an inner variable, and in the presheaf model inner variables become
actual variables in the inner theory. Hence, we map the $n$ which $\ms{suc}$
depends on to the concrete $n$ in the context.

We can also interpret displayed algebras in finite product categories:
\begin{alignat*}{3}
  & \hspace{-2em}\rlap{$|\DispAlg\,\{\ms{NatSig}\}\,(X,\,\mi{zero},\,\mi{suc})|\,\{\emptycon\}\,\tt \equiv$}\\
              & (X^D &&: |\mbbC|)\\
      \times\,& (\mi{zero^D} &&: \mbbC(\emptycon,\,X^D))\\
      \times\,& (\mi{suc^D} &&: \mbbC(\emptycon \otimes |X|\,\tt \otimes X^D,\, X^D))
\end{alignat*}

While displayed algebras in cwfs can be used as bundles of induction motives and
methods, in finite product categories they are argument bundles to
\emph{primitive recursion}; this is sometimes also called a
\emph{paramorphism} \cite{bananas}. In an internal syntax, the type of primitive
recursion for natural numbers could be written more compactly as:
\begin{alignat*}{3}
  & \ms{primrec} : (X : \Set) \to X \to (\Nat \to X \to X) \to \Nat \to X
\end{alignat*}
This is not the same thing as the usual recursion principle (corresponding to
weak initiality), because of the extra dependency on $\Nat$ in the method for
successors.

\subsection{Sections}
Sections are analogous to morphisms. We again have a choice between weak and
strict preservation; below we have weak preservation.
\begin{alignat*}{3}
  & \rlap{$\blank^S : (A : \Ty)\{X\,X^D\}(X^S : (x : \Tm_0\,X)\to \Tm_0\,(X^D\,x))$}\\
  & \hspace{2em}\rlap{$\to (\alpha : A^A\,X) \to A^D\,X^D\,\alpha \to \Set$}\\
  & \iota^S\,&&X^S\,\alpha\,\,\alpha^D \defn \Tm_0\,(X^S\,\alpha = \alpha^D) \\
  & (\iota\to A)^S\,&&X^S\,\alpha\,\,\alpha^D \defn
  (x : \Tm_0\,X) \to A^S\,X^S\,(\alpha\,x)\,(\alpha^D\,(X^S\,x))
\end{alignat*}

\subsection{Term Algebras}

For term algebras, we need to assume a bit more in the inner theory. For
starters, it has to support the theory of signatures. In order to avoid name
clashes down the line, we use $\SigTy_0$ to refer to signature types, and
$\SigTm_0$ for terms. That is, we have
\begin{alignat*}{3}
  & \SigTy_0  &&: \Ty_0\\
  & \Con_0   &&: \Ty_0\\
  & \Var_0   &&: \Tm_0\,\Con_0 \to \Tm_0\,\SigTy_0 \to \Ty_0\\
  & \SigTm_0 &&: \Tm_0\,\Con_0 \to \Tm_0\,\SigTy_0 \to \Ty_0\\
  & \Sub_0   &&: \Tm_0\,\Con_0 \to \Tm_0\,\Con_0 \to \Ty_0
\end{alignat*}
together with all constructors and induction principles. We also assume inner
$\Pi$-types, because we previously defined $\Sub$ using functions.

\emph{Remark.} In the current section we are liberal with making assumptions in
the inner theory. Strictly speaking, if we only want to construct term algebras,
we don't need to assume signature induction principles. Also, we will see in
Section \ref{TODO} that inner ToS induction is not necessary to show weak
initiality of term algebras; weaker assumptions suffice. In this section, we
omit these generalizations, as the goal is to redo the constructions of Chapter
\ref{chap:simple-inductive-signatures} without making essential changes.

We still have ToS in the outer layer. To make the naming
scheme consistent, we shall write outer ToS types as $\SigTy_1$,
$\SigTm_1$, $\Con_1$, $\Var_1$ and $\Sub_1$. We have conversion functions from
the outer ToS to the inner ToS:
\begin{mydefinition} We have the following \textbf{lowering} functions which
preserve all structure.
\begin{alignat*}{3}
  & \down\,: \SigTy_1 &&\to \Tm_0\,\SigTy_0\\
  & \down\,: \Con_1 &&\to \Tm_0\,\Con_0\\
  & \down\,: \Var_1\,\Gamma\,A &&\to \Tm_0\,(\Var_0\,(\down\!\Gamma)\,(\down\!A))\\
  & \down\,: \SigTm_1\,\Gamma\,A &&\to \Tm_0\,(\SigTm_0\,(\down\!\Gamma)\,(\down\!A))\\
  & \down\,: \Sub_1\,\Gamma\,\Delta &&\to \Tm_0\,(\Sub_0\,(\down\!\Gamma)\,(\down\!\delta))
\end{alignat*}
These functions are called ``lifting'' in the context of multi-stage
programming; see e.g.\ the $\ms{Lift}$ typeclass in Haskell
\cite{pickering-multistage}. There, like here, the point is to build
object-language terms from meta-level (``compile-time'') values.

Lowering is straightforward to define for types, contexts, variables and terms,
but there is a bit of a complication for $\Sub$. Unfolding the definitions, we
need to map from $\{A\} \to \Var_1\,\Delta\,A \to \SigTm_1\,\Gamma\,A$ to
$\Tm_0\,(\{A\} \to \Var_0\,(\down\Delta)\,A \to \SigTm_0\,(\down\Gamma)\,A)$. It
might appear problematic that we have types and variables in \emph{negative}
position, because we can't map inner types/variables to outer ones.
Fortunately, $\Sub_1\,\Gamma\,\Delta$ is isomorphic to a finite product type,
and we can lower a finite product component-wise.

Concretely, we define lowering by induction on $\Delta$, while making use of
a case splitting operation for $\Var_0$. We use an informal $\ms{case}$
operation below, which can be defined using inner induction. Note that since
$\Var_0\,\emptycon\,A$ is an empty type, case splitting on it behaves like
elimination for the empty type.
\begin{alignat*}{3}
  &\rlap{$\hspace{0.3em}\down_{\Delta} : \Sub_1\,\Gamma\,\Delta \to \Tm_0\,(\Sub_0\,(\down\!\Gamma)\,(\down\!\Delta))$}\\
  &\down_{\emptycon}\,&&\sigma \defn
      \lambda\,\{A\}\,(x : \Var_0\,\emptycon\,A).\,\ms{case}\,x\,\ms{of}\,()\\
  &\down_{\Delta\ext B}\,&&\sigma \defn
      \lambda\,\{A\}\,(x : \Var_1\,(\down\!\Delta\,\ext \down\!B)\,A).\,\ms{case}\,x\,\ms{of}\\
  & &&\vz\hspace{0.65em}\to\,\,\down\!(\sigma\,\vz)\\
  & &&\vs\,x \to\,\,\down_{\Delta}\!(\sigma \circ \vs)\,x
\end{alignat*}
In general, for finite $A$ type, functions of the form $A \to \Tm_0\,B$ can be
represented as inner types up to isomorphism; they can be viewed as finite
products of terms.

\emph{Remark.} For infinite $A$ this does not work anymore in our system. In
\cite{twolevel}, the assumption that this still works with $A \equiv \Nat_1$ is
an important axiom (``cofibrancy of $\Nat_1$'') which makes it possible to embed
higher categorical structures in 2LTT. From the metaprogramming perspective,
cofibrancy of $\Nat_1$ implies that the inner theory is \emph{infinitary}, since
we can form inner terms from infinite collections of inner terms. We don't
assume this axiom in 2LTT, although we will consider infinitary (object) type
theories in Chapters \ref{chap:fqiit} and \ref{chap:iqiit}.
\end{mydefinition}

\noindent
We continue to the definition of term algebras. We fix an $\Omega : \Con_1$, and
define $\ms{T} : \Ty_0$ as $\SigTm_0\,(\down\!\Omega)\,\iota$.
\begingroup
\allowdisplaybreaks
\begin{alignat*}{3}
  & \hspace{-5em}\rlap{$\blank^T : (A : \SigTy_1) \to \Tm_0\,(\SigTm_0\,(\down\!\Omega)\,(\down\!A)) \to A^A\,\ms{T}$} \\
  & \hspace{-5em}\iota^T\,&&t \defn t \\
  & \hspace{-5em}(\iota\to A)^T\,&&t \defn \lambda\,u.\,A^T\,(\app\,t\,u)\\
  & \hspace{-5em}&&\\
  & \hspace{-5em}\rlap{$\blank^T : (\Gamma : \Con_1) \to \Sub_1\,\Omega\,\Gamma \to \Gamma^A\,\ms{T}$}\\
  & \hspace{-5em}\rlap{$\Gamma^T\,\nu\,\{A\}\,x \defn A^T\,(\down\!(\nu\,x))$}\\
  & \hspace{-5em} && \\
  & \hspace{-5em}\rlap{$\TmAlg_{\Omega} : \Alg\,\Omega$}\\
  & \hspace{-5em}\rlap{$\TmAlg_{\Omega} \defn \Omega^T\,\Omega\,\id$}
\end{alignat*}
\endgroup
We omit the $\blank^T$ interpretation for terms and substitutions for now, as
they require a bit more setup, and they are not needed just for term algebras.

\subsection{Weak Initiality}

Recall from Section \ref{sec:simple-weak-initiality} that recursion is
implemented using the $\blank^A$ interpretation of terms. Since terms are now in
the inner theory, we need to define an inner version of the same interpretation.
We need to compute types by inner induction, so we additionally assume a
Russell-style inner $\U_0$ universe. The Russell style means that we may freely
coerce between $\Tm_0\,\U_0$ and $\Ty_0$. The following are defined the same way
as $\blank^A$ before.
\begin{alignat*}{3}
  &\blank^A : \Tm_0\,(\SigTy_0 \to \U_0 \to \U_0)\\
  &\blank^A : \Tm_0\,(\Con_0 \to \U_0 \to \U_0)\\
  &\blank^A : \Tm_0\,(\SigTm_0\,\Gamma\,A \to \{X : \U_0\} \to \Gamma^A\,X \to A^A\,X)\\
  &\blank^A : \Tm_0\,(\Sub_0\,\Gamma\,\Delta \to \{X : \U_0\} \to \Gamma^A\,X \to \Delta^A\,X)
\end{alignat*}
Since lowering preserves all structure, and $\blank^A$ is defined in the same
way in both the inner and outer theories, lowering is compatible with
$\blank^A$ in the following way.
\begin{mylemma}\label{lem:down-compat-alg} Assume $A : \SigTy_1$, $\Gamma : \Con_1$, $X : \Ty_0$, $\gamma : \Gamma^A\,X$ and $t : \SigTm_1\,\Gamma\,A$. We have the following:
  \begin{itemize}
  \item $(A^A_{\to},\,A^A_{\leftarrow}) : \Tm_0\,((\down\!A)^A\,X) \simeq A^A\,X$
  \item $(\Gamma^A_{\to},\,\Gamma^A_{\leftarrow}) : \Tm_0\,((\down\!\Gamma)^A\,X) \simeq \Gamma^A\,X$
  \item $t^A\,\gamma \equiv A^A_{\to}\,((\down\!t)^A\,(\Gamma^A_{\leftarrow}\,\gamma))$
  \end{itemize}
\end{mylemma}
\begin{proof}
By induction on $\Gamma$, $A$ and $t$.
\end{proof}
We construct recursors now, yielding strict algebra morphisms.  We
assume $(X,\,\omega) : \Alg\,\Omega$. Recall that $\omega : \Omega^A\,X$, thus
$\Omega^A_{\leftarrow}\,\omega : \Tm_0\,((\down\!\Omega)^A\,X)$. We define $\ms{R} :
\Tm_0\,\ms{T} \to \Tm_0\,X$ as $\ms{R}\,t \defn t^A\,(\Omega^A_{\leftarrow}\,\omega)$.
\begin{alignat*}{3}
& \hspace{-8em}\rlap{$\blank^R : (A : \SigTy_1)(t : \Tm_0\,(\SigTm_0\,(\down\!\Omega)\,(\down\!A))) \to A^M\,\ms{R}\,(A^T\,t)\,(\A^A_{\rightarrow}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega)))$}\\
& \hspace{-8em}\iota^R\,&&t : t^A\,(\Omega^A_{\leftarrow}\,\omega) \equiv \iota^A_{\to}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega))\\
& \hspace{-8em}(\iota\to A)^R\,&&t \defn \lambda\,u.\,A^R\,(\app\,t\,u)\\
& \hspace{-8em}&& \\
& \hspace{-8em}\rlap{$\blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)$}\\
& \hspace{-8em}\rlap{$\Gamma^R\,\nu\,\{A\}\,x \defn A^R\,(\down\!(\nu\,x))$}
\end{alignat*}
In the proof obligation for $t^A\,(\Omega^A_{\leftarrow}\,\omega) \equiv
\iota^A_{\to}\,(t^A\,(\Omega^A_{\leftarrow}\,\omega))$, $\iota^A_{\to}$ computes
to the identity function; note that $\iota^A_{\to} : \Tm_0\,X \to \Tm_0\,X$. Hence
the equality becomes reflexive.

In $\Gamma^R\,\nu\,\{A\}\,x \defn A^R\,(\down\!(\nu\,x))$, we have that
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(A^A_{\to}\,(\down\!(\nu\,x)^A\,(\Omega^A_{\leftarrow}\,\omega)))
\]
Hence by Lemma \ref{lem:down-compat-alg}, we have
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,((\nu\,x)^A\,\omega)
\]
Hence, by the definition of $\blank^A$ for substitutions:
\[
  A^R\,\down\!(\nu\,x) : A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(\nu^A\,\omega\,x)
\]
Which is exactly what is required when we unfold the expected return type:
\begin{alignat*}{3}
  & \blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \Gamma^M\,\ms{R}\,(\Gamma^T\,\nu)\,(\nu^A\,\omega)\\
  & \blank^R : (\Gamma : \Con_1)(\nu : \Sub_1\,\Omega\,\Gamma) \to \{A\}(x : \Var_1\,\Gamma\,A) \to
    A^M\,\ms{R}\,(A^T\,(\down\!(\nu\,x)))\,(\nu^A\,\omega\,x)
\end{alignat*}
The recursor is defined the same way as in Definition \ref{def:simple-recursor}:
\begin{alignat*}{3}
  & \Rec_{\Omega} : (\mi{alg} : \Alg\,\Omega) \to \Mor\,\TmAlg_{\Omega}\,\mi{alg}\\
  & \Rec_{\Omega}\,(X,\,\omega) \defn (\ms{R},\,\Omega^R\,\Omega\,\id)
\end{alignat*}

\subsection{Induction}

For induction, we need to additionally define $\blank^D$ in the inner layer.
\begin{alignat*}{3}
  &\blank^D : \Tm_0\,((A : \SigTy_0)\{X\} \to (\Tm_0\,X \to \U_0) \to A^A\,X \to \U_0)\\
  &\blank^D : \Tm_0\,((\Gamma : \Con_0)\{X\} \to (\Tm_0\,X \to \U_0) \to \Gamma^A\,X \to \U_0)\\
  &\blank^D : \Tm_0\,((t : \SigTm_0\,\Gamma\,A) \to \Gamma^D\,X^D\,\gamma \to A^D\,X^D\,(t^A\,\gamma))\\
  &\blank^D : \Tm_0\,((\sigma : \Sub_0\,\Gamma\,\Delta) \to \Gamma^D\,X^D\,\gamma \to \Delta^D\,X^D\,(\sigma^A\,\gamma))
\end{alignat*}

\begin{mylemma}
We have again compatibility of lowering with $\blank^D$. Assuming
$(X,\,\gamma) : \Alg\,\Gamma$, $(X^D,\,\gamma^D) : \DispAlg\,(X,\,\gamma)$,
$t : \SigTm_1\,\Gamma\,A$, and $\alpha : A^A\,X$, we have
\begin{itemize}
  \item $(\A^D_{\to},\,\A^D_{\leftarrow}) :
    \Tm_0\,((\down\!\A)^D\,X^D\,(\A^A_{\leftarrow}\,\alpha)) \simeq \A^D\,X^D\,\alpha$
  \item $(\Gamma^D_{\to},\,\Gamma^D_{\leftarrow}) :
    \Tm_0\,((\down\!\Gamma)^D\,X^D\,(\Gamma^A_{\leftarrow}\,\gamma)) \simeq \Gamma^D\,X^D\,\gamma$
  \item $t^D\,\gamma^D \equiv A^D_{\to}\,((\down\!t)^D\,(\Gamma^D_{\leftarrow}\,\gamma^D))$
\end{itemize}
The equation for $t^D\,\gamma^D$ is well-typed because of the term equation in Lemma
\ref{lem:down-compat-alg}.
\end{mylemma}
\begin{proof} Again by induction on $\Gamma$, $A$ and $t$.
\end{proof}

We also need to extend $\blank^T$ with action on terms. Note that we return
an inner equality, since we can only compute such equality by induction on the
inner term input:
\[
\blank^T : (t : \SigTm_0\,(\down\!\Gamma)\,(\down\!A))(\nu : \Sub_1\,\Omega\,\Gamma) \to
  \Tm_0\,(A^A_{\leftarrow}\,(A^T\,(t[\down\!\nu])) = t^A\,(\Gamma^A_{\leftarrow}\,\nu))
\]
We assume $(X^D,\,\omega^D) : \DispAlg\,\TmAlg_\Omega$, and define elimination
as follows:
\begin{alignat*}{3}
  & \ms{E} : (t : \Tm_0\,\ms{T}) \to \Tm_0\,(X^D\,t) \\
  & \ms{E}\,t \defn t^D\,(\Omega^D_{\leftarrow}\,\omega^D)
\end{alignat*}
This definition is well-typed only up to $t^T\,\id : \Tm_0\,(t =
t^A\,(\Omega^A_{\leftarrow}\,(\Omega^T\,\Omega\,\id)))$. Since $t^T\,\id$ is an
inner equality, in a fully formal intensional presentation we would have to
write an explicit transport in the definition.

We shall skip the remainder of the eliminator construction; it goes the same way
as in Definition \ref{def:simple-eliminator-construction}. Intuitively, this is
possible since the inner theory has all necessary features to reproduce the
eliminator construction, and lowering preserves all structure.

Since $t^T$ yields inner equations, this implies that the displayed algebra
sections returned by the eliminator are \emph{weak sections}, i.e.\ they contain
$\beta$-rules expressed in inner equalities.

\section{Discussion}

\subsection{Evaluation}

Let's review how 2LTT addresses the shortcomings that we mentioned in Section
\ref{sec:2ltt-motivation}.
\\\\
\textbf{Generalized semantics.} For this purpose, there is minimal
technical overhead to using 2LTT; we only need to sprinkle $\Ty_0$ and $\Tm_0$
around a bit, and we get semantics internally to cwfs (including all finite product
categories).
\\\\
\textbf{Term algebra constructions.}
Here, we had to deal with significantly more noise, because of the necessary
lowerings and their preservation isomorphisms. However, this overhead should be
compared to reasoning about object-level definitional equality in a deeply
embedded way, which entails explicitly manipulating abstract syntax and its
substitutions and weakenings. Compared to that, 2LTT is tremendously easier. One
could also argue that lowering is an entirely mechanical affair, and we can just
omit most of it if we are comfortable enough with the formalism.

\subsection{Recursor vs. Eliminator Construction}

The essential extra detail that we
had to handle in Section \ref{sec:2ltt-simple-signatures} was the choice between
strict and weak equations. This choice brings along further implementation
constraints.

Strict equations are stronger as assumptions, because they represent
definitional equality of inner terms. However, we can only produce strict
equations by eliminating from outer types. Hence, if we aim to output strict
equations, we have to assume every dependency in the outer theory, which in turn
may require using lowering.

Weak equations are easier to produce: strict equality implies weak equality,
plus we can prove weak equality by inner induction. But we cannot use weak
equality to transport outer values.

In the recursor construction, we produced strict $\beta$-rules, which trivially
imply weak $\beta$-rules as well. In contrast, the eliminator construction
relies essentially on equations produced by $\blank^T$ for inner terms. Can we
somehow get strict equations from $\blank^T$? This does not seem possible, at
least without changing the approach in a major way: terms must be inner, or else
we have no hope of inner recursion/induction. And if terms are inner, then
$\ms{E}$ must act on arbitrary inner terms, hence $\blank^T$ must do so too.

It would be interesting to check if there is a possible alternative formulation of
term algebras and constructed eliminators, which makes it possible to get strict
eliminators. Looking back to Section \ref{sec:generic-programming}, it appears
that by using spine neutral terms, we get strict elimination for each
signature. However, this relies on the Agda implementation of pattern matching
and structurally recursive definitions, so it would require more work to translate
these definitions to 2LTT in a generic way.

\chapter{Finitary Quotient Inductive-Inductive Types}
\label{chap:fqiit}

In this chapter we bump the expressive power of signatures by a large margin,
and also substantially extend the semantics. However, we keep the basic approach
the same; indeed its advantages become more apparent with the more sophisticated
signatures.

\section{Theory of Signatures}
\label{sec:fqiit-tos}

Signatures are once again given by contexts of a type theory, but now it is a
dependent type theory, given as a cwf with certain type formers, in the style
of Section \ref{sec:models-of-tts}.
\\\\
\textbf{Metatheory and notation.} We work in 2LTT with $\Ty_0$ and $\Tm_0$, and
we assume no inner type formers.  We follow notation from Section
\ref{sec:2ltt-internal-syntax}. We mostly omit $\Tm_0$ applications in the
following.
\\\\
We specify models of the theory of \emph{finitary quotient
inductive-inductive signatures}. The names involved are a bit of a mouthful, so
we abbreviate ``finitary quotient inductive-inductive'' as FQII, and like
before, we abbreviate ``theory of signatures'' as ToS. In this chapter, by
signature we mean an FQII signature unless otherwise specified.

\begin{mydefinition} A \textbf{model of the theory of signatures} consists of the following.
  \begin{itemize}
    \item A \textbf{cwf} with underlying sets $\Con$, $\Sub$, $\Ty$ and $\Tm$, all returning in
      the outer $\Set$ universe of 2LTT.
    \item A \textbf{Tarski-style universe} $\U$ with decoding $\El$.
    \item An \textbf{extensional identity type} $\Id : \Tm\,\Gamma\,A \to
      \Tm\,\Gamma\,A \to \Ty\,\Gamma$, specified by $(\reflect,\,\refl) :
      \Tm\,\Gamma\,(\Id\,t\,u) \simeq (t \equiv u)$.
    \item An \textbf{inductive function type} $\Pi : (a : \Tm\,\Gamma\,\U) \to
      \Ty\,(\Gamma\ext\El\,a) \to \Ty\,\Gamma$, specified by
      $(\app,\,\lam) : \Tm\,\Gamma\,(\Pi\,a\,B) \simeq \Tm\,(\Gamma \ext \El\,a)\,B$.
    \item An \textbf{external function type} $\Pie : (A : \Ty_0) \to (A \to \Ty\,\Gamma) \to \Ty\,\Gamma$, specified by
      $(\appe,\,\lame) : \Tm\,\Gamma\,(\Pie\,A\,B) \simeq ((x : A) \to \Tm\,\Gamma\,(B\,x))$.
  \end{itemize}
\end{mydefinition}
At this point we only have a notion of model for ToS, but as we will see in
Chapter \ref{chap:iqiit}, ToS is also an algebraic theory, more specifically an
infinitary QII one. It is infinitary because $\Pie$ and $\lame$ allow branching
over elements of arbitrary $A : \Ty_0$ types.

Because of the algebraic character of ToS, there is a category of ToS models
where morphisms strictly preserve all structure, and the initial model
corresponds to the syntax. In this chapter, we just assume that the ToS
syntax exists, and leave metatheoretical matters to Chapter \ref{chap:iqiit}.
\begin{mydefinition} An FQII \textbf{signature} is an element of $\Con$ in the syntax of ToS.
\end{mydefinition}
We review several example signatures in the following, using progressively
more ToS type formers.  We also introduce progressively more compact notation
for signatures. As a rule of thumb, we shall use compact notation for larger and
more complex signatures, but we shall be more explicit when we specify models of
ToS later in this chapter.
\begin{myexample}
  Simple inductive signatures can be evidently expressed using $\U$ and
  $\Pi$. By adding a single $\U$ to the signature, we introduce the inductive
  sort.
  \begin{alignat*}{3}
    & \ms{NatSig} &&\defn \emptycon \ext (N : \U) \ext (\mi{zero} : \El\,N)
                        \ext (\mi{suc} : \Pi (n : N) (\El\,N))\\
    & \ms{TreeSig} &&\defn \emptycon \ext (T : \U) \ext (\mi{leaf} : \El\,T)
                         \ext (\mi{node} : \Pi (t_1 : T) (\Pi (t_2 : T) (\El\,T)))
  \end{alignat*}
  Observe that the domains in $\Pi$ are terms with type $\U$, while the codomains are proper types.
\end{myexample}

\begin{notation} We write non-dependent function types in ToS as follows.
  \begin{itemize}
  \item $a \funi B$ for $\Pi\,(\_ : a)\,B$.
  \item $A \fune B$ for $\Pie\,A\,(\lambda\,\_.\,B)$.
  \end{itemize}
\end{notation}
\noindent
Using this notation, we may write $\mi{suc} : N \funi \El\,N$ and $\mi{node} : T
\funi T \funi \El\,T$.

\begin{notation}
The ``categorical'' application $\app$ with explicit substitutions is a bit
inconvenient. Instead, we simply write whitespace for $\Pii$ and $\Pie$
application:
\begin{alignat*}{3}
  & t\,u \defn (\appi\,t)[\id,\,u]\\
  & t\,u \defn (\appe\,t)\,u
\end{alignat*}
\end{notation}

\begin{myexample}
We may have any number of sorts by adding more $\U$ to the signatures. Moreover,
sorts can be indexed over previous sorts. Hence, using only $\U$, $\El$ and
$\Pi$, we can express any closed inductive-inductive type \cite{TODO}. The
following fragment of the the signature for categories is such:
\begin{alignat*}{3}
  & \emptycon \ext (\mi{Obj} : \U) \ext (\mi{Hom} : \mi{Obj} \funi \mi{Obj} \funi \U)
      \ext (\mi{id} : \Pi(i : \mi{Obj})\,(\El\,(\mi{Hom}\,i\,i)))n
\end{alignat*}
These inductive-inductive signatures are more flexible than those in prior works
\cite{TODO}, since we allow type constructors (sorts) and point constructors to
be arbitrarily mixed (as opposed to mandating that sorts are declared first). For example:
\begin{alignat*}{3}
  & \emptycon \ext (A : \U) \ext (a : \El\,A) \ext (B : A \funi \U) \ext (C : B\,a \funi \U)
\end{alignat*}
Here $C$ is indexed over $B\,a$, where $a$ is a point constructor of $a$, so a
sort specification mentions a point constructor.
\end{myexample}

\begin{myexample} $\Id$ lets us add equations to signatures. With this, we can write down the full
signature for categories:
\begin{alignat*}{3}
  & \emptycon &&\ext (\mi{Obj}   &&: \U)\\
  &           &&\ext (\mi{Hom}   &&: \mi{Obj} \funi \mi{Obj} \funi \U)\\
  &           &&\ext (\mi{id}    &&: \Pi(i : \mi{Obj})\,(\El\,(\mi{Hom}\,i\,i)))\\
  &           &&\ext (\mi{comp}  &&: \Pi\,(i\,j\,k : \mi{Obj})\,(\mi{Hom}\,j\,k \funi \mi{Hom}\,i\,j \funi \El\,(\mi{Hom}\,i\,k)))\\
  &           &&\ext (\mi{idr}   &&: \Pi\,(i\,j : \mi{Obj})(f : \mi{Hom}\,i\,j)\,(\Id\,(\mi{comp}\,i\,i\,j\,f\,(\mi{id}\,i))\,f))\\
  &           &&\ext (\mi{idl}   &&: \Pi\,(i\,j : \mi{Obj})(f : \mi{Hom}\,i\,j)\,(\Id\,(\mi{comp}\,i\,j\,j\,(\mi{id}\,j)\,f)\,f))\\
  &           &&\ext (\mi{assoc} &&: \Pi\,(i\,j\,k\,l : \mi{Obj})(f : \mi{Hom}\,j\,l)(g : \mi{Hom}\,j\,k)(h : \mi{Hom}\,i\,j)\\
  &           && &&\hspace{1.7em} (\Id
                 \,(\mi{comp}\,i\,j\,l\,(\mi{comp}\,j\,k\,l\,f\,g)\,h)
                 \,(\mi{comp}\,i\,k\,l\,f\,(\mi{comp}\,i\,j\,k\,g\,h))
\end{alignat*}
Now, this is already rather hard to read, even together with the compressed
notation for multiple $\Pi$ binders.
\begin{notation}
For more complex signatures, we may entirely switch to an internal notation,
where we mostly reuse the same conventions as in the metatheories. We use $(x :
a) \to B$ for inductive functions, $(x : A) \to^{ext} B$ for external functions,
but we still write $\Id$ for the identity type and make $\U$ and $\El$
explicit. In this notation, a signature is just a listing of types. The category
signature becomes the following:
\begin{alignat*}{3}
  & \mi{Obj} &&: \U\\
  & \mi{Hom} &&: \mi{Obj} \to \mi{Obj} \to \U\\
  & \mi{id}  &&: \El\,(\mi{Hom}\,i\,i)\\
  & \mi{\blank\!\circ\!\blank} &&: \mi{Hom}\,j\,k \to \mi{Hom}\,i\,j \to \El\,(\mi{Hom}\,i\,k)\\
  & \mi{idr} &&: \Id\,(f \circ \mi{id})\,f\\
  & \mi{idl} &&: \Id\,(\mi{id} \circ f)\,f\\
  & \mi{assoc} &&: \Id\,(f \circ (g \circ h))\,((f \circ g) \circ h)
\end{alignat*}
\end{notation}
\end{myexample}

\begin{myexample}
The external function type makes it possible to reference inner types (in 2LTT)
in signatures. Here ``external'' is meant relative to a given signature, and
refers to types and inhabitants which are not introduced inside a signature.
For example, we give a signature for lists by assuming $A : \Ty_0$ for the
(external) type of list elements:
\begin{alignat*}{3}
  &\mi{List} &&: \U\\
  &\mi{nil}  &&: \El\,\mi{List}\\
  &\mi{cons} &&: A \to^{ext} \mi{List} \to \El\,\mi{List}
\end{alignat*}
Hence, ``parameters'' are always assumptions made in the metatheory. We can
also \emph{index} sorts by external values. Let's specify length-indexed vectors
now; we keep the $A : \Ty_0$ assumption, but also assume that $\Ty_0$ has
natural numbers, with $\Nat_0 : \Ty_0$, $\zero_0$ and $\suc_0$.
\begin{alignat*}{3}
  &\mi{Vec}  &&: \Nat_0 \to^{ext} \U \\
  &\mi{nil}  &&: \El\,(\mi{Vec}\,\zero_0)\\
  &\mi{cons} &&: (n : \Nat_0) \to^{ext} A \to^{ext} \mi{Vec}\,n \to \El\,(\mi{Vec}\,(\suc_0\,n))
\end{alignat*}
\end{myexample}

\begin{myexample}
We can also introduce \emph{sort equations} using $\Id$: this means equating
terms of $\U$, i.e.\ inductively specified sets. This is useful for specifying
certain strict type formers. For example, a signature for cwfs can be extended with
a specification for strict constant families.
\begin{alignat*}{3}
  & \mi{Con}     &&: \U\\
  & \mi{Sub}     &&: \mi{Con} \to \mi{Con} \to \U \\
  & \mi{Ty}      &&: \mi{Con} \to \U\\
  & \mi{Tm}      &&: (\Gamma : \mi{Con}) \to \mi{Ty}\,\Gamma \to \U\\
  & ...          &&\\
  & \mi{K}       &&: \mi{Con} \to \{\Gamma : \mi{Con}\} \to \El\,(\mi{Ty}\,\Gamma)\\
  & \mi{K_{spec}} &&: \Id\,(\mi{Tm}\,\Gamma\,(\mi{K}\,\Delta))\,(\mi{Sub}\,\Gamma\,\Delta)
\end{alignat*}
The equation for Russell-style universes is likewise a sort equation:
\begin{alignat*}{3}
  &\mi{Univ}    &&: \El\,(\mi{Ty}\,\Gamma)\\
  &\mi{Russell} &&: \Id\,(\mi{Tm}\,\Gamma\,\mi{Univ})\,(\mi{Ty}\,\Gamma)
\end{alignat*}
\end{myexample}

\begin{myexample}
As we mentioned in Definition \ref{def:presheaf-type}, there is a signature for
presheaves, so let's look at that now. Assume a category $\mbbC$ in the inner
theory; this means that objects and morphisms of $\mbbC$ are in $\Ty_0$.
\begin{alignat*}{3}
  & \mi{Obj}         &&: |\mbbC| \toe \U\\
  & \mi{Hom}         &&: \mbbC(i,\,j) \toe \mi{Obj}\,j \to \El\,(\mi{Obj}\,i)\\
  & \mi{Hom_{\ms{id}}} &&: \Id\,(\mi{Hom}\,\id\,x)\,x\\
  & \mi{Hom_{\circ}}  &&: \Id\,(\mi{Hom}\,(f \circ g)\,x)\,(\mi{Hom}\,f\,(\mi{Hom}\,g\,x))
\end{alignat*}
We depart from the sugary naming scheme in Definition \ref{def:presheaf-type},
and name the action on objects $\mi{Obj}$ and the action on morphisms
$\mi{Hom}$.  We will shortly specify algebras for signatures, where it will be
evident that this signature specifies presheaves from $\mbbC$ to the category
of inner types. That category has elements of $\Ty_0$ as objects and $\Tm_0\,A
\to \Tm_0\,B$ functions as morphisms.
\end{myexample}

\textbf{Strict positivity.} Only strictly positive signatures are expressible.
Similarly to the case with simple signatures, there is no way to abstract over a
inductive functions, since inductive function domains are in $\U$, and $\U$ has
no type formers at all. With $\Pie$, we can abstract over functions, but only on
ones which are external to a signature and don't depend on internally specified
constructors.

\section{Semantics}
\label{sec:fqiit-semantics}

\subsection{Overview}

For simple signatures, we only gave semantics in enough detail so that notions
of recursion and induction could be recovered. We aim to do more now. For each
signature, we would like to have
\begin{enumerate}
  \item A \emph{category} of algebras, with homomorphisms as morphisms.
  \item A notion of induction, which requires a notion of dependent algebras.
  \item A proof that for algebras, initiality is equivalent to supporting induction.
\end{enumerate}

We do this by creating a model of ToS where contexts (signatures) are categories
with certain extra structure and substitutions are structure-preserving
functors. Then, ToS signatures can be interpreted in this model, using the
initiality of ToS syntax (i.e.\ the recursor).

Our semantics has a type-theoretic flavor, which is inspired by the cubical set
model of Martin-Löf type theory by Bezem et al. \cite{cubicalmodel}. The idea is
to avoid strictness issues by starting from basic ingredients which are already
strict enough. Hence, instead of modeling ToS types as certain slices and
substitution by pullback, we model types as displayed categories with extra
structure, which naturally support strict reindexing/substitution.

We make a similar choice in the interpretation of signatures themselves: we use
structured cwfs of algebras, where types correspond to displayed algebras. This
choice is in contrast to having finitely complete categories of algebras.
Preliminarily, the reason is that ``native'' displayed algebras and sections
allow us to compute induction principles strictly as one would write in a type
theory. In fact, in this chapter we recover exactly the same semantics for
simple signatures that we already specified.

In contrast, displayed algebras are a derived notion in finitely complete
categories, and the induction principles would be only up to isomorphism.  This
issue is perhaps not relevant from a purely categorical perspective, but we are
concerned with eventually implementing QIITs in proof assistants. If we don't
compute induction principles here in an exact way, we don't get them from
anywhere else.

\subsection{Separate vs.\ bundled models}

Previously, we defined $\blank^A$, $\blank^M$, $\blank^D$ and $\blank^S$
interpretations of signatures separately, by doing induction anew for each
one. Formally, this amounts to giving a plain model of ToS in order to define
$\blank^A$, but then giving three \emph{displayed} models of ToS to specify the
other interpretations, because they sometimes need to refer to the recursors or
eliminators of other interpretations.

For example, $\blank^A : \Con \to \Set$ while $\blank^D : (\Gamma : \Con) \to
\Gamma^A \to \Set$, so displayed algebras already refer to $\blank^A$, which is
part of the recursor for the corresponding model.

However, this piecewise style can be avoided: we can give a single non-displayed
model which packs everything in a $\Sigma$-type, yielding just one
interpretation function for signatures. Let's call that function $\blank^M$ now:
\begin{alignat*}{5}
  & \blank^M : \Con &&\to \,&&(A &&: \Set)\\
  & &&\hspace{0.3em}\times &&(M  &&: A \to A \to \Set)\\
  & &&\hspace{0.3em}\times &&(D  &&: A \to \Set)\\
  & &&\hspace{0.3em}\times &&(S  &&: (a : A) \to D\,a \to \Set)
\end{alignat*}
Note that it is often not possible to merge multiple recursors/eliminators by
packing models together. For example, addition on natural numbers is defined by
recursion, and so is multiplication; but since multiplication calls addition in
an iterated fashion, it is not possible to define both operations by a single
algebra. Nevertheless, merging does work in our case. We will, in fact, get a
formal vocabulary for merging models (and manipulating them in other ways) from
the semantics of ToS itself.

In simple cases, and in Agda, the piecewise style is convenient, since we don't
have to deal with $\Sigma$-s. However, for larger models, important organizing
principles may become more apparent if we bundle things together.

In the following, we shall define a model $\bM : \ToS$ such that its $\Con$
component is a bundle containing all $A$, $M$, $D$, $S$ components like above
(and it contains more). We present the components of $\bM$ in order. There is
significant overlap in names and notations, so we use \textbf{bold} font to
disambiguate components of $\bM$ from components of other structures. For
example, we use $\bs{\sigma : \Sub\,\Gamma\,\Delta}$ to denote a substitution in
$\bM$, while there could be a $\Sub$-named components in other structures under
consideration.

\subsection{Finite Limit Cwfs}

We define $\bCon : \Set$ as finite limit cwfs (flcwfs). In the following we
specify flcwfs and describe some internal constructions.

\begin{mydefinition}\label{def:flcwf}
We define $\flcwf : \Set$ as an iterated $\Sigma$-type with the following components:
\begin{enumerate}
  \item A cwf with $\Con$, $\Sub$, $\Ty$, $\Tm$ all returning in $\Set$. \emph{Remark:}
        this implies that $\flcwf : \Set$ is in a larger universe than all of these
        internal components. We continue to elide universe sizing details.
  \item $\Sigma$-types.
  \item Extensional identity type $\Id$ with $\refl$ and $\reflect$.
  \item Strict constant families $\K$.
\end{enumerate}
\end{mydefinition}
\begin{mydefinition}
We abbreviate the additional structure on cwfs consisting of $\Sigma$, $\Id$ and
$\K$ as \textbf{fl-structure}.
\end{mydefinition}

We recover previous concepts as follows. Assuming $\Gamma$ signature, we get an
flcwf by interpreting $\Gamma$ in $\bM$. In that flcwf we have
\begin{itemize}
  \item $\Con$ as the type of algebras.
  \item $\Sub$ as the type of algebra morphisms.
  \item $\Ty$ as the type of displayed algebras.
  \item $\Tm$ as the type of displayed algebra sections.
\end{itemize}
From this, notions of initiality and induction are apparent as well. Initiality
is the usual categorical notion. For induction, assuming $\bGamma : \bCon$, we
have the following predicate:
\begin{alignat*}{3}
  & \Inductive : \Con_{\bGamma} \to \Set\\
  & \Inductive\,\Gamma \defn (A : \Ty_{\bGamma}\,\Gamma)\ra \Tm_{\bGamma}\,\Gamma\,A
\end{alignat*}
In short, an algebra is inductive if every displayed algebra over it has a
section. Fortunately, we also know that induction and initiality are
equivalent.

\begin{theorem}\label{thm:initiality-induction}
An object $\Gamma : \Con_{\bGamma}$ in an flcwf $\bGamma$ supports induction if
and only if it is initial. Moreover, induction and initiality are both mere
properties.
\end{theorem}

\begin{proof}
First, we show that induction implies initiality. We assume $\Gamma : \Con$,
$\ms{ind} : \ms{Inductive}\,\Gamma$ and $\Delta : \Con$. We aim to show that
there is a unique inhabitant of $\Sub\,\Gamma\,\Delta$. We have
$\ms{ind}\,(\K\,\Delta) : \Tm\,\Gamma\,(\K\,\Delta)$, hence
$\ms{ind}\,(\K\,\Delta) : \Sub\,\Gamma\,\Delta$. We only need to show that this
is unique.  Assume $\delta : \Sub\,\Gamma\,\Delta$. Now,
$\ms{ind}\,(\Id\,\delta\,(\ms{ind}\,(\K\,\Delta))) :
\Tm\,\Gamma\,(\Id\,\delta\,(\ms{ind}\,(\K\,\Delta)))$, and it follows by
equality reflection that $\delta \equiv \ms{ind}\,(\K\,\Delta)$.

Second, the other direction. We assume that $\Gamma$ is initial, and also $A :
\Ty\,\Gamma$, and aim to inhabit $\Tm\,\Gamma\,A$. By initiality we get a unique
$\sigma : \Sub\,\Gamma\,(\Gamma \ext A)$. Now, $\q[\sigma] : \Tm\,\Gamma\,(A[\p \circ \sigma])$,
but since $\p \circ \sigma : \Sub\,\Gamma\,\Gamma$, it must be equal to $\id$ by the initiality
of $\Gamma$. Hence, $\q[\sigma] : \Tm\,\Gamma\,A$.

Lastly: it is well-known that initiality is a mere property, so let's show the
same for induction.  We assume $\ms{ind},\,\ms{ind'} : \ms{Inductive}\,\Gamma$
and $A : \Ty\,\Gamma$. We have
$\reflect\,(\ms{ind}\,(\Id\,(\ms{ind}\,A)\,(\ms{ind'}\,A))) : \ms{ind}\,A \equiv
\ms{ind'}\,A$. Since $A$ is arbitrary, by function extensionality we also have $\ms{ind} \equiv \ms{ind'}$.
\end{proof}

Note that the above proof does not rely on $\Sigma$-types in the flcwf, so why
do we include them in the semantics? One reason is the prior result by
Clairmabault and Dybjer \cite{clairambault2014biequivalence} that a slightly
different formulation of flcwfs is biequivalent to finitely complete
categories. More concretely, in ibid.\ there is a 2-category of cwfs with
$\Sigma$, $\Id$ and ``democracy'', the last of which is equivalent to the weak
formulation of constant families. Then, it is shown that this 2-category is
biequivalent to the 2-category of finitely complete categories.

Our flcwf is not exactly the same, because our constant families are strict. But
we certainly don't lose anything by having stricter semantics, since the weak
versions can be trivially recovered. In short, including $\Sigma$ is a good
deal, as this allows us to connect our semantics back to finitely complete
categories, which are more commonplace in categorical settings.

We present some concepts in flcwfs which will be needed later, especially
in Chapter \ref{chap:iqiit}.

\begin{mydefinition}[Type categories, c.f.\ \cite{clairambault2014biequivalence}]
\label{def:type_categories} For each $\Gamma : \Con$, there is a category
whose objects are types $A : \Ty\,\Gamma$, and morphisms from $A$ to $B$ are
terms $t : \Tm\,(\Gamma\,\ext\,A)\,(B[\p])$. Identity morphisms are given by $\q
: \Tm\,(\Gamma\,\ext\,A)\,(A[\p])$, and composition $t \circ u$ by $t[\p,
  u]$. The assignment of type categories to contexts extends to a split indexed
category. For each $\sigma : \Sub\,\Gamma\,\Delta$, there is a functor from
$\Ty\,\Delta$ to $\Ty\,\Gamma$, which sends $A$ to $A[\sigma]$ and $t :
\Tm\,(\Gamma\,\ext\,A)\,(B[\p])$ to $t[\sigma\circ \p, \q]$.
\end{mydefinition}

\begin{notation}
  ~\\
  \begin{itemize}
  \item  \vspace{-1.7em}
         In any cwf, we use $\sigma : \Gamma \simeq \Delta$ to indicate
         that $\sigma : \Sub\,\Gamma\,\Delta$ is an isomorphism with inverse $\sigma^{-1}$.
    \item A \emph{type isomorphism}, written as $t : A \simeq B$ is an isomorphism in a
         type category, with inverse as $t^{-1}$.
  \end{itemize}
\end{notation}









"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"

"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"

"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"

"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"


"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"

"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"






\subsection{Finite Limit Cwfs}
\subsection{Equivalence of Initiality and Induction}
\subsection{Model of the Theory of Signatures}

\section{Term Algebras}
\label{sec:fqiit-term-algebras}
\subsection{Generic Term Algebras}
\subsection{Induction for Term Algebras}
\subsection{Church Encoding}
\subsection{Awodey-Frey-Speight Encoding}

\section{Left Adjoints of Signature Morphisms}




\chapter{Infinitary Quotient Inductive-Inductive Types}
\label{chap:iqiit}
\section{Theory of Signatures}
\section{Semantics}
\section{Term Algebras}

\chapter{Levitation, Bootstrapping and Universe Levels}
\label{chap:levitation}
\section{Levitation for Closed QIITs}
\section{Levitation for Infinitary QIITs}

\chapter{Higher Inductive-Inductive Types}
\label{chap:hiit}

\section{Theory of Signatures}
\section{Semantics}

\chapter{Reductions}

\section{Finitary Inductive Types}
\section{Finitary Inductive-Inductive Types}
\section{Closed Quotient Inductive-Inductive Types}

\chapter{Conclusion}

\bibliography{references}
\backmatter
\end{document}
